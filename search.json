[
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Prof. Giuseppe Ragusa\n   Sapienza, Università di Roma\n   Dipartimento di Economia e Diritto\n   Prof. Giuseppe Ragusa\n   giuseppe.ragusa@uniroma1.it\n   Ricevimento\n\n\n\n\n\n   Martedì (Ma) e Mercoledì (Me)\n   18 febbraio, 2025 - 31 maggio 2025\n   (Ma) 14:00–16:00 (Me) 16:00-18:00\n   Aula 10"
  },
  {
    "objectID": "syllabus.html#descrizione-del-corso",
    "href": "syllabus.html#descrizione-del-corso",
    "title": "Syllabus",
    "section": "Descrizione del corso",
    "text": "Descrizione del corso\nEconometria (1018133) offre agli studenti un’introduzione pratica all’econometria, strumento fondamentale per comprendere e analizzare l’economia da un punto di vista empirico. Attraverso un approccio equilibrato tra teoria e pratica, gli studenti esploreranno i concetti fondamentali e gli strumenti empirici necessari per comprendere le sfide relative all’impiego di tecniche quantitative in microeconomia, macroeconomia e finanza.\nL’enfasi è sulla comprensione intuitiva e non sulle formalità matematiche questo corso ti fornirà le competenze necessarie per affrontare sfide analitiche complesse con sicurezza e competenza."
  },
  {
    "objectID": "syllabus.html#obiettivi-del-corso",
    "href": "syllabus.html#obiettivi-del-corso",
    "title": "Syllabus",
    "section": "Obiettivi del corso",
    "text": "Obiettivi del corso\nAlla conclusione del corso, gli studenti saranno in grado di condurre analisi empiriche in modo indipendente e interpretarne i risultati, valutando attentamente l’adeguatezza delle assunzioni necessarie per garantire la corretta interpretazione dei risultati.\nIn particolare, gli studenti saranno in grado di:\n\nComprendere la logica e la filosofia dei modelli econometrici presentati, valutando la loro capacità di cogliere relazioni causali o di fornire predizioni di qualità.\nValutare criticamente le assunzioni fondamentali sottostanti ai modelli econometrici, analizzandone l’impatto sulla validità dei risultati.\nUtilizzare rigorose misure statistiche per valutare la qualità delle predizioni generate dai modelli econometrici.\nApplicare efficacemente il software R per manipolare dati, produrre visualizzazioni informative e stimare i parametri dei modelli econometrici utilizzando dati reali, sviluppando così competenze pratiche nel campo dell’analisi dei dati e della modellistica economica."
  },
  {
    "objectID": "syllabus.html#libro-di-testo",
    "href": "syllabus.html#libro-di-testo",
    "title": "Syllabus",
    "section": "Libro di testo",
    "text": "Libro di testo\n\n\n\n\n\nIl libro di testo utilizzato in questo corso è:\nStock, J. H. e Watson, M.W: Introduzione all’econometria, Pearson Italia, 2020. ISBN: 8891906190.\nDurante il corso, gli studenti avranno accesso a slides didattiche che forniranno una guida dettagliata attraverso i concetti e gli argomenti trattati. Queste risorse supplementari saranno fondamentali per consolidare la comprensione dei materiali di studio e facilitare il processo di apprendimento."
  },
  {
    "objectID": "syllabus.html#software",
    "href": "syllabus.html#software",
    "title": "Syllabus",
    "section": "Software",
    "text": "Software\n\n\n\n\n\nCome già accennato, il corso prevede l’utilizzo di R, uno dei linguaggi di programmazione statistico/econometrico più diffusi e potenti.\nR ha una licenza open-source (GNU GPL), è compatibile con i maggiori sistemi operativi (GNU/Linux, macOS, Microsoft Windows)."
  },
  {
    "objectID": "syllabus.html#orari-di-ricevimento",
    "href": "syllabus.html#orari-di-ricevimento",
    "title": "Syllabus",
    "section": "Orari di ricevimento",
    "text": "Orari di ricevimento\nGli orari di ricevimento sono:\n\n\n\nGiorno\nOrario\n\n\n\n\nMartedì\n16:00-17:00\n\n\nVenerdì\n10:00-12:00\n\n\n\nE’ obbligatorio prenotare un appuntamento a questo link."
  },
  {
    "objectID": "syllabus.html#modalità-di-valutazione",
    "href": "syllabus.html#modalità-di-valutazione",
    "title": "Syllabus",
    "section": "Modalità di valutazione",
    "text": "Modalità di valutazione\nL’esame di Econometria si compone di una prova scritta e una prova orale, entrambe obbligatorie.\nLa prova scritta valuterà la capacità degli studenti di comprendere e interpretare le stime dei modelli econometrici introdotti durante il corso e di applicarli in contesti specifici.\nLa prova orale è volta ad accertare in maniera più articolata le conoscenza acquisite nel corso.\nL’ammissione alla prova orale è consentita agli studenti che abbiano superato con sufficienza la prova scritta."
  },
  {
    "objectID": "syllabus.html#programma-per-gli-studenti-dellordinamento-attuale-6-cfu",
    "href": "syllabus.html#programma-per-gli-studenti-dellordinamento-attuale-6-cfu",
    "title": "Syllabus",
    "section": "Programma per gli Studenti dell’Ordinamento Attuale (6 cfu)",
    "text": "Programma per gli Studenti dell’Ordinamento Attuale (6 cfu)\n\nParte I: Elementi Fondamentali\nCapitolo 1. Domande economiche e dati economici: Introduzione ai quesiti economici, effetti causali, esperimenti ideali e tipologie di dati (sezionali, serie temporali, panel).\nCapitolo 2. Richiami di probabilità: Variabili casuali, distribuzioni, valore atteso, varianza, covarianza e principali distribuzioni campionarie\nCapitolo 3. Richiami di statistica: Stima, verifica di ipotesi, intervalli di confidenza per medie di popolazioni e confronto tra medie.\n\n\nParte II: Analisi di Regressione\nCapitolo 4. Regressione lineare con un singolo regressore: Il modello OLS, assunzioni dei minimi quadrati, distribuzione campionaria, verifica di ipotesi e intervalli di confidenza.\nCapitolo 5. Regressione lineare con regressori multipli: Distorsione da variabile omessa, modello di regressione multipla, collinearità, verifica di ipotesi congiunte (statistica F) e misure di bontà dell’adattamento (\\(R^2\\) e \\(R^2\\) corretto).\nCapitolo 6. Funzioni di regressione non lineari: Modellazione di relazioni non lineari tramite polinomi, logaritmi e interazioni tra variabili.\nCapitolo 7. Valutazione di studi basati sulla regressione multipla: Validità interna ed esterna, minacce comuni (variabili omesse, errori di misurazione, causalità simultanea).\n\n\nParte III: Ulteriori Sviluppi dell’Analisi di Regressione\nCapitolo 8. Regressione con dati panel: Utilizzo di dati panel per controllare fattori non osservati tramite modelli a effetti fissi ed effetti temporali.\nCapitolo 9. Regressione con variabile dipendente binaria: Modello lineare di probabilità e introduzione ai modelli Probit e Logit.\nCapitolo 10. Regressione con variabili strumentali (IV): Logica della stima IV, lo stimatore dei minimi quadrati a due stadi (TSLS) e le condizioni di validità degli strumenti (rilevanza ed esogeneità)."
  },
  {
    "objectID": "syllabus.html#programma-per-studenti-con-esame-da-9-cfu",
    "href": "syllabus.html#programma-per-studenti-con-esame-da-9-cfu",
    "title": "Syllabus",
    "section": "Programma per Studenti con Esame da 9 CFU",
    "text": "Programma per Studenti con Esame da 9 CFU\nGli studenti che devono sostenere l’esame da 9 crediti, sono tenuti a portare tutto il programma sopra elencato, con l’aggiunta dei seguenti capitoli relativi alle serie temporali:\n\nParte IV: Regressioni per Serie Temporali di Tipo Economico\nCapitolo 12. Introduzione a regressioni temporali e previsioni: Modelli autoregressivi (AR), stazionarietà, trend, rotture strutturali e criteri di informazione per la scelta della lunghezza dei ritardi.\nCapitolo 13. Stima degli effetti causali dinamici: Modelli a ritardi distribuiti (ADL), esogeneità e stima con errori autocorrelati (errori standard HAC)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Econometria (1018133)",
    "section": "",
    "text": "Prof. Giuseppe Ragusa\n   Sapienza, Università di Roma\n   Dipartimento di Economia e Diritto\n   Viale del Castro Laurenziano, 9\n   giuseppe.ragusa at uniroma1 dot it\n   Ricevimento\n\n\n\n\n\n   Martedì (Ma) e Mercoledì (Me)\n   18 febbraio, 2025 - 31 maggio 2025\n   (Ma) 14:00–16:00 (Me) 16:00-18:00\n   Aula 10"
  },
  {
    "objectID": "index.html#descrizione-del-corso",
    "href": "index.html#descrizione-del-corso",
    "title": "Econometria (1018133)",
    "section": "Descrizione del corso",
    "text": "Descrizione del corso\nEconometria (1018133) offre agli studenti un’introduzione pratica all’econometria, strumento fondamentale per comprendere e analizzare l’economia da un punto di vista empirico. Attraverso un approccio equilibrato tra teoria e pratica, gli studenti esploreranno i concetti fondamentali e gli strumenti empirici necessari per comprendere le sfide relative all’impiego di tecniche quantitative in microeconomia, macroeconomia e finanza."
  },
  {
    "objectID": "IntroduzioneR.html",
    "href": "IntroduzioneR.html",
    "title": "R: Introduzione",
    "section": "",
    "text": "R è un linguaggio di programmazione open source utilizzato per l’analisi e visualizzazione dei dati.\nR è la versione open source di S, software sviluppato da John Chambers, Rick Becker and Allan Wilks presso i Bell Laboratories di AT&T alla fine degli anni ’70. Nell’idea del suoi creatori, S doveva essere un linguaggio di programmazione che fosse più semplice e più interattivo rispetto ai linguaggi utilizzati per l’analisi dei dati dell’epoca (FORTRAN e SAS).\nR fu sviluppato inizialmente da Ross Ihaka e Robert Gentleman presso l’Università di Auckland, in Nuova Zelanda. La prima versione di R venne condivisa dai sui creatori nel 1993. Nel 1995 il software fu rilasciato sotto la licenza open source GNU GPL.\nLa versione 1.0 è stata rilasciata il 29 febbraio 2000 e da quel momento la crescita della sua popolarità non si è arrestata.\nNegli ultimi dieci anni, due aziende hanno contribuito alla crescita di R: R Studio (oggi diventata Posit) e Revolution Analytics.\nRevolution Analytics fondata nel 2007, è stata una delle prime società a offrire una versione commerciale di R. Revolution Analytics ha introdotto nuove funzionalità, come l’elaborazione parallela e distribuita, che hanno permesso di elaborare grandi quantità di dati in modo più efficiente. L’acquisizione di Revolution Analytics da parte di Microsoft nel 2015 ha ulteriormente rafforzato l’adozione di R, poiché Microsoft ha iniziato a integrare R in molti dei suoi prodotti, come SQL Server e Power BI.\nRStudio, dal 2022 Posit, ha avuto un ruolo fondamentale nello sviluppo dell’ecosistema R. Fondata nel 2011 da JJ Allaire, l’azienda ha introdotto un ambiente di sviluppo integrato (IDE) che ha rivoluzionato l’interazione con il linguaggio e ha reso la programmazione in R più accessibile e intuitiva, facilitando la scrittura, il debug e la gestione dei pacchetti.\nOltre al suo IDE, RStudio ha svolto un ruolo chiave nello sviluppo del tidyverse, una collezione di pacchetti ideata e sviluppata da Hadley Wickham, uno dei più influenti progammatori di R e Chief Scientist di Posit. Il tidyverse comprende pacchetti come ggplot2, dplyr e tidyr usati per la visualizzazione, la manipolazione e la ristrutturazione dei dati. Questi strumenti hanno reso più efficiente e meno soggette a errori l’analisi dei dati promuovendo uno stile di programmazione coerente e leggibile.\nR è oggi uno dei linguaggi di programmazione più popolari per l’analisi dei dati e la statistica negli ultimi anni. Ecco alcuni dati sull’adozione di R:\n\nNumero di utenti: Secondo un sondaggio del 2022 condotto da Stack Overflow R è uno dei linguaggi di programmazione più popolare al mondo, utilizzato dal 4.7% degli sviluppatori ed è il primo fra i software specificatamente pensati per applicazioni statistiche.\nNumero di pacchetti: Il Comprehensive R Archive Network (CRAN), il principale repository di pacchetti per R, contiene oltre 19.000 pacchetti. Questi pacchetti coprono una vasta gamma di applicazioni che vanno dalla statistica al machine learning, dalla visualizzazione e manipolazione dei dati alla stesura automatica di report, e altri task generici non necessariamente legati alle applicazioni di carattere statistico.\nUso aziendale: L’adozione di R nell’ambiente aziendale è in costante aumento.",
    "crumbs": [
      "Syllabus",
      "Introduzione a `R`"
    ]
  },
  {
    "objectID": "IntroduzioneR.html#storia",
    "href": "IntroduzioneR.html#storia",
    "title": "R: Introduzione",
    "section": "",
    "text": "R è un linguaggio di programmazione open source utilizzato per l’analisi e visualizzazione dei dati.\nR è la versione open source di S, software sviluppato da John Chambers, Rick Becker and Allan Wilks presso i Bell Laboratories di AT&T alla fine degli anni ’70. Nell’idea del suoi creatori, S doveva essere un linguaggio di programmazione che fosse più semplice e più interattivo rispetto ai linguaggi utilizzati per l’analisi dei dati dell’epoca (FORTRAN e SAS).\nR fu sviluppato inizialmente da Ross Ihaka e Robert Gentleman presso l’Università di Auckland, in Nuova Zelanda. La prima versione di R venne condivisa dai sui creatori nel 1993. Nel 1995 il software fu rilasciato sotto la licenza open source GNU GPL.\nLa versione 1.0 è stata rilasciata il 29 febbraio 2000 e da quel momento la crescita della sua popolarità non si è arrestata.\nNegli ultimi dieci anni, due aziende hanno contribuito alla crescita di R: R Studio (oggi diventata Posit) e Revolution Analytics.\nRevolution Analytics fondata nel 2007, è stata una delle prime società a offrire una versione commerciale di R. Revolution Analytics ha introdotto nuove funzionalità, come l’elaborazione parallela e distribuita, che hanno permesso di elaborare grandi quantità di dati in modo più efficiente. L’acquisizione di Revolution Analytics da parte di Microsoft nel 2015 ha ulteriormente rafforzato l’adozione di R, poiché Microsoft ha iniziato a integrare R in molti dei suoi prodotti, come SQL Server e Power BI.\nRStudio, dal 2022 Posit, ha avuto un ruolo fondamentale nello sviluppo dell’ecosistema R. Fondata nel 2011 da JJ Allaire, l’azienda ha introdotto un ambiente di sviluppo integrato (IDE) che ha rivoluzionato l’interazione con il linguaggio e ha reso la programmazione in R più accessibile e intuitiva, facilitando la scrittura, il debug e la gestione dei pacchetti.\nOltre al suo IDE, RStudio ha svolto un ruolo chiave nello sviluppo del tidyverse, una collezione di pacchetti ideata e sviluppata da Hadley Wickham, uno dei più influenti progammatori di R e Chief Scientist di Posit. Il tidyverse comprende pacchetti come ggplot2, dplyr e tidyr usati per la visualizzazione, la manipolazione e la ristrutturazione dei dati. Questi strumenti hanno reso più efficiente e meno soggette a errori l’analisi dei dati promuovendo uno stile di programmazione coerente e leggibile.\nR è oggi uno dei linguaggi di programmazione più popolari per l’analisi dei dati e la statistica negli ultimi anni. Ecco alcuni dati sull’adozione di R:\n\nNumero di utenti: Secondo un sondaggio del 2022 condotto da Stack Overflow R è uno dei linguaggi di programmazione più popolare al mondo, utilizzato dal 4.7% degli sviluppatori ed è il primo fra i software specificatamente pensati per applicazioni statistiche.\nNumero di pacchetti: Il Comprehensive R Archive Network (CRAN), il principale repository di pacchetti per R, contiene oltre 19.000 pacchetti. Questi pacchetti coprono una vasta gamma di applicazioni che vanno dalla statistica al machine learning, dalla visualizzazione e manipolazione dei dati alla stesura automatica di report, e altri task generici non necessariamente legati alle applicazioni di carattere statistico.\nUso aziendale: L’adozione di R nell’ambiente aziendale è in costante aumento.",
    "crumbs": [
      "Syllabus",
      "Introduzione a `R`"
    ]
  },
  {
    "objectID": "IntroduzioneR.html#installazione-di-r-e-rstudio",
    "href": "IntroduzioneR.html#installazione-di-r-e-rstudio",
    "title": "R: Introduzione",
    "section": "Installazione di R e Rstudio",
    "text": "Installazione di R e Rstudio\nR può essere scaricato gratuitamente dal sito ufficiale (www.r-project.org/) scegliendo la versione adatta al sistema operativo utilizzato.\nPer installare RStudio sul tuo computer bisogna visitare https://posit.co/download/rstudio-desktop/, scaricare la versione di RStudio Desktop compatibile con il sistema operativo e seguire le istruzioni per completare l’installazione.\n\n\n\n\n\n\nImportant\n\n\n\nUna differenza chiave da comprendere capire è quella tra R, il linguaggio di programmazione mentre RStudio è un’interfaccia ad R che consente di lavorare maggiore facilità con R.",
    "crumbs": [
      "Syllabus",
      "Introduzione a `R`"
    ]
  },
  {
    "objectID": "IntroduzioneR.html#calcoli-di-base",
    "href": "IntroduzioneR.html#calcoli-di-base",
    "title": "R: Introduzione",
    "section": "Calcoli di Base",
    "text": "Calcoli di Base\nR come una semplice calcolatrice.\n\nAddizione, Sottrazione, Moltiplicazione e Divisione\n\n\n\nMatematica\nCodice R\nRisultato\n\n\n\n\n\\(3 + 2\\)\n3 + 2\n5\n\n\n\\(3 - 2\\)\n3 - 2\n1\n\n\n\\(3 \\cdot2\\)\n3 * 2\n6\n\n\n\\(3 / 2\\)\n3 / 2\n1.5\n\n\n\n\n\nEsponenti\n\n\n\nMatematica\nCodice R\nRisultato\n\n\n\n\n\\(3^2\\)\n3 ^ 2\n9\n\n\n\\(2^{(-3)}\\)\n2 ^ (-3)\n0.125\n\n\n\\(100^{1/2}\\)\n100 ^ (1 / 2)\n10\n\n\n\\(\\sqrt{100}\\)\nsqrt(100)\n10\n\n\n\n\n\nCostanti Matematiche\n\n\n\nMatematica\nCodice R\nRisultato\n\n\n\n\n\\(\\pi\\)\npi\n3.1415927\n\n\n\\(e\\)\nexp(1)\n2.7182818\n\n\n\n\n\nLogaritmi\nNota che useremo \\(\\ln\\) e \\(\\log\\) in modo interscambiabile per indicare il logaritmo naturale. Non c’è ln() in R, invece usa log() per indicare il logaritmo naturale.\n\n\n\nMatematica\nCodice R\nRisultato\n\n\n\n\n\\(\\log(e)\\)\nlog(exp(1))\n1\n\n\n\\(\\log_{10}(1000)\\)\nlog10(1000)\n3\n\n\n\\(\\log_{2}(8)\\)\nlog2(8)\n3\n\n\n\\(\\log_{4}(16)\\)\nlog(16, base = 4)\n2\n\n\n\n\n\nTrigonometria\n\n\n\nMatematica\nCodice R\nRisultato\n\n\n\n\n\\(\\sin(\\pi / 2)\\)\nsin(pi / 2)\n1\n\n\n\\(\\cos(0)\\)\ncos(0)\n1",
    "crumbs": [
      "Syllabus",
      "Introduzione a `R`"
    ]
  },
  {
    "objectID": "IntroduzioneR.html#i-pacchetti-di-r",
    "href": "IntroduzioneR.html#i-pacchetti-di-r",
    "title": "R: Introduzione",
    "section": "I pacchetti di R",
    "text": "I pacchetti di R\nI pacchetti in R sono collezioni di funzioni, dati e codice compilato che sono sviluppati da terzi per aumentare le funzionalità di R. Sono fondamentali poiché permettono agli utenti di eseguire una vasta gamma di analisi e processi senza dover scrivere tanto codice. Ci sono migliaia di pacchetti disponibili su CRAN (Comprehensive R Archive Network), oltre a quelli disponibili su altre fonti come GitHub.\nPer installare un pacchetto in R, si utilizza la funzione install.packages(). Questa funzione scarica e installa il pacchetto desiderato dal repository CRAN. Una volta installato un pacchetto, è necessario caricarlo nella sessione di lavoro corrente usando la funzione library() per poter utilizzare le sue funzionalità.\nEcco un esempio di come installare e caricare il pacchetto ggplot2:\n\n# Installa il pacchetto ggplot2\ninstall.packages(\"ggplot2\")\n\n# Carica il pacchetto ggplot2\nlibrary(ggplot2)\n\nIn questo esempio, il primo comando installa ggplot2 e il secondo comando lo carica nella sessione di R attuale, rendendo disponibili tutte le sue funzioni e capacità.\nI pacchetti possono anche essere installati da Rstudio, dal menu Strumenti|Installa pacchetti. Similarmente, i pacchetti possono essere aggiornati usando la voce Aggiorna pacchetti.\nAlcuni pacchetti di R includono raccolte di dati (dataset). Questi dataset sono particolarmente utili. Per esempio, wooldridge, Ecdat e AER contengono vari dataset di carattere economico.\nPer accedere ai dataset inclusi nei pacchetti bisogna installarli e poi caricarli.\n\n# Installa il pacchetto AER\ninstall.packages(\"AER\")\n# Installa il pacchetto wooldridge\ninstall.packages(\"wooldridge\")\n\n# Carichiamo i pacchetti\nlibrary(AER)\nlibrary(wooldridge)\n\n# Carica un dataset specifico, ad esempio 'Accident'\ndata(Fatalities)\n\nAlternativamente, i pacchetti possono essere installati direttamente da RStudio usando il menu Tools (Strumenti).\nDopo aver installato e caricato Ecdat il comando data() consente di caricare uso specifico dataset in memoria per essere poi utilizzato nella nostra sessione.\nI dataset inclusi nei pacchetti offrono diversi vantaggi:\n\nFacilità di Accesso: Gli utenti possono accedere rapidamente a un’ampia gamma di dati senza doverli cercare o scaricare da fonti esterne.\nValidità e Affidabilità: I dati forniti nei pacchetti R sono generalmente ben documentati e validati, il che li rende affidabili per analisi e apprendimento.",
    "crumbs": [
      "Syllabus",
      "Introduzione a `R`"
    ]
  },
  {
    "objectID": "IntroduzioneR.html#caricamento-dei-pacchetti",
    "href": "IntroduzioneR.html#caricamento-dei-pacchetti",
    "title": "R: Introduzione",
    "section": "Caricamento dei pacchetti",
    "text": "Caricamento dei pacchetti\nL’installazione rende disponibili i pacchetti sul proprio computer. Perché R possa utilizzare le funzionalità del pacchetto è necessario caricare i pacchetti utilizzando il comando library(). Ad esempio, per caricare il pacchetto Ecdat bisogna eseguire il seguente comando nella console R:\n\nlibrary(AER)\n\n\nI dataset di Ecdat\nPer avere un’idea dei dataset messi a disposizione da Ecdat possiamo utilizzare la funzione di help\n\nhelp(package=\"AER\")\n\nI dataset possono essere caricati nella sessione di R mediante il comando data(). Per esempio, il seguente comando\n\ndata(CASchools)\n\nrende disponibile il dataset Caschool. Il data set può essere richiamato semplicemente digitando il suo nome\n\nsummary(CASchools)\n\n   district            school                  county      grades   \n Length:420         Length:420         Sonoma     : 29   KK-06: 61  \n Class :character   Class :character   Kern       : 27   KK-08:359  \n Mode  :character   Mode  :character   Los Angeles: 27              \n                                       Tulare     : 24              \n                                       San Diego  : 21              \n                                       Santa Clara: 20              \n                                       (Other)    :272              \n    students          teachers          calworks          lunch       \n Min.   :   81.0   Min.   :   4.85   Min.   : 0.000   Min.   :  0.00  \n 1st Qu.:  379.0   1st Qu.:  19.66   1st Qu.: 4.395   1st Qu.: 23.28  \n Median :  950.5   Median :  48.56   Median :10.520   Median : 41.75  \n Mean   : 2628.8   Mean   : 129.07   Mean   :13.246   Mean   : 44.71  \n 3rd Qu.: 3008.0   3rd Qu.: 146.35   3rd Qu.:18.981   3rd Qu.: 66.86  \n Max.   :27176.0   Max.   :1429.00   Max.   :78.994   Max.   :100.00  \n                                                                      \n    computer       expenditure       income          english      \n Min.   :   0.0   Min.   :3926   Min.   : 5.335   Min.   : 0.000  \n 1st Qu.:  46.0   1st Qu.:4906   1st Qu.:10.639   1st Qu.: 1.941  \n Median : 117.5   Median :5215   Median :13.728   Median : 8.778  \n Mean   : 303.4   Mean   :5312   Mean   :15.317   Mean   :15.768  \n 3rd Qu.: 375.2   3rd Qu.:5601   3rd Qu.:17.629   3rd Qu.:22.970  \n Max.   :3324.0   Max.   :7712   Max.   :55.328   Max.   :85.540  \n                                                                  \n      read            math      \n Min.   :604.5   Min.   :605.4  \n 1st Qu.:640.4   1st Qu.:639.4  \n Median :655.8   Median :652.5  \n Mean   :655.0   Mean   :653.3  \n 3rd Qu.:668.7   3rd Qu.:665.9  \n Max.   :704.0   Max.   :709.5",
    "crumbs": [
      "Syllabus",
      "Introduzione a `R`"
    ]
  },
  {
    "objectID": "IntroduzioneR.html#il-sistema-di-help",
    "href": "IntroduzioneR.html#il-sistema-di-help",
    "title": "R: Introduzione",
    "section": "Il sistema di help",
    "text": "Il sistema di help\nIl sistema di help di R è un’importante risorsa per gli utenti che utilizzano questo software. Consente di accedere a informazioni dettagliate su tutte le funzioni e i pacchetti di R, nonché di comprendere meglio il funzionamento del linguaggio di programmazione R.\nOgni funzione in R ha la sua pagina di help alla quale si può accedere tramite la funzione help() o tramite il simbolo ? seguito dal nome della funzione della quale si vogliono ottenee inforrmazioni. Per esempio\n\nhelp(mean)\n\napre la pagina di help relativa alla funzione mean.\nLa pagina di help fornisce una descrizione della funzione, i suoi argomenti e tipologia dei valori che la funzione restituisce. La maggior parte delle funzioni in R hanno esempi di utilizzo nella loro pagina di help.\nPer ottenere aiuto sulle funzionalità di un pacchetto bisogna passare l’argomento packages seguito dal nome del pacchetto. Per esempio, il seguente comando mostra la pagina di help per il pacchetto ggplot2\n\nhelp(packages=\"ggplot2\")",
    "crumbs": [
      "Syllabus",
      "Introduzione a `R`"
    ]
  },
  {
    "objectID": "IntroduzioneR.html#primi-grafici-con-ggplot2",
    "href": "IntroduzioneR.html#primi-grafici-con-ggplot2",
    "title": "R: Introduzione",
    "section": "Primi grafici con ggplot2",
    "text": "Primi grafici con ggplot2\nI passi per ottenere un grafico con ggplot2 sono:\n\nInstallare e caricare il pacchetto ggplot2 utilizzando il comando install.packages(\"ggplot2\") seguito da library(ggplot2).\nCaricare i dati che si desidera visualizzare in un data frame.\nCreare un oggetto ggplot utilizzando la funzione ggplot(). Gli argomenti di questa funzione sono il data.frame e la funzione aes mediante la quale possono essere specificate le variabili che si desidera utilizzare per l’asse x e l’asse y.\nAggiungere i livelli e gli stili al grafico utilizzando una serie di geometrie come geom_point(), geom_line(), geom_bar(). Queste funzioni definiscono le modalità di rappresentazione dei dati nel grafico (ad esempio, con punti, linee, barre, ecc.).\nAggiungere etichette, titoli e altre personalizzazioni utilizzando funzioni come labs(), xlab(), ylab(), ggtitle() e altre funzioni di personalizzazione.\n\nEcco un esempio di codice di base per creare un grafico a dispersione utilizzando ggplot2:\n\nlibrary(ggplot2)\n# Caricare i dati\ndata(CASchools)\n## Creiamo le variabili\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following object is masked from 'package:car':\n\n    recode\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nCASchools &lt;- CASchools |&gt; mutate(str=students/teachers, testscr=(read+math)/2)\n\n# Creare l'oggetto ggplot\nscatterplot &lt;- ggplot(CASchools, aes(x = str, y = testscr))\n# Aggiungere i punti al grafico\nscatterplot &lt;- scatterplot + geom_point(col = \"darkgreen\")\n# Aggiungere etichette e titoli\nscatterplot &lt;- scatterplot +\n  labs(title = \"Grafico a dispersione - testscr/str\",\n      x = \"Rapporto studenti insegnanti\", y = \"Punteggi nei test\")\n# Visualizzare il grafico\nscatterplot\n\n\n\n\n\n\n\n\nQuesto è solo un esempio molto semplice, ma ggplot2 offre molte altre funzionalità per la creazione di grafici avanzati e personalizzati. Per esempio, possiamo cambiare il tema grafico usando theme_bw() che elimina i colori\n\nscatterplot &lt;- scatterplot + theme_bw()\nscatterplot\n\n\n\n\n\n\n\n\nPossiamo anche costruire grafici raggruppati per variabile. Per ottenere un grafico a dispersione per str e testscr per le due tipologie di scuole grades==\"KK-06\" egrades=“KK-08”`:\n\nscatterplot &lt;- scatterplot + facet_wrap(~grades)\nscatterplot\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nLa funzione facet_wrap() in ggplot2 è utilizzata per dividere i dati in sottoinsiemi basati su una variabile e creare una griglia di grafici separati, ognuno dei quali visualizza i dati per uno dei livelli della variabile.\nLa sintassi di base di facet_wrap() è la seguente:\n\nfacet_wrap(~variable, nrow = x, ncol = y)\n\nDove variable è la variabile che si vuole utilizzare per suddividere i dati in sottoinsiemi (nell precedente esempio abbiamo utilizzato grspan) e nrow e ncol specificano il numero di righe e colonne della griglia di grafici che si desidera creare.\n\n\nPossiamo anche aggiungere le rette di regression a ciascun grafico usando la geometria geom_smooth\n\nscatterplot + geom_smooth(method=\"lm\", col = \"darkred\")\n\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "Syllabus",
      "Introduzione a `R`"
    ]
  },
  {
    "objectID": "IntroduzioneR.html#prime-manipolazione-di-dati-usando-dplyr",
    "href": "IntroduzioneR.html#prime-manipolazione-di-dati-usando-dplyr",
    "title": "R: Introduzione",
    "section": "Prime manipolazione di dati usando dplyr",
    "text": "Prime manipolazione di dati usando dplyr\n\nlibrary(dplyr)\n\nCalcoliamo la media e la standard deviation di testscr\n\nCASchools |&gt;\n  summarize(m = mean(testscr), s = sd(testscr))\n\n         m        s\n1 654.1565 19.05335\n\n\nPossiamo anche calcolare la media, la deviazione standard e il numero di osservazioni per il gruppo di scuole che hanno un rapporto studenti insegnanti minore di 20, \\(str&lt;20\\) e il gruppo di scuole che hanno un rapporto maggiore o uguale a venti (\\(str&gt;20\\)) usando la funzione group_by seguita dall’indicazione del gruppo (nel nostro caso str&lt;20):\n\ndf_1 &lt;- CASchools |&gt;\n  group_by(str&lt;20) |&gt;\n  summarize(m = mean(testscr),\n            s = sd(testscr),\n            n = n())\n\nIl risultato delle manipolazioni è un tibble — un sorta di data.frame più flessibile definito nel pacchetto dplyr.\ndf_1 può essere a sua volta utilizzato per altri calcoli e si comporta in tutto e per tutto come un normale data.frame.\n\ndf_1\n\n# A tibble: 2 × 4\n  `str &lt; 20`     m     s     n\n  &lt;lgl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 FALSE       650.  17.9   181\n2 TRUE        657.  19.4   239\n\n\n\n\n\n\n\n\nNote\n\n\n\nI tibble sono una versione migliorata dei tradizionali data.frame, progettata per semplificare l’analisi dei dati in R. Tuttavia, i data.frame sono ancora molto utilizzati e sono l’oggetto dati di base per molti pacchetti in R. Fortunatamente, molti dei comandi di R disegnati per i data.frame funzionano anche per i tibble.\nLe maggiori differenze fra i tibble e i data.frame sono:\n\nTipo di output: Il metodo di visualizzazione di un tibble è più compatto e leggibile rispetto a quello di un data.frame.\nComportamento dei nomi delle variabili: in un tibble, i nomi delle variabili sono sempre conservati e non vengono mai modificati (ad esempio, i nomi delle variabili non vengono convertiti in stringhe). In un data.frame, i nomi delle variabili possono essere modificati o convertiti in stringhe.\nComportamento di default dei dati mancanti: in un tibble, i dati mancanti vengono visualizzati in modo più chiaro rispetto a un data.frame.\nComportamento della subsetting: in un tibble, il subsetting (o l’estrazione di sottoinsiemi di dati) è più rigoroso rispetto a un data.frame, in quanto conserva sempre la classe del tibble, anche se viene restituito un singolo valore.\nFunzioni dplyr: un tibble è progettato per essere compatibile con le funzioni del pacchetto dplyr, che sono utilizzate per manipolare i dati.\n\n\n\nAbbiamo visto che una stima della differenza dei valori attesi fra i due gruppi \\[\n\\Delta = E(testscr|str&lt;20) - E(testscr|str\\geqslant20)\n\\] può essere ottenuta calcolando la differenza delle medie campionarie dei due gruppi e può essere ottenuta usando le informazioni in df_1:\n\n## Differenza delle medie campionarie\ndf_1$m[2]-df_1$m[1]\n\n[1] 7.169435\n\n\ne, quindi, \\[\n\\hat{\\Delta} = \\overline{testscr}_{str&lt;20} - \\overline{testscr}_{str\\geqslant20} = 7.1694355.\n\\]\nCon le stesse informazioni è possibile calcolare l’intervallo di confidenza al 95% per \\(\\Delta\\) che è dato da \\[\n\\hat{\\Delta}\\pm1.96\\times\\sqrt{\\frac{s_{str&lt;20}^{2}}{n_{str&lt;20}}+\\frac{s_{str\\geqslant20}^{2}}{n_{str\\geqslant20}}}.\n\\] Usando le informazioni contenute in df_1 otteniamo: \\[\n(3.5909173, 10.7479537)\n\\]",
    "crumbs": [
      "Syllabus",
      "Introduzione a `R`"
    ]
  },
  {
    "objectID": "IntroduzioneR.html#qualcosa-di-più-complicato",
    "href": "IntroduzioneR.html#qualcosa-di-più-complicato",
    "title": "R: Introduzione",
    "section": "Qualcosa di più complicato",
    "text": "Qualcosa di più complicato\nInvece di stimare la variazione del valore atteso rispetto alle due macro-categorie (\\(str&lt;20\\) e \\(str\\geqslant20\\)) possiamo provare a stimare il valore atteso condizionatamente a piccoli intervalli. Per esempio, possiamo voler stimare la seguente differenza \\[\nE(testscr|20.1 &lt; str \\leqslant 20.6) - E(testscr|20.6 &lt; str \\leqslant 21.1)\n\\] oppure \\[\nE(testscr|21.6 &lt; str \\leqslant 22) - E(testscr|22 &lt; str \\leqslant 22.5).\n\\]\nPer stimare queste quantità utilizzando i dati nel campion, è necessario calcolare la media campionaria per le scuole che hanno un \\(str\\) che appartiene a ciascun intervallo. Per costruire questi intervalli, possiamo utilizzare la funzione cut(). La funzione cut() è utilizzata per suddividere un vettore numerico in più intervalli.\n\n\n\n\n\n\nNote\n\n\n\nLa sintassi della funzione cut() è la seguente:\n\ncut(x, breaks,\n       labels = NULL,\n       include.lowest = FALSE,\n       right = TRUE,\n       dig.lab = 3, ...)\n\ndove:\n\nx è il vettore numerico da suddividere in bin\nbreaks è un vettore contenente i valori di taglio, ovvero i punti di separazione tra i bin. Questo può essere specificato in diversi modi, ad esempio tramite un numero intero che specifica il numero di bin desiderati o un vettore numerico che specifica i limiti di ogni bin.\nlabels è un vettore di etichette per ogni bin. Se non specificato, gli intervalli saranno etichettati in base ai loro limiti.\ninclude.lowest indica se includere o meno il valore più basso del vettore x nel primo bin. Il valore predefinito è FALSE.\nright indica se i bin devono essere chiusi a destra o a sinistra. Il valore predefinito è TRUE, ovvero i bin sono chiusi a destra.\ndig.lab è il numero di cifre decimali da utilizzare per le etichette, se specificato.\n... sono altri argomenti opzionali.\n\n\n\nEcco un esempio di utilizzo della funzione cut() per suddividere str in tre bin di uguale ampiezza:\n\nstr_cat3 &lt;- cut(CASchools$str, 3)\nsummary(str_cat3)\n\n  (14,17.9] (17.9,21.9] (21.9,25.8] \n         73         305          42 \n\n\nIn questo caso il comando summary produce una tavola di frequenza con il numero delle scuole in ciascuna delle tre categorie (14,17.9], (17.9,21.9], (21.9,25.8].\nPossiamo anche specificare i breaks in modo esplicito\n\nstr_cat3 &lt;- cut(CASchools$str, c(13,20, 21, 26))\nsummary(str_cat3)\n\n(13,20] (20,21] (21,26] \n    243      86      91 \n\n\nIn questo ultimo caso, gli intervalli sono (13,20], (20,21], (21,26].\n\n\n\n\n\n\nNote\n\n\n\nstr_cat3 e, in generale, l’output di cut è un oggetto di classe factor. Questo tipo di variabili sono utilizzate per rappresentare variabili categoriche o qualitative, ovvero variabili che possono assumere un numero limitato di categorie o livelli (come il numero di intervalli nel nostro questo caso). La funzione summary() restituisce una tavola di frequenza per questo tipo di variabili perchè non avrebbe senso calcolare media, mediana e le altre quantità che sono solitamente restituita da summary quando l’argomento è una variabile di tipo numeric.\n\n\n\nlibrary(knitr)\n\ndf_2 &lt;- CASchools |&gt;\n1  mutate(str_cat = cut(str, 25)) |&gt;\n2  group_by(str_cat) |&gt;\n3  summarize(m = mean(testscr), s = sd(testscr), n = n())\n\n4df_2 |&gt; kable()\n\n\n1\n\nla funzione cut per dividere str in 25 intervalli;\n\n2\n\ngroup_by suddivide Caschool in gruppi specificati da str_cat\n\n3\n\nsummarize calcola la media, la standard deviation e il numero di osservazioni per ciascun gruppo\n\n4\n\nkabble restituisce la tavole dei valori\n\n\n\n\n\n\n\nstr_cat\nm\ns\nn\n\n\n\n\n(14,14.5]\n646.0500\n14.778549\n2\n\n\n(14.5,14.9]\n681.0750\n20.117175\n2\n\n\n(14.9,15.4]\n669.0583\n27.490822\n6\n\n\n(15.4,15.9]\n666.4300\n16.397309\n5\n\n\n(15.9,16.4]\n657.4625\n31.451667\n4\n\n\n(16.4,16.8]\n656.4000\n22.941904\n12\n\n\n(16.8,17.3]\n655.1200\n19.810348\n10\n\n\n(17.3,17.8]\n661.8417\n21.060796\n24\n\n\n(17.8,18.2]\n660.9820\n21.377904\n25\n\n\n(18.2,18.7]\n655.2611\n19.005517\n27\n\n\n(18.7,19.2]\n659.1279\n17.430919\n43\n\n\n(19.2,19.7]\n654.1674\n18.195812\n46\n\n\n(19.7,20.1]\n652.2074\n16.740562\n54\n\n\n(20.1,20.6]\n652.5538\n18.840602\n39\n\n\n(20.6,21.1]\n650.9581\n18.103746\n37\n\n\n(21.1,21.6]\n645.9219\n17.020844\n32\n\n\n(21.6,22]\n651.4000\n19.099851\n15\n\n\n(22,22.5]\n650.9208\n14.543983\n12\n\n\n(22.5,23]\n639.0750\n16.285656\n10\n\n\n(23,23.4]\n643.8833\n17.057683\n6\n\n\n(23.4,23.9]\n658.9750\n7.672113\n2\n\n\n(23.9,24.4]\n676.8500\nNA\n1\n\n\n(24.4,24.9]\n651.2000\nNA\n1\n\n\n(24.9,25.3]\n642.3833\n23.492246\n3\n\n\n(25.3,25.8]\n659.5750\n7.601398\n2\n\n\n\n\n\nAlcuni degli errori standard sono uguali a NA perché in almeno uno dei gruppi il numero di osservazioni è inferiore a 2, il numero minimo per poter calcolare questa misura dispersione.\nManipolando df_2, possiamo calcolare le differenze nelle media campionarie fra due intervalli adiacenti.\n\n1df_3 &lt;- df_2 |&gt; mutate(Delta_str = paste0(str_cat, \"-\", lag(str_cat)),\n2               Delta_testscr = m - lag(m),\n3               stderr = sqrt(s^2/n + lag(s^2/n))) |&gt;\n4               select(Delta_str, Delta_testscr, stderr)\n\n5kable(df_3)\n\n\n1\n\nla variabile Delta_str è uguale alla differenza dei due intervalli ottenuta incollando paste0 l’intervallo di ciascuna riga con quella precedente (la funzione lag(m) associa il valore di m della riga precedente). Questa variabile è utile per annotare l’asse delle ascisse del grafico che produrremo prodotto in seguito.\n\n2\n\nDelta_str contiene la differenze delle medie campionari di due intervalli successivi. Queste differenze sono calcolate usando m - lag(m) e quindi Delta_testscr è uguale a m, la media per l’intervallo, meno il valore della media per l’intervallo che preceda la riga in considerazione (lag(m))\n\n3\n\nstderr è l’errore standard della differenza delle medie in ciascun intervallo che è uguale a\n\n4\n\nselezioniamo le variabili che ci servono per il grafico mediante la funzione select()\n\n5\n\nkable(df_3) formatta il data.frame come una tavolo html. La funzione kable è contenuta nel pacchetto knitr.\n\n\n\n\n\n\n\nDelta_str\nDelta_testscr\nstderr\n\n\n\n\n(14,14.5]-NA\nNA\nNA\n\n\n(14.5,14.9]-(14,14.5]\n35.0250092\n17.650867\n\n\n(14.9,15.4]-(14.5,14.9]\n-12.0166626\n18.119269\n\n\n(15.4,15.9]-(14.9,15.4]\n-2.6283356\n13.406413\n\n\n(15.9,16.4]-(15.4,15.9]\n-8.9674973\n17.351547\n\n\n(16.4,16.8]-(15.9,16.4]\n-1.0625102\n17.063492\n\n\n(16.8,17.3]-(16.4,16.8]\n-1.2799901\n9.116244\n\n\n(17.3,17.8]-(16.8,17.3]\n6.7216634\n7.597798\n\n\n(17.8,18.2]-(17.3,17.8]\n-0.8596639\n6.063179\n\n\n(18.2,18.7]-(17.8,18.2]\n-5.7208867\n5.626609\n\n\n(18.7,19.2]-(18.2,18.7]\n3.8667929\n4.521516\n\n\n(19.2,19.7]-(18.7,19.2]\n-4.9605187\n3.776709\n\n\n(19.7,20.1]-(19.2,19.7]\n-1.9599817\n3.519560\n\n\n(20.1,20.6]-(19.7,20.1]\n0.3464398\n3.780410\n\n\n(20.6,21.1]-(20.1,20.6]\n-1.5957329\n4.237893\n\n\n(21.1,21.6]-(20.6,21.1]\n-5.0362355\n4.232186\n\n\n(21.6,22]-(21.1,21.6]\n5.4781262\n5.776997\n\n\n(22,22.5]-(21.6,22]\n-0.4791743\n6.476694\n\n\n(22.5,23]-(22,22.5]\n-11.8458328\n6.644512\n\n\n(23,23.4]-(22.5,23]\n4.8083344\n8.661198\n\n\n(23.4,23.9]-(23,23.4]\n15.0916901\n8.827500\n\n\n(23.9,24.4]-(23.4,23.9]\n17.8749847\nNA\n\n\n(24.4,24.9]-(23.9,24.4]\n-25.6499939\nNA\n\n\n(24.9,25.3]-(24.4,24.9]\n-8.8166707\nNA\n\n\n(25.3,25.8]-(24.9,25.3]\n17.1916402\n14.589465\n\n\n\n\n\nSi noti che per prima riga la differenza delle medie è NA. Il motivo è che non c’è un intervallo con valori più piccoli di per poter calcolare la differenza. La seconda riga ci dice che \\[\n\\overline{testscr}_{str \\in (14.5,14.9]} - \\overline{testscr}_{str \\in (14,14.5]}  = 35.0250092,\n\\] e che quindi scuole con classi con \\((14.5,14.9]\\) studenti per insegnante hanno punteggi più alti di circa 35.0250092 punti rispetto a quelle con \\(str\\in (14,14.5]\\). Questo valore positivo (classi più piccole hanno test score più bassi) e molto grande (quasi due volte la deviazione standard dei punteggi in tutto il campione) è dovuto al fatto che stiamo stimando la differenza dei valori attesi usando soltanto 4 scuole. Un numero troppo esigue per aspettarci che la stima sia in qualche modo “vicina” a quella che potremmo stimare se avessimo a disposizione i dati nel campione.\nLa terza riga ci dice che \\[\n\\overline{testscr}_{str \\in (14.9,15.4]} - \\overline{testscr}_{str \\in (14.5,14.9]}  = -12.0166626,\n\\] e che quindi scuole con \\(str\\in (14.9,15.4]\\) hanno punteggi più alti di circa -12.0166626 punti rispetto a quelle con \\(str\\in (14.5,14.9]\\). E così via per le altre righe.\nE’ molto probabile che tutte le stime e non soltanto quelle della prima riga siano particolarmente imprecise visto che sono tutte basate su un numero esiguo di osservazioni. Per quantificare la loro precisione, o la loro imprecisione, possiamo costruire l’intervallo di confidenza (al 95%) per ciascun valore dell’intervallo di \\(str\\). L’intervallo di confidenza al 95% è:\n\nc(df_3$Delta_testscr - 1.96 * df_3$stderr,\n  df_3$Delta_testscr + 1.96 * df_3$stderr)\n\ndove stderr è l’errore standard della differenza delle media che è stato calcolato nel precdedente blocco di codice.\nPer aggiungere l’intervallo di confidenza a df_3 possiamo usare dplyr e la funzione mutate:\n\ndf_3 &lt;- df_3 |&gt;\n1  mutate(ci_sx = Delta_testscr - 1.96 * stderr,\n2         ci_dx = Delta_testscr + 1.96 * stderr)\n\nkable(df_3)\n\n\n1\n\nl’estremo sinistro dell’intervallo di confidenza;\n\n2\n\nl’estremo destro dell’intervallo di confidenza;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDelta_str\nDelta_testscr\nstderr\nci_sx\nci_dx\n\n\n\n\n(14,14.5]-NA\nNA\nNA\nNA\nNA\n\n\n(14.5,14.9]-(14,14.5]\n35.0250092\n17.650867\n0.4293091\n69.620709\n\n\n(14.9,15.4]-(14.5,14.9]\n-12.0166626\n18.119269\n-47.5304300\n23.497105\n\n\n(15.4,15.9]-(14.9,15.4]\n-2.6283356\n13.406413\n-28.9049041\n23.648233\n\n\n(15.9,16.4]-(15.4,15.9]\n-8.9674973\n17.351547\n-42.9765294\n25.041535\n\n\n(16.4,16.8]-(15.9,16.4]\n-1.0625102\n17.063492\n-34.5069539\n32.381934\n\n\n(16.8,17.3]-(16.4,16.8]\n-1.2799901\n9.116244\n-19.1478280\n16.587848\n\n\n(17.3,17.8]-(16.8,17.3]\n6.7216634\n7.597798\n-8.1700207\n21.613347\n\n\n(17.8,18.2]-(17.3,17.8]\n-0.8596639\n6.063179\n-12.7434947\n11.024167\n\n\n(18.2,18.7]-(17.8,18.2]\n-5.7208867\n5.626609\n-16.7490402\n5.307267\n\n\n(18.7,19.2]-(18.2,18.7]\n3.8667929\n4.521516\n-4.9953795\n12.728965\n\n\n(19.2,19.7]-(18.7,19.2]\n-4.9605187\n3.776709\n-12.3628686\n2.441831\n\n\n(19.7,20.1]-(19.2,19.7]\n-1.9599817\n3.519560\n-8.8583199\n4.938356\n\n\n(20.1,20.6]-(19.7,20.1]\n0.3464398\n3.780410\n-7.0631636\n7.756043\n\n\n(20.6,21.1]-(20.1,20.6]\n-1.5957329\n4.237893\n-9.9020039\n6.710538\n\n\n(21.1,21.6]-(20.6,21.1]\n-5.0362355\n4.232186\n-13.3313205\n3.258850\n\n\n(21.6,22]-(21.1,21.6]\n5.4781262\n5.776997\n-5.8447884\n16.801041\n\n\n(22,22.5]-(21.6,22]\n-0.4791743\n6.476694\n-13.1734956\n12.215147\n\n\n(22.5,23]-(22,22.5]\n-11.8458328\n6.644512\n-24.8690769\n1.177411\n\n\n(23,23.4]-(22.5,23]\n4.8083344\n8.661198\n-12.1676134\n21.784282\n\n\n(23.4,23.9]-(23,23.4]\n15.0916901\n8.827500\n-2.2102091\n32.393589\n\n\n(23.9,24.4]-(23.4,23.9]\n17.8749847\nNA\nNA\nNA\n\n\n(24.4,24.9]-(23.9,24.4]\n-25.6499939\nNA\nNA\nNA\n\n\n(24.9,25.3]-(24.4,24.9]\n-8.8166707\nNA\nNA\nNA\n\n\n(25.3,25.8]-(24.9,25.3]\n17.1916402\n14.589465\n-11.4037118\n45.786992\n\n\n\n\n\nCome si vede chiaramente dall’analisi della tabella, tutti gli intervalli di confidenza sono molto ampi. Come preannunciato, i dati a nostra disposizione non sono abbastanza informativi per poter stimare tutte le differenze su intervalli così poco numerosi. Anche nel caso in cui considerassimo la differenza delle medie in scuole con \\(str\\in(18.7,19.2]\\) (27 scuole) e scuole con \\(str\\in (18.2,18.7]\\) (47 scuole), l’intervallo di confidenza è molto ampio: \\((-4.9953795, 12.7289653)\\). Un intervallo di confidenza così ampio implica che non possiamo neanche quantificare con l’appropriata confidenza il segno della differenza che potrebbe essere -12 o 2.\nLa rappresentazione grafica delle informazioni contenute in una tavole facilita spesso la comprensione dei risultati.\n\n1ggplot(df_3, aes(x=Delta_str,y=Delta_testscr)) +\n2  geom_pointrange(aes(ymin=ci_sx, ymax=ci_dx)) +\n3  geom_hline(yintercept = 0, col = \"darkred\") +\n  theme_bw() +\n  xlab(\"Intervalli str\") + ylab(\"Delta Media testscr\") +\n4  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n1\n\nsull’ascissa abbiamo la differenza degli intervalli, sull’ordinata la differenza delle medie;\n\n2\n\nla geometria utilizzata è geom_pointrange, che “plotta” la differenza delle medie (il punto) e l’intervallo di confidenza al 95% definito da ((ci_sx, ci_dx)) e rappresentato dalle linee che si estendono verticalmente.\n\n3\n\ngeom_hline(yintercept=0, col = \"darkred\") produce una riga orizzonate di colore rosso scuro\n\n4\n\nle etichette dell’asse della x sono ruotate di 90 gradi per favorire la loro leggibilità.\n\n\n\n\n\n\n\n\n\n\n\nIl grafico mostra che la stima di molte delle differenze è negativa e che gli intervalli di confidenza (eccettuati i tre casi in cui non è possibile costruire l’intervallo di confidenza) sono troppo ampi per poter concludere che il valore della differenza nella popolazione sia negativa",
    "crumbs": [
      "Syllabus",
      "Introduzione a `R`"
    ]
  },
  {
    "objectID": "materiale.html",
    "href": "materiale.html",
    "title": "Materiale didattico",
    "section": "",
    "text": "Questa pagina contiene i collegamenti al materiale didattico del corso. (Nella sidebar qui a sinistra)\nIl materiale didattico è organizzato per lezione e a ciscuna lezione è associato\n\nle slide \ndispense R in formato html \nil codice R in formato qmd in formato Rmd \nletture consigliate \n\nI collegamenti (a sinistra) si attiveranno in sincrono con la progressione del corso.\nPer scaricare le slides bisogna essersi registrati al sito moodle del corso"
  }
]