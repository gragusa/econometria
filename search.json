[
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Prof. Giuseppe Ragusa\n   Sapienza, Università di Roma\n   Dipartimento di Economia e Diritto\n   Prof. Giuseppe Ragusa\n   giuseppe.ragusa@uniroma1.it\n   Ricevimento\n\n\n\n\n\n   Lunedì (L) e Martedì (M)\n   19 febbraio, 2024 - 1 giugno 2024\n   (L) 10:00–12:00 (M) 14:00-16:00\n   (L) Aula 10 (M) Aula 8b"
  },
  {
    "objectID": "syllabus.html#descrizione-del-corso",
    "href": "syllabus.html#descrizione-del-corso",
    "title": "Syllabus",
    "section": "Descrizione del corso",
    "text": "Descrizione del corso\nEconometria (1018133) offre agli studenti un’introduzione pratica all’econometria, strumento fondamentale per comprendere e analizzare l’economia da un punto di vista empirico. Attraverso un approccio equilibrato tra teoria e pratica, gli studenti esploreranno i concetti fondamentali e gli strumenti empirici necessari per comprendere le sfide relative all’impiego di tecniche quantitative in microeconomia, macroeconomia e finanza.\nL’enfasi è sulla comprensione intuitiva e non sulle formalità matematiche questo corso ti fornirà le competenze necessarie per affrontare sfide analitiche complesse con sicurezza e competenza."
  },
  {
    "objectID": "syllabus.html#obiettivi-del-corso",
    "href": "syllabus.html#obiettivi-del-corso",
    "title": "Syllabus",
    "section": "Obiettivi del corso",
    "text": "Obiettivi del corso\nAlla conclusione del corso, gli studenti saranno in grado di condurre analisi empiriche in modo indipendente e interpretarne i risultati, valutando attentamente l’adeguatezza delle assunzioni necessarie per garantire la corretta interpretazione dei risultati.\nIn particolare, gli studenti saranno in grado di:\n\nComprendere la logica e la filosofia dei modelli econometrici presentati, valutando la loro capacità di cogliere relazioni causali o di fornire predizioni di qualità.\nValutare criticamente le assunzioni fondamentali sottostanti ai modelli econometrici, analizzandone l’impatto sulla validità dei risultati.\nUtilizzare rigorose misure statistiche per valutare la qualità delle predizioni generate dai modelli econometrici.\nApplicare efficacemente il software R per manipolare dati, produrre visualizzazioni informative e stimare i parametri dei modelli econometrici utilizzando dati reali, sviluppando così competenze pratiche nel campo dell’analisi dei dati e della modellistica economica."
  },
  {
    "objectID": "syllabus.html#libro-di-testo",
    "href": "syllabus.html#libro-di-testo",
    "title": "Syllabus",
    "section": "Libro di testo",
    "text": "Libro di testo\n\n\n\n\n\nIl libro di testo utilizzato in questo corso è:\nStock, J. H. e Watson, M.W: Introduzione all’econometria, Pearson Italia, 2020. ISBN: 8891906190.\nDurante il corso, gli studenti avranno accesso a slides didattiche che forniranno una guida dettagliata attraverso i concetti e gli argomenti trattati. Queste risorse supplementari saranno fondamentali per consolidare la comprensione dei materiali di studio e facilitare il processo di apprendimento."
  },
  {
    "objectID": "syllabus.html#software",
    "href": "syllabus.html#software",
    "title": "Syllabus",
    "section": "Software",
    "text": "Software\n\n\n\n\n\nCome già accennato, il corso prevede l’utilizzo di R, uno dei linguaggi di programmazione statistico/econometrico più diffusi e potenti.\nR ha una licenza open-source (GNU GPL), è compatibile con i maggiori sistemi operativi (GNU/Linux, macOS, Microsoft Windows)."
  },
  {
    "objectID": "syllabus.html#orari-di-ricevimento",
    "href": "syllabus.html#orari-di-ricevimento",
    "title": "Syllabus",
    "section": "Orari di ricevimento",
    "text": "Orari di ricevimento\nGli orari di ricevimento sono:\n\n\n\nGiorno\nOrario\n\n\n\n\nLunedì\n9:00-10:00\n\n\nMartedì\n9:00-10:00\n\n\n\nE’ obbligatorio prenotare un appuntamento a questo link."
  },
  {
    "objectID": "syllabus.html#modalità-di-valutazione",
    "href": "syllabus.html#modalità-di-valutazione",
    "title": "Syllabus",
    "section": "Modalità di valutazione",
    "text": "Modalità di valutazione\nL’esame di Econometria comprende due fasi: una prova scritta e una prova orale, entrambe obbligatorie.\nLa prova scritta valuterà la capacità degli studenti di comprendere e interpretare le stime dei modelli econometrici introdotti durante il corso e di applicarli in contesti specifici.\nLa prova orale è volta ad accertare in maniera piu’ articolata le conoscenza acquisite nel corso.\nL’ammissione alla prova orale è garantita agli studenti che abbiano superato con sufficienza la prova scritta."
  },
  {
    "objectID": "panel_app.html",
    "href": "panel_app.html",
    "title": "Panel data",
    "section": "",
    "text": "Il modello \\[\ny_{it} = \\alpha_i + \\lambda_t + \\beta_1X_{1it} + \\dots + \\beta_k X_{kit} + u_{it},\n\\] può essere stimato tramite il metodo dei minimi quadrati ordinari (OLS), includendo le dummy per ciascuno stato e per ciascun periodo. Alternativamente, possiamo stimare il modello tramite OLS dopo che le variabili sono state trasformate mediante la trasformazione within.\nPer ottenere le stime dei coefficienti in entrambi gli approcci, che ricordiamo essere numericamente equivalenti, è possibile utilizzare il pacchetto fixest.\nUtilizziamo i dati nel dataset Fatility.\n\nlibrary(Ecdat)\ndata(\"Fatality\")\n\nEcco la traduzione in italiano del testo fornito:\nFatality consiste di 336 osservazioni su 10 variabili. Queste variabili riguardano la mortalità stradale, le tasse sull’alcol, e le leggi sulla guida in stato di ebbrezza in 48 stati degli Stati Uniti dal 1982 al 1988. Si noti che state è una variabile che prende 48 valori distinti (uno per ciascuno dei 48 stati contigui federali degli USA). Anche year prende 7 valori distinti che identificando il periodo temporale in cui è stata fatta l’osservazione. Questo ci dà un totale di 7×48=336 osservazioni. Poiché tutte le variabili sono osservate per tutte le entità e in tutti i periodi di tempo, il pannello è bilanciato. Se ci fossero dati mancanti per almeno un’entità in almeno un periodo di tempo, chiameremmo il pannello non bilanciato.\nLe variabili contenute nel dataset Fatality sono:\n\n\n\nVariabile\nDescrizione\n\n\n\n\nstate\nCodice identificativo dello stato\n\n\nyear\nAnno\n\n\nmrall\nTasso di mortalità stradale (morti per 10.000)\n\n\nbeertax\nTassa su una cassa di birra\n\n\nmlda\nEtà minima legale per il consumo di alcol\n\n\njaild\nPresenza di pene detentive obbligatorie?\n\n\ncomserd\nObbligatorietà del servizio comunitario?\n\n\nvmiles\nMiglia medie percorse per conducente\n\n\nunrate\nTasso di disoccupazione\n\n\nperinc\nReddito personale per capita",
    "crumbs": [
      "Syllabus",
      "R",
      "Panel data"
    ]
  },
  {
    "objectID": "panel_app.html#dati-panel",
    "href": "panel_app.html#dati-panel",
    "title": "Panel data",
    "section": "",
    "text": "Il modello \\[\ny_{it} = \\alpha_i + \\lambda_t + \\beta_1X_{1it} + \\dots + \\beta_k X_{kit} + u_{it},\n\\] può essere stimato tramite il metodo dei minimi quadrati ordinari (OLS), includendo le dummy per ciascuno stato e per ciascun periodo. Alternativamente, possiamo stimare il modello tramite OLS dopo che le variabili sono state trasformate mediante la trasformazione within.\nPer ottenere le stime dei coefficienti in entrambi gli approcci, che ricordiamo essere numericamente equivalenti, è possibile utilizzare il pacchetto fixest.\nUtilizziamo i dati nel dataset Fatility.\n\nlibrary(Ecdat)\ndata(\"Fatality\")\n\nEcco la traduzione in italiano del testo fornito:\nFatality consiste di 336 osservazioni su 10 variabili. Queste variabili riguardano la mortalità stradale, le tasse sull’alcol, e le leggi sulla guida in stato di ebbrezza in 48 stati degli Stati Uniti dal 1982 al 1988. Si noti che state è una variabile che prende 48 valori distinti (uno per ciascuno dei 48 stati contigui federali degli USA). Anche year prende 7 valori distinti che identificando il periodo temporale in cui è stata fatta l’osservazione. Questo ci dà un totale di 7×48=336 osservazioni. Poiché tutte le variabili sono osservate per tutte le entità e in tutti i periodi di tempo, il pannello è bilanciato. Se ci fossero dati mancanti per almeno un’entità in almeno un periodo di tempo, chiameremmo il pannello non bilanciato.\nLe variabili contenute nel dataset Fatality sono:\n\n\n\nVariabile\nDescrizione\n\n\n\n\nstate\nCodice identificativo dello stato\n\n\nyear\nAnno\n\n\nmrall\nTasso di mortalità stradale (morti per 10.000)\n\n\nbeertax\nTassa su una cassa di birra\n\n\nmlda\nEtà minima legale per il consumo di alcol\n\n\njaild\nPresenza di pene detentive obbligatorie?\n\n\ncomserd\nObbligatorietà del servizio comunitario?\n\n\nvmiles\nMiglia medie percorse per conducente\n\n\nunrate\nTasso di disoccupazione\n\n\nperinc\nReddito personale per capita",
    "crumbs": [
      "Syllabus",
      "R",
      "Panel data"
    ]
  },
  {
    "objectID": "panel_app.html#modello-senza-effetti-fissi-temporali",
    "href": "panel_app.html#modello-senza-effetti-fissi-temporali",
    "title": "Panel data",
    "section": "Modello senza effetti fissi temporali",
    "text": "Modello senza effetti fissi temporali\nIl primo modello che consideriamo è \\[\nmrall_{it} = \\alpha_i + \\beta_1beertax_{it} + u_{it}\n\\]\n\nlibrary(ggplot2)\nggplot(Fatality, aes(y=mrall, x = beertax)) +\n  geom_point(aes(col=factor(state))) + \n  geom_smooth(method='lm', col = \"black\") +\n  geom_smooth(aes(col=factor(state)), method='lm', se = FALSE) +\n  theme_minimal() + \n  theme(legend.position = 'none')\n\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\nFigure 1 esplora la relazione tra la tassa sulla birra (beertax) e il tasso di mortalità stradale (mrall), con un’attenzione particolare alle differenze tra stati. Nel grafico sono mostrate le rette di regressione per ciascuno stato (colori distinti per i punti e per le rette di regressione indicano uno stato). Come si vede, molte delle rette hanno un’inclinazione negativa. Comunque, se considerassimo un’unica regressione otterremo un coefficiente positivo come indicato dalla retta di regressione di colore nero. Tenere conto degli effetti fissi, cioè di \\(\\alpha_i\\), permetteremo alle singolo rette di regressione di avere intercette distinte.\n\nlibrary(fixest)\npd0 &lt;- feols(mrall~beertax, data=Fatality, vcov = \"hetero\")\npd1 &lt;- feols(mrall~beertax|state, data=Fatality, vcov = \"hetero\")\npd2 &lt;- feols(mrall~beertax|state, data=Fatality, cluster = ~state)\n\n\n\n\nIl coefficiente di BeerTax, \\(\\hat{\\beta}_1\\), è negativo e statisticamente significativo. L’interpretazione è che la riduzione stimata delle fatalità stradali dovuta a un aumento di $1 nella tassa sulla birra è di 0,66 per 10000 persone o, di 66 persone ogni milione di abitanti.\nSebbene l’inclusione degli effetti fissi statali elimini il rischio di una distorsione dovuta a fattori omessi che variano tra gli stati ma non nel tempo, è possibile che ci siano altre variabili omesse che variano nel tempo ma non fra stati. Possiamo tenere conto di queste variabili aggiungendo gli effetti temporali.\n\nlibrary(fixest)\npd3 &lt;- feols(mrall~beertax|state+year, data=Fatality, vcov = \"hetero\")\npd4 &lt;- feols(mrall~beertax|state+year, data=Fatality, cluster = ~state)\n\n\n\n\nIl coefficiente stimato in un modello con gli effetti fissi per anno è -0.66. È molto simile al coefficiente stimato per il modello di regressione che include solo gli effetti fissi dell’entità, ma adesso è stimato con minore precisione ed è statisticamente significativo al 10% quando usiamo gli errori standard che tengono conto di potenziale correlazione temporale nei residui (cluster(year)).\nPossiamo concludere che la relazione stimata tra le fatalità stradali e la tassa sulla birra non è influenzata da variabili omesse a causa di fattori che sono costanti nel tempo o tra gli stati.\nMa ci sono ancora due fonti di distorsione dovuta a variabili omesse che non sono state considerate da tutti i modelli usati: le condizioni economiche e le leggi sulla guida. I dati a nostra disposizione includono informazioni specifiche per stato sull’età legale per bere (mlda), le pene (jaild, comserd) e vari indicatori economici come il tasso di disoccupazione (unrate) e il reddito pro capite (perinc). Possiamo utilizzare queste covariate per estendere l’analisi precedente.\nIl modello che consideriamo adesso è\n\\[\n\\begin{aligned}\nmrall_{it} = \\alpha_i &+ \\beta_1 beertax_{it} + \\beta_2 unrate_{it} + \\beta_3 \\log(perinc_{it}) + \\beta_4 mlda_{it} \\\\\n&+ \\beta_5 comserd_{it} + \\beta_6 jaild_{it} + u_{it}\n\\end{aligned}\n\\tag{1}\\]\nStimiamo il modello Equation 1 includendo una variabile dummy per ciascuno stato (tranne uno per evitare multicollinearità), utilizzando feols e aggiungendo factor(state) alla formula:\n\nlm1_dummy &lt;- feols(mrall ~ beertax + unrate + log(perinc) + mlda + comserd + jaild \n                   + factor(state), data=Fatality, vcov = \"hetero\")\nlm1_dummy\n\nOLS estimation, Dep. Var.: mrall\nObservations: 336 \nStandard-errors: Heteroskedasticity-robust \n                Estimate Std. Error   t value Pr(&gt;|t|)    \n(Intercept)    -2.239669   3.732728 -0.600009 0.548982    \nbeertax        -0.359256   0.221616 -1.621075 0.106119    \nunrate         -0.019057   0.009784 -1.947822 0.052428 .  \nlog(perinc)     0.662102   0.385591  1.717111 0.087057 .  \nmlda           -0.037538   0.019161 -1.959105 0.051086 .  \ncomserdyes     -0.019369   0.118064 -0.164052 0.869808    \njaildyes       -0.019841   0.032254 -0.615143 0.538956    \nfactor(state)4 -0.309122   0.349763 -0.883802 0.377556    \n... 46 coefficients remaining (display them with summary() or use argument n)\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.167474   Adj. R2: 0.897213\n\n\nAlternativamente, possiamo applicare la trasformazione within, ovvero eseguire la regressione sulle variabili trasformate in deviazione dalla media temporale di ciascuna variabile, aggiungendo |state alla fine della formula:\n\nlm_fe &lt;- feols(mrall ~ beertax + unrate + log(perinc) + mlda + comserd \n               + jaild | state, data=Fatality)\nlm_fe\n\nOLS estimation, Dep. Var.: mrall\nObservations: 336 \nFixed-effects: state: 48\nStandard-errors: Clustered (state) \n             Estimate Std. Error   t value Pr(&gt;|t|)    \nbeertax     -0.359256   0.294458 -1.220058 0.228530    \nunrate      -0.019057   0.012734 -1.496547 0.141197    \nlog(perinc)  0.662102   0.547510  1.209296 0.232597    \nmlda        -0.037538   0.025577 -1.467660 0.148857    \ncomserdyes  -0.019369   0.123518 -0.156807 0.876068    \njaildyes    -0.019841   0.007608 -2.607756 0.012178 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.167474     Adj. R2: 0.897213\n                 Within R2: 0.126181\n\n\nI coefficienti stimati in lm_dummy sono identici a quelli in lm_fe, tuttavia gli errori standard differiscono. In lm_fe, feols utilizza automaticamente errori standard clusterizzati per stato.\n\nlm_dummy_cluster &lt;- feols(mrall ~ beertax + unrate + log(perinc) + mlda + comserd \n                          + jaild + factor(state), data=Fatality, cluster=\"state\")\nlm_dummy_cluster\n\nOLS estimation, Dep. Var.: mrall\nObservations: 336 \nStandard-errors: Clustered (state) \n                Estimate Std. Error   t value Pr(&gt;|t|)    \n(Intercept)    -2.239669   5.727427 -0.391043 0.697533    \nbeertax        -0.359256   0.318051 -1.129554 0.264396    \nunrate         -0.019057   0.013754 -1.385533 0.172430    \nlog(perinc)     0.662102   0.591379  1.119591 0.268577    \nmlda           -0.037538   0.027626 -1.358789 0.180699    \ncomserdyes     -0.019369   0.133415 -0.145175 0.885193    \njaildyes       -0.019841   0.008218 -2.414313 0.019712 *  \nfactor(state)4 -0.309122   0.466877 -0.662105 0.511138    \n... 46 coefficients remaining (display them with summary() or use argument n)\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.167474   Adj. R2: 0.897213\n\n\nGli errori standard in lm_dummy_cluster e lm_fe presentano lievi differenze dovute alla gestione diversa dei gradi di libertà nei due metodi.",
    "crumbs": [
      "Syllabus",
      "R",
      "Panel data"
    ]
  },
  {
    "objectID": "panel_app.html#aggiungere-effetti-fissi-temporali",
    "href": "panel_app.html#aggiungere-effetti-fissi-temporali",
    "title": "Panel data",
    "section": "Aggiungere effetti fissi temporali",
    "text": "Aggiungere effetti fissi temporali\nÈ possibile includere effetti temporali aggiungendo year alla specificazione di feols:\n\nlm_fe &lt;- feols(mrall ~ beertax + unrate + log(perinc) + mlda + comserd \n               + jaild | state + year, data=Fatality)\nlm_fe\n\nOLS estimation, Dep. Var.: mrall\nObservations: 336 \nFixed-effects: state: 48,  year: 7\nStandard-errors: Clustered (state) \n             Estimate Std. Error   t value   Pr(&gt;|t|)    \nbeertax     -0.476567   0.303670 -1.569357 1.2327e-01    \nunrate      -0.062880   0.013034 -4.824134 1.5206e-05 ***\nlog(perinc)  1.796308   0.642674  2.795052 7.4898e-03 ** \nmlda        -0.001890   0.021519 -0.087826 9.3039e-01    \ncomserdyes   0.034492   0.132229  0.260853 7.9535e-01    \njaildyes     0.014597   0.016246  0.898519 3.7349e-01    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.140612     Adj. R2: 0.925966\n                 Within R2: 0.354415\n\n\nOppure, possiamo aggiungere variabili dummy per year nel modello:\n\nlm_dummy_year_cluster &lt;- feols(mrall ~ beertax + unrate + log(perinc) + mlda + comserd \n                               + jaild + factor(state) + factor(year), data=Fatality, cluster=\"state\")\nlm_dummy_year_cluster\n\nOLS estimation, Dep. Var.: mrall\nObservations: 336 \nStandard-errors: Clustered (state) \n                 Estimate Std. Error   t value   Pr(&gt;|t|)    \n(Intercept)    -12.603660   6.784529 -1.857706 6.9482e-02 .  \nbeertax         -0.476567   0.328510 -1.450691 1.5351e-01    \nunrate          -0.062880   0.014101 -4.459361 5.0929e-05 ***\nlog(perinc)      1.796308   0.695244  2.583707 1.2944e-02 *  \nmlda            -0.001890   0.023279 -0.081185 9.3564e-01    \ncomserdyes       0.034492   0.143045  0.241129 8.1050e-01    \njaildyes         0.014597   0.017574  0.830578 4.1041e-01    \nfactor(state)4  -0.898339   0.481419 -1.866024 6.8285e-02 .  \n... 52 coefficients remaining (display them with summary() or use argument n)\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.140612   Adj. R2: 0.925966\n\n\nIn entrambi i casi, gli errori standard considerano la correlazione temporale all’interno degli stati, ma differiscono leggermente a causa di come i gradi di libertà sono gestiti nei due approcci.",
    "crumbs": [
      "Syllabus",
      "R",
      "Panel data"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Econometria (1018133)",
    "section": "",
    "text": "Prof. Giuseppe Ragusa\n   Sapienza, Università di Roma\n   Dipartimento di Economia e Diritto\n   Viale del Castro Laurenziano, 9\n   giuseppe.ragusa at uniroma1 dot it\n   Ricevimento\n\n\n\n\n\n   Lunedì (L) e Martedì (M)\n   19 febbraio, 2024 - 1 giugno 2024\n   (L) 10:00–12:00 (M) 14:00-16:00\n   (L) Aula 10 (M) Aula 8b"
  },
  {
    "objectID": "index.html#descrizione-del-corso",
    "href": "index.html#descrizione-del-corso",
    "title": "Econometria (1018133)",
    "section": "Descrizione del corso",
    "text": "Descrizione del corso\nEconometria (1018133) offre agli studenti un’introduzione pratica all’econometria, strumento fondamentale per comprendere e analizzare l’economia da un punto di vista empirico. Attraverso un approccio equilibrato tra teoria e pratica, gli studenti esploreranno i concetti fondamentali e gli strumenti empirici necessari per comprendere le sfide relative all’impiego di tecniche quantitative in microeconomia, macroeconomia e finanza."
  },
  {
    "objectID": "Dummy_ilfs.html",
    "href": "Dummy_ilfs.html",
    "title": "Variabili Dummy and Dati Italiani",
    "section": "",
    "text": "Le variabili dummy sono utilizzate per analizzare variabili categoriche.",
    "crumbs": [
      "Syllabus",
      "R",
      "Variabili dummy"
    ]
  },
  {
    "objectID": "Dummy_ilfs.html#variabili-dummy",
    "href": "Dummy_ilfs.html#variabili-dummy",
    "title": "Variabili Dummy and Dati Italiani",
    "section": "",
    "text": "Le variabili dummy sono utilizzate per analizzare variabili categoriche.",
    "crumbs": [
      "Syllabus",
      "R",
      "Variabili dummy"
    ]
  },
  {
    "objectID": "Dummy_ilfs.html#dati-sui-lavoratori-italiani",
    "href": "Dummy_ilfs.html#dati-sui-lavoratori-italiani",
    "title": "Variabili Dummy and Dati Italiani",
    "section": "Dati sui lavoratori italiani",
    "text": "Dati sui lavoratori italiani\nUtilizeremo un dataset contenente alcuni variabili che descrivono le caratteristiche di una campione di lavoratori dipendenti italiani.\n\n\n\n\n\n\n\nVariabile\nDescrizione\n\n\n\n\nretric\nRetribuzione mensile netta\n\n\ngenere\nGenere del lavoratore\n\n\nregione\nRegione di residenza\n\n\nedulev\nLivello di istruzione\n\n\nistruzione_anni\nAnni di istruzione completati\n\n\neta\nEtà del lavoratore\n\n\ntitolo10\nTitolo di studio\n\n\ndetind\nTipo di contratto di lavoro (indeterminato, determinato)\n\n\npiepar\nTipo di orario di lavoro (pieno, parziale)\n\n\ntenure\nAnni di lavoro presso l’attuale datore di lavoro\n\n\ncittadinanza\nSe il lavoratore ha la cittadinanza italiana\n\n\nsg13\nLuogo di nascita\n\n\norelav\nOre di lavoro settimanali\n\n\ngenere_dummy\nVariabile dummy per il genere (1 = Femmina, 0 = Maschio)\n\n\n\nIl file può essere scaricato qua.",
    "crumbs": [
      "Syllabus",
      "R",
      "Variabili dummy"
    ]
  },
  {
    "objectID": "Dummy_ilfs.html#salari-per-genere",
    "href": "Dummy_ilfs.html#salari-per-genere",
    "title": "Variabili Dummy and Dati Italiani",
    "section": "Salari per genere",
    "text": "Salari per genere\nConsideriamo la variabile genere:\n\nhead(df[, \"genere\"])\n\n# A tibble: 6 × 1\n  genere \n  &lt;chr&gt;  \n1 Maschio\n2 Femmina\n3 Femmina\n4 Maschio\n5 Maschio\n6 Femmina\n\n\nLa variabile assume il valore maschio o femmina a seconda che l’individua sia di genere maschile o femminile. Possiamo creare la variabile manualmente nel modo seguente\n\ndf &lt;- df %&gt;% mutate(Maschio = ifelse(genere==\"Maschio\", 1, 0))\n\nLa variabile Maschio prende il valore 1 se il genere dell’individuo è maschile e 0 altrimenti.\nPossiamo utilizzare questa variabile per analizzare la variabile genere. Per esempio, possiamo prendere la media di Maschio\n\nmean(df$Maschio)\n\n[1] 0.5345987\n\n\nLa media nel caso di una variabile dummy è la percentuale di osservazioni che prendono il valore uno. Nel caso dei nostri dati, \\(\\bar{X}_{maschi}=0.535\\) indica che circa il 53.46% dei lavoratori nel nostro campione è maschio.\nNon c’è nulla di speciale nella scelta di “maschio” come valore per assegnare alla variabile dummy il valore 1. Possiamo infatti creare la variabile dummy Femmina con il valore 1 qualora il lavoratore sia di genere femminile.\n\ndf &lt;- df %&gt;% mutate(Femmina = ifelse(genere==\"Femmina\", 1, 0))\n\nIn questo caso, \\(\\bar{X}_{femmina}=0.465\\) indica che circa il 46.54 dei lavoratori nel nostro campione è una donna (questa percentuale non è altro che \\(1-\\bar{X}_{maschio}\\).)\nCome possiamo usare questa variabile in una regressione? Possiamo usare la dummy come variabile indipendente.\n\nlm_maschi &lt;- feols(retric~Maschio, data = df)\nlm_maschi\n\nOLS estimation, Dep. Var.: retric\nObservations: 138,618 \nStandard-errors: IID \n            Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept) 1171.258    1.99513 587.058 &lt; 2.2e-16 ***\nMaschio      281.449    2.72871 103.144 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 506.7   Adj. R2: 0.071272\n\n\nL’interpretazione del coefficiente sulla dummy non è altro che la differenza dela salario fra uomini (Maschio=1) e donne (Maschio=0). Quindi, visto che \\(\\hat{\\beta}_1 = 281.4492935\\), gli uomini nel nostro campione guadagnano in media \\(281.4492935\\) euro piu’ delle donne. L’intercetta è in questa regressione la media (sempre nel campione) del salario delle donne (l’intercetta è interpretabile come la media della variabile dipendente quando i regressori sono uguali a zero).\nSe utilizziamo la dummy Femmina invece della variabile dummy Maschio, i coefficienti stimati saranno diversi, ma la loro interpetazione finale sarà identica.\n\nlm_femmine &lt;- feols(retric~Femmina, data = df)\nlm_femmine\n\nOLS estimation, Dep. Var.: retric\nObservations: 138,618 \nStandard-errors: IID \n            Estimate Std. Error  t value  Pr(&gt;|t|)    \n(Intercept) 1452.708    1.86154  780.381 &lt; 2.2e-16 ***\nFemmina     -281.449    2.72871 -103.144 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 506.7   Adj. R2: 0.071272\n\n\nIn questa nuova regression, \\(\\hat{\\beta}_1 = 1452.7076446\\), e quindi possiamo dire che le donne nel nostro campione guadagnano in media \\(1452.7076446\\) euro in meno degli uomini. L’intercetta è invece la media del salario degli uomini.\nSe calcolassimo le medie e la differenze delle medie manualemnte senza usare la regressione otterremo gli stessi risultati. Per esempio, il salario medio dei lavoratori di sesso maschile è esattamente uguale al coefficiente \\(\\hat{\\beta}_0\\) nella regressione che usa la veriaile dummy Femmina:\n\nmean(df$retric[df$genere==\"Maschio\"])\n\n[1] 1452.708\n\n\nPer avere una completa panaromica della media di retric per genere possiamo usare la funzione group_by e summarize di dplyr”\n\ndf %&gt;% group_by(genere) %&gt;% summarize(mean(retric))\n\n# A tibble: 2 × 2\n  genere  `mean(retric)`\n  &lt;chr&gt;            &lt;dbl&gt;\n1 Femmina          1171.\n2 Maschio          1453.\n\n\nI coefficienti delle due regressioni stimano i corrispondenti valori della popolazione: \\(\\hat{\\beta}_0\\) stima la media nella popolazione dei salari per il caso in cui la variabile dummy è zero; \\(\\hat{\\beta}_1\\) stima la differenza dei salari medi nella poplazione fra i lavoratori con variabile dummy uguale a 1 e variabile dummy uguale a zero. Quindi possiamo chiederci se questa differenza nei salari che vediamo nel campioni è probabile che permangano qualora avessimo a disposizione l’intera popolazione. L’intervallo di confidenza risponde a questa domanda fornendoci un intervallo di valori probabili della differenza salariale fra uomini e donne nel campione:\n\nconfint(lm_maschi)\n\n                2.5 %    97.5 %\n(Intercept) 1167.3479 1175.1688\nMaschio      276.1011  286.7975\n\n\nGli intervalli sono molto piccoli (come era prevedibile vista la grandezza del campione) e ci dice che questa differenza non è probabilmenmte dovuta al particolare compione che stiamo analizzando.\n\nSalari per regione\nUna variabile particolarmente interessante del nostro dataset è la variabile regione che fornisce la regione di residenza di ciascun lavoratore nel nostro campione\n\nhead(df[,\"regione\"])\n\n# A tibble: 6 × 1\n  regione  \n  &lt;chr&gt;    \n1 Puglia   \n2 Lombardia\n3 Piemonte \n4 Lombardia\n5 Umbria   \n6 Campania \n\n\nL’esistenza di differenza salariali nelle regioni italiane può essere investigata mediante un grafico che mostra la distribuzione di retric per ciascuna regione:\n\nggplot(df, aes(x = retric)) + \n  xlab(\"Regione\") + \n  ylab(\"Retribuzione netta\") +\n  geom_histogram(aes(y=stat(density)))  + \n  theme_minimal() + \n  theme(axis.text.x = \n          element_text(\n            angle = 25,\n            vjust = 0.5,\n            hjust = 1,\n            size = 6), \n        axis.text.y = \n          element_text(size = 6)\n        ) + facet_wrap(~regione)\n\nWarning: `stat(density)` was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(density)` instead.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nggplot(df, aes(y = retric, x = fct_reorder(regione, retric))) + \n  xlab(\"Regione\") + \n  ylab(\"Retribuzione netta\") +\n  geom_boxplot(outlier.alpha = 0.6)  + \n  theme_minimal() + \n  theme(axis.text.x = element_text(\n  angle = 45,\n  vjust = 0.5,\n  hjust = 1\n))\n\n\n\n\n\n\n\n\nPur essendo una variabile categorica, regione prende piu’ di due valori e quindi non è possibile codificare l’informazione contenuta in essa mediante un’unica variabile dummy. In questo caso creiama una dummy per ciascuna regione: una dummy Lombardia che prende il valore 1 per quei lavoratori che risiedono in Lombardia e 0 per gli altri, una dummy Sicilia per i lavoratori che risiedono in Sicilia e 0 per gli altri, e così via.\nE’ possibile creare queste dummy manualmente:\n\ndf &lt;- df %&gt;% mutate(Lombardia = ifelse(regione==\"Lombardia\", 1, 0),\n                    Sicilia = ifelse(regione==\"Sicilia\", 1, 0),\n                    .\n                    .\n                    )\n\nLa creazione manuale è però tediosa e prona ad errori. È preferibile automatizzare il processo di creazione delle dummy mediante il pachetto fastDummies.\n\nlibrary(fastDummies)\ndf &lt;- fastDummies::dummy_cols(df, select_columns = \"regione\", \n                              omit_colname_prefix = TRUE)\n\nDopo l’esecuzione del codice, df conterrà una variabile dummy per ciascuna regione. Possiamo adesso calcolare la media di ciascuna dummy così creata per ottenere la percentuale dei residenti in ciascuna regione. Per esempio,\n\nmean(df$Calabria)\n\n[1] 0.01961506\n\n\nindica che circa il 1.96% dei lavoratori del nostro campione è residente in Calabria.\nQual è l’interpretazione della regressione in cui aggiungiamo tutte le dummy?\n\nlm_regione &lt;- feols(retric~Abruzzo+Basilicata+ Calabria + Campania + \n`Emilia Romagna` + `Friuli Venezia Giulia` + \nLazio + Liguria + Lombardia + Marche + Molise+\nPiemonte + Puglia + Sardegna + Sicilia +\nToscana + `Trentino alto Adige` + Umbria + \n`Valle d'Aosta` + Veneto, data = df)\n\nThe variable 'Veneto' has been removed because of collinearity (see $collin.var).\n\nsummary(lm_regione)\n\nOLS estimation, Dep. Var.: retric\nObservations: 138,618 \nStandard-errors: IID \n                          Estimate Std. Error    t value   Pr(&gt;|t|)    \n(Intercept)             1352.67843    5.88778 229.743479  &lt; 2.2e-16 ***\nAbruzzo                  -67.03866   11.67738  -5.740897 9.4372e-09 ***\nBasilicata               -62.22983   10.73230  -5.798367 6.7108e-09 ***\nCalabria                -159.50447   11.59058 -13.761558  &lt; 2.2e-16 ***\nCampania                -124.70487    8.18131 -15.242653  &lt; 2.2e-16 ***\n`Emilia Romagna`           8.80117    7.58301   1.160645 2.4579e-01    \n`Friuli Venezia Giulia`    3.25957    9.44556   0.345090 7.3003e-01    \nLazio                    -30.97062    7.82437  -3.958227 7.5546e-05 ***\nLiguria                   -2.50250   10.18666  -0.245665 8.0594e-01    \nLombardia                 56.13623    6.91684   8.115883 4.8617e-16 ***\nMarche                   -76.95157   10.14049  -7.588549 3.2551e-14 ***\nMolise                   -79.67389   14.50991  -5.490998 4.0037e-08 ***\nPiemonte                 -12.44023    7.66513  -1.622964 1.0460e-01    \nPuglia                  -139.24116    9.10816 -15.287521  &lt; 2.2e-16 ***\nSardegna                -150.99941   10.57937 -14.273005  &lt; 2.2e-16 ***\nSicilia                 -166.02165    7.95915 -20.859208  &lt; 2.2e-16 ***\nToscana                  -54.75509    8.10400  -6.756549 1.4187e-11 ***\n`Trentino alto Adige`     81.81903    7.95858  10.280604  &lt; 2.2e-16 ***\nUmbria                   -79.82247   10.44123  -7.644928 2.1040e-14 ***\n`Valle d'Aosta`           14.82207    9.45899   1.566983 1.1712e-01    \n... 1 variable was removed because of collinearity (Veneto)\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 520.6   Adj. R2: 0.019842\n\n\nLa funzione feols ci informa che una delle variabili dummy è stata rimossa per evitare la collinearità (la trappola delle variabili dummy). I coefficienti della regressione sono la differenza fra il salario medio nella regione a cui il coefficiente si riferisce e la regione omessa dalla regressione che, in questo caso, è la regione Veneto. Per esempio, il coefficite della dummy Sicilia ci dice che in media i lavoratori residenti nell’isola guadagnano 166.0216453 euro in meno dei lavoratori residenti in Veneto.\nAggiungere variabili dummy al modello di regressione è un’operazione così frequente che R possiede un meccanismo automatico per la loro gestione: aggiungere nella regressione la variabile categorica automaticamente crea e aggiunge al modello una dummy per ciascuna categoria.\n\nfeols(retric~regione, data=df)\n\nOLS estimation, Dep. Var.: retric\nObservations: 138,618 \nStandard-errors: IID \n                               Estimate Std. Error    t value   Pr(&gt;|t|)    \n(Intercept)                  1285.63977    10.0844 127.487822  &lt; 2.2e-16 ***\nregioneBasilicata               4.80883    13.4986   0.356247 7.2166e-01    \nregioneCalabria               -92.46581    14.1905  -6.516024 7.2442e-11 ***\nregioneCampania               -57.66621    11.5743  -4.982284 6.2913e-07 ***\nregioneEmilia Romagna          75.83983    11.1594   6.796071 1.0794e-11 ***\nregioneFriuli Venezia Giulia   70.29823    12.4999   5.623892 1.8706e-08 ***\nregioneLazio                   36.06804    11.3248   3.184884 1.4484e-03 ** \nregioneLiguria                 64.53616    13.0689   4.938129 7.8967e-07 ***\n... 12 coefficients remaining (display them with summary() or use argument n)\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 520.6   Adj. R2: 0.019842\n\n\nSe volessimo ottenere i risultati delle regressione omettando un’altra regione, possiamo usare la funzione i() che prende come pri argomento la variabile categorica e come secondo argomento la categoria da escludere. Pertanto, per escludere la dummy riferita alla regione Campania usiamo come regressore i(regione, \"Campanio\").\n\nfeols(retric~i(regione, \"Campania\"), data=df)\n\nOLS estimation, Dep. Var.: retric\nObservations: 138,618 \nStandard-errors: IID \n                                Estimate Std. Error   t value   Pr(&gt;|t|)    \n(Intercept)                    1227.9736    5.68048 216.17407  &lt; 2.2e-16 ***\nregione::Abruzzo                 57.6662   11.57425   4.98228 6.2913e-07 ***\nregione::Basilicata              62.4750   10.62000   5.88277 4.0437e-09 ***\nregione::Calabria               -34.7996   11.48667  -3.02956 2.4495e-03 ** \nregione::Emilia Romagna         133.5060    7.42320  17.98496  &lt; 2.2e-16 ***\nregione::Friuli Venezia Giulia  127.9644    9.31776  13.73339  &lt; 2.2e-16 ***\nregione::Lazio                   93.7343    7.66960  12.22154  &lt; 2.2e-16 ***\nregione::Liguria                122.2024   10.06826  12.13738  &lt; 2.2e-16 ***\n... 12 coefficients remaining (display them with summary() or use argument n)\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 520.6   Adj. R2: 0.019842\n\n\nCome nel caso della variabile genere, i valori dei coefficienti sono esattamenti uguali alle differenze delle medie calcolate manualmente. Per convincerci di ciò, possiamo calcolare la media di retric per regione e sottrarre la media della Campania usando la funzione group_by e summarize di dplyr.\n\n## Calcoliamo la media dei salari in Campania\nmc &lt;- df %&gt;% filter(regione==\"Campania\") %&gt;% \n  summarize(mc = mean(retric)) %&gt;% pull(mc)\n## `mc` e' uguale all'intercetta della regressione che \n## esclude la dummy per la Campania.\n## Calcoliamo la media dei salari in ciascuna regione e sottraiamo\n## `mc`\ndf %&gt;% filter(regione!=\"Campania\") %&gt;% \n  group_by(regione) %&gt;% \n  summarize(`Differenza da media Campania` = mean(retric)-mc) %&gt;%\n  arrange(`Differenza da media Campania`)\n\n# A tibble: 19 × 2\n   regione               `Differenza da media Campania`\n   &lt;chr&gt;                                          &lt;dbl&gt;\n 1 Sicilia                                        -41.3\n 2 Calabria                                       -34.8\n 3 Sardegna                                       -26.3\n 4 Puglia                                         -14.5\n 5 Umbria                                          44.9\n 6 Molise                                          45.0\n 7 Marche                                          47.8\n 8 Abruzzo                                         57.7\n 9 Basilicata                                      62.5\n10 Toscana                                         69.9\n11 Lazio                                           93.7\n12 Piemonte                                       112. \n13 Liguria                                        122. \n14 Veneto                                         125. \n15 Friuli Venezia Giulia                          128. \n16 Emilia Romagna                                 134. \n17 Valle d'Aosta                                  140. \n18 Lombardia                                      181. \n19 Trentino alto Adige                            207. \n\n\nIl vantaggio di usare la regressione rispetto a calcolare la differenza medie manualmente è la regressione ci restituisce gli errori standard delle differenze delle media consentendoci la costruzione immediata degli intervalli di confidenza.\n\nconfint(lm_regione)\n\n                              2.5 %      97.5 %\n(Intercept)             1341.138502 1364.218367\nAbruzzo                  -89.926111  -44.151208\nBasilicata               -83.264940  -41.194721\nCalabria                -182.221796 -136.787151\nCampania                -140.740079 -108.669653\n`Emilia Romagna`          -6.061372   23.663721\n`Friuli Venezia Giulia`  -15.253560   21.772697\nLazio                    -46.306226  -15.635005\nLiguria                  -22.468156   17.463149\nLombardia                 42.579363   69.693096\nMarche                   -96.826733  -57.076413\nMolise                  -108.113045  -51.234739\nPiemonte                 -27.463752    2.583285\nPuglia                  -157.092974 -121.389340\nSardegna                -171.734783 -130.264047\nSicilia                 -181.621436 -150.421854\nToscana                  -70.638786  -38.871401\n`Trentino alto Adige`     66.220357   97.417696\nUmbria                  -100.287085  -59.357850\n`Valle d'Aosta`           -3.717364   33.361506\n\n\n\n\nGender gap\nL’obiettivo è misurare la differenza salariale tra donne e uomini che condividono le stesse caratteristiche rilevanti, come l’istruzione, l’esperienza lavorativa, il settore di impiego, ecc., ma differiscono per genere.\n\nlm_gp &lt;- feols(retric~genere+regione, data=df)\nlm_gp\n\nOLS estimation, Dep. Var.: retric\nObservations: 138,618 \nStandard-errors: IID \n                                Estimate Std. Error    t value   Pr(&gt;|t|)    \n(Intercept)                  1118.134158    9.81249 113.950063  &lt; 2.2e-16 ***\ngenereMaschio                 290.437520    2.70004 107.568035  &lt; 2.2e-16 ***\nregioneBasilicata               0.001989   12.96823   0.000153 9.9988e-01    \nregioneCalabria               -91.809556   13.63291  -6.734407 1.6524e-11 ***\nregioneCampania               -65.965371   11.11971  -5.932295 2.9944e-09 ***\nregioneEmilia Romagna          95.899709   10.72248   8.943802  &lt; 2.2e-16 ***\nregioneFriuli Venezia Giulia   86.855842   12.00973   7.232126 4.7793e-13 ***\nregioneLazio                   48.195564   10.88033   4.429603 9.4479e-06 ***\n... 13 coefficients remaining (display them with summary() or use argument n)\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 500.1   Adj. R2: 0.095359\n\n\nIn questa prima regressione stiamo “controllando” per la regione di residenza. L’interpretazione del coefficiente di gender è quindi la differenza media dei salari fra uomini e donne a parità di regione di residenza. La stima di tale differenza è di circa 290.44 euro. Questa differenza è statisticamente significativa, cioè possiamo rigettare l’ipotesi nulla che nella popolazione la differenza è uguale a zero (\\(H_0: \\beta_1=0\\)) poichè l’intervallo di onfidenza non contiene zero o, equivalentemente, la statistica \\(t\\) è maggiore in valore assoluto del valore critico (\\(1.96\\)).\nChiaramente, uomini e donne possono differire per livelli di istruzione (istruzione_anno), per la tipologia di contratto (detind) e se lavorano in part-time (piepar) e per il numero di ore lavorate.\n\nlm_gp2 &lt;- feols(retric~istruzione_anni+piepar+detind+genere+regione, data=df)\nlm_gp2\n\nOLS estimation, Dep. Var.: retric\nObservations: 138,618 \nStandard-errors: IID \n                            Estimate Std. Error    t value   Pr(&gt;|t|)    \n(Intercept)               -19.714271   8.840365  -2.230029 2.5747e-02 *  \nistruzione_anni            41.355406   0.261081 158.400638  &lt; 2.2e-16 ***\npiepartempo pieno         521.552688   2.792073 186.797681  &lt; 2.2e-16 ***\ndetindtempo indeterminato 286.402687   2.939087  97.446140  &lt; 2.2e-16 ***\ngenereMaschio             201.536591   2.283682  88.250741  &lt; 2.2e-16 ***\nregioneBasilicata          -0.101848  10.224505  -0.009961 9.9205e-01    \nregioneCalabria           -39.440407  10.749966  -3.668887 2.4370e-04 ***\nregioneCampania           -42.821891   8.767499  -4.884163 1.0398e-06 ***\n... 16 coefficients remaining (display them with summary() or use argument n)\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 394.3   Adj. R2: 0.437681\n\n\nPer tenere conto delle ore lavorate (orelav) possiamo usare come variabile dipendente il rapporto fra il salario orario netto mensile e le ore lavorete nel mese (che è uguale a \\(4\\times orelav\\)):\n\nlm_gp3 &lt;- feols(I(retric/(4*orelav))~istruzione_anni+piepar+detind+genere+regione, data=df)\nlm_gp3\n\nOLS estimation, Dep. Var.: I(retric/(4 * orelav))\nObservations: 138,618 \nStandard-errors: IID \n                           Estimate Std. Error   t value   Pr(&gt;|t|)    \n(Intercept)                3.724961   0.201074 18.525280  &lt; 2.2e-16 ***\nistruzione_anni            0.403373   0.005938 67.927402  &lt; 2.2e-16 ***\npiepartempo pieno         -0.178177   0.063506 -2.805674 5.0218e-03 ** \ndetindtempo indeterminato  1.799457   0.066850 26.917971  &lt; 2.2e-16 ***\ngenereMaschio              0.287500   0.051942  5.534970 3.1184e-08 ***\nregioneBasilicata         -0.158508   0.232557 -0.681588 4.9550e-01    \nregioneCalabria           -0.462131   0.244508 -1.890040 5.8755e-02 .  \nregioneCampania           -0.312879   0.199417 -1.568968 1.1666e-01    \n... 16 coefficients remaining (display them with summary() or use argument n)\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 8.96792   Adj. R2: 0.040316\n\n\n\nEsercizi:\n\nCome possiamo interpretare il coefficiente su genereMaschio nell’ultima regressione? Per esempio, come è possibile interpretare la grandezza del coefficiente in maniera percentuale (per esemptio, di quanto è più alto il salario degli uomini in termini percentuali rispetto a quello delle donne?)\nLa differenza fra i salari fra uomini e donne nell’ultima regression è statisticamente significativa?\nQuali sono le altre variabili che è probabile possono influenzare l’interpretezione del coefficiente su genereMaschio come indicativo di discriminazione?",
    "crumbs": [
      "Syllabus",
      "R",
      "Variabili dummy"
    ]
  },
  {
    "objectID": "IntroduzioneR.html",
    "href": "IntroduzioneR.html",
    "title": "R: Introduzione",
    "section": "",
    "text": "R è un linguaggio di programmazione open source utilizzato per l’analisi e visualizzazione dei dati.\nR è la versione open source di S, software sviluppato da John Chambers, Rick Becker and Allan Wilks presso i Bell Laboratories di AT&T alla fine degli anni ’70. Nell’idea del suoi creatori, S doveva essere un linguaggio di programmazione che fosse più semplice e più interattivo rispetto ai linguaggi utilizzati per l’analisi dei dati dell’epoca (FORTRAN e SAS).\nR fu sviluppato inizialmente da Ross Ihaka e Robert Gentleman presso l’Università di Auckland, in Nuova Zelanda. La prima versione di R venne condivisa dai sui creatori nel 1993. Nel 1995 il software fu rilasciato sotto la licenza open source GNU GPL.\nLa versione 1.0 è stata rilasciata il 29 febbraio 2000 e da quel momento la crescita della sua popolarità non si è arrestata.\nNegli ultimi dieci anni, due aziende hanno contribuito alla crescita di R: R Studio (oggi diventata Posit) e Revolution Analytics.\nRevolution Analytics fondata nel 2007, è stata una delle prime società a offrire una versione commerciale di R. Revolution Analytics ha introdotto nuove funzionalità, come l’elaborazione parallela e distribuita, che hanno permesso di elaborare grandi quantità di dati in modo più efficiente. L’acquisizione di Revolution Analytics da parte di Microsoft nel 2015 ha ulteriormente rafforzato l’adozione di R, poiché Microsoft ha iniziato a integrare R in molti dei suoi prodotti, come SQL Server e Power BI.\nRStudio, dal 2022 Posit, ha avuto un ruolo fondamentale nello sviluppo dell’ecosistema R. Fondata nel 2011 da JJ Allaire, l’azienda ha introdotto un ambiente di sviluppo integrato (IDE) per R, che ha rivoluzionato il modo in cui gli utenti interagiscono con il linguaggio. L’ambiente integrato, anch’esso chiamato RStudio, ha reso la programmazione in R più accessibile e intuitiva, facilitando la scrittura, il debug e la gestione dei pacchetti.\nOltre al suo IDE, RStudio ha svolto un ruolo chiave nello sviluppo del “tidyverse”, una collezione di pacchetti R per la scienza dei dati, guidata da Hadley Wickham, uno dei più influenti progammatori di R e Chief Scientist di Posit. Il tidyverse, introdotto intorno al 2014, comprende pacchetti come ggplot2, dplyr e tidyr usati per la visualizzazione, la manipolazione e la ristrutturazione dei dati. Questi strumenti hanno reso più efficiente e meno soggette a errori l’analisi dei dati, promuovendo uno stile di programmazione coerente e leggibile.\nR è oggi uno dei linguaggi di programmazione più popolari per l’analisi dei dati e la statistica negli ultimi anni. Ecco alcuni dati sull’adozione di R:\n\nNumero di utenti: Secondo un sondaggio del 2022 condotto da Stack Overflow R è uno dei linguaggi di programmazione più popolare al mondo, utilizzato dal 4.7% degli sviluppatori. Nella lista è il primo software ad essere specificatamente pensato per applicazioni statistiche.\nNumero di pacchetti: Il Comprehensive R Archive Network (CRAN), il principale repository di pacchetti per R, contiene oltre 19.000 pacchetti. Questi pacchetti coprono una vasta gamma di applicazioni che vanno dalla statistica al machine learning, dalla visualizzazione e manipolazione dei dati alla stesura automatica di report, e altri task generici non necessariamente legati alle applicazioni di carattere statistico.\nUso aziendale: L’adozione di R nell’ambiente aziendale è aumentata negli ultimi anni, con molte aziende che lo utilizzano per l’analisi dei dati e la statistica.\n\nIn generale, R è diventato un linguaggio di programmazione popolare tra i data scientist, gli statistici e gli analisti dei dati grazie alla sua vasta gamma di pacchetti, alla sua flessibilità e alla sua potenza.\nQuore.",
    "crumbs": [
      "Syllabus",
      "R",
      "Introduzione a `R`"
    ]
  },
  {
    "objectID": "IntroduzioneR.html#storia",
    "href": "IntroduzioneR.html#storia",
    "title": "R: Introduzione",
    "section": "",
    "text": "R è un linguaggio di programmazione open source utilizzato per l’analisi e visualizzazione dei dati.\nR è la versione open source di S, software sviluppato da John Chambers, Rick Becker and Allan Wilks presso i Bell Laboratories di AT&T alla fine degli anni ’70. Nell’idea del suoi creatori, S doveva essere un linguaggio di programmazione che fosse più semplice e più interattivo rispetto ai linguaggi utilizzati per l’analisi dei dati dell’epoca (FORTRAN e SAS).\nR fu sviluppato inizialmente da Ross Ihaka e Robert Gentleman presso l’Università di Auckland, in Nuova Zelanda. La prima versione di R venne condivisa dai sui creatori nel 1993. Nel 1995 il software fu rilasciato sotto la licenza open source GNU GPL.\nLa versione 1.0 è stata rilasciata il 29 febbraio 2000 e da quel momento la crescita della sua popolarità non si è arrestata.\nNegli ultimi dieci anni, due aziende hanno contribuito alla crescita di R: R Studio (oggi diventata Posit) e Revolution Analytics.\nRevolution Analytics fondata nel 2007, è stata una delle prime società a offrire una versione commerciale di R. Revolution Analytics ha introdotto nuove funzionalità, come l’elaborazione parallela e distribuita, che hanno permesso di elaborare grandi quantità di dati in modo più efficiente. L’acquisizione di Revolution Analytics da parte di Microsoft nel 2015 ha ulteriormente rafforzato l’adozione di R, poiché Microsoft ha iniziato a integrare R in molti dei suoi prodotti, come SQL Server e Power BI.\nRStudio, dal 2022 Posit, ha avuto un ruolo fondamentale nello sviluppo dell’ecosistema R. Fondata nel 2011 da JJ Allaire, l’azienda ha introdotto un ambiente di sviluppo integrato (IDE) per R, che ha rivoluzionato il modo in cui gli utenti interagiscono con il linguaggio. L’ambiente integrato, anch’esso chiamato RStudio, ha reso la programmazione in R più accessibile e intuitiva, facilitando la scrittura, il debug e la gestione dei pacchetti.\nOltre al suo IDE, RStudio ha svolto un ruolo chiave nello sviluppo del “tidyverse”, una collezione di pacchetti R per la scienza dei dati, guidata da Hadley Wickham, uno dei più influenti progammatori di R e Chief Scientist di Posit. Il tidyverse, introdotto intorno al 2014, comprende pacchetti come ggplot2, dplyr e tidyr usati per la visualizzazione, la manipolazione e la ristrutturazione dei dati. Questi strumenti hanno reso più efficiente e meno soggette a errori l’analisi dei dati, promuovendo uno stile di programmazione coerente e leggibile.\nR è oggi uno dei linguaggi di programmazione più popolari per l’analisi dei dati e la statistica negli ultimi anni. Ecco alcuni dati sull’adozione di R:\n\nNumero di utenti: Secondo un sondaggio del 2022 condotto da Stack Overflow R è uno dei linguaggi di programmazione più popolare al mondo, utilizzato dal 4.7% degli sviluppatori. Nella lista è il primo software ad essere specificatamente pensato per applicazioni statistiche.\nNumero di pacchetti: Il Comprehensive R Archive Network (CRAN), il principale repository di pacchetti per R, contiene oltre 19.000 pacchetti. Questi pacchetti coprono una vasta gamma di applicazioni che vanno dalla statistica al machine learning, dalla visualizzazione e manipolazione dei dati alla stesura automatica di report, e altri task generici non necessariamente legati alle applicazioni di carattere statistico.\nUso aziendale: L’adozione di R nell’ambiente aziendale è aumentata negli ultimi anni, con molte aziende che lo utilizzano per l’analisi dei dati e la statistica.\n\nIn generale, R è diventato un linguaggio di programmazione popolare tra i data scientist, gli statistici e gli analisti dei dati grazie alla sua vasta gamma di pacchetti, alla sua flessibilità e alla sua potenza.\nQuore.",
    "crumbs": [
      "Syllabus",
      "R",
      "Introduzione a `R`"
    ]
  },
  {
    "objectID": "IntroduzioneR.html#installazione-di-r-e-rstudio",
    "href": "IntroduzioneR.html#installazione-di-r-e-rstudio",
    "title": "R: Introduzione",
    "section": "Installazione di R e Rstudio",
    "text": "Installazione di R e Rstudio\nR può essere scaricato gratuitamente dal sito ufficiale (www.r-project.org/) scegliendo la versione adatta al sistema operativo utilizzato.\nPer installare RStudio sul tuo computer bisogna visitare https://posit.co/download/rstudio-desktop/, scaricare la versione di RStudio Desktop compatibile con il sistema operativo e seguire le istruzioni per completare l’installazione.\n\n\n\n\n\n\nImportant\n\n\n\nUna differenza chiave da comprendere capire è quella tra R, il linguaggio di programmazione mentre RStudio è un’interfaccia ad R che consente di lavorare maggiore facilità con R.",
    "crumbs": [
      "Syllabus",
      "R",
      "Introduzione a `R`"
    ]
  },
  {
    "objectID": "IntroduzioneR.html#calcoli-di-base",
    "href": "IntroduzioneR.html#calcoli-di-base",
    "title": "R: Introduzione",
    "section": "Calcoli di Base",
    "text": "Calcoli di Base\nR come una semplice calcolatrice.\n\nAddizione, Sottrazione, Moltiplicazione e Divisione\n\n\n\nMatematica\nCodice R\nRisultato\n\n\n\n\n\\(3 + 2\\)\n3 + 2\n5\n\n\n\\(3 - 2\\)\n3 - 2\n1\n\n\n\\(3 \\cdot2\\)\n3 * 2\n6\n\n\n\\(3 / 2\\)\n3 / 2\n1.5\n\n\n\n\n\nEsponenti\n\n\n\nMatematica\nCodice R\nRisultato\n\n\n\n\n\\(3^2\\)\n3 ^ 2\n9\n\n\n\\(2^{(-3)}\\)\n2 ^ (-3)\n0.125\n\n\n\\(100^{1/2}\\)\n100 ^ (1 / 2)\n10\n\n\n\\(\\sqrt{100}\\)\nsqrt(100)\n10\n\n\n\n\n\nCostanti Matematiche\n\n\n\nMatematica\nCodice R\nRisultato\n\n\n\n\n\\(\\pi\\)\npi\n3.1415927\n\n\n\\(e\\)\nexp(1)\n2.7182818\n\n\n\n\n\nLogaritmi\nNota che useremo \\(\\ln\\) e \\(\\log\\) in modo interscambiabile per indicare il logaritmo naturale. Non c’è ln() in R, invece usa log() per indicare il logaritmo naturale.\n\n\n\nMatematica\nCodice R\nRisultato\n\n\n\n\n\\(\\log(e)\\)\nlog(exp(1))\n1\n\n\n\\(\\log_{10}(1000)\\)\nlog10(1000)\n3\n\n\n\\(\\log_{2}(8)\\)\nlog2(8)\n3\n\n\n\\(\\log_{4}(16)\\)\nlog(16, base = 4)\n2\n\n\n\n\n\nTrigonometria\n\n\n\nMatematica\nCodice R\nRisultato\n\n\n\n\n\\(\\sin(\\pi / 2)\\)\nsin(pi / 2)\n1\n\n\n\\(\\cos(0)\\)\ncos(0)\n1",
    "crumbs": [
      "Syllabus",
      "R",
      "Introduzione a `R`"
    ]
  },
  {
    "objectID": "IntroduzioneR.html#i-pacchetti-di-r",
    "href": "IntroduzioneR.html#i-pacchetti-di-r",
    "title": "R: Introduzione",
    "section": "I pacchetti di R",
    "text": "I pacchetti di R\nI pacchetti in R sono collezioni di funzioni, dati e codice compilato che sono sviluppati da terzi per aumentare le funzionalità di R. Sono fondamentali poiché permettono agli utenti di eseguire una vasta gamma di analisi e processi senza dover scrivere tanto codice. Ci sono migliaia di pacchetti disponibili su CRAN (Comprehensive R Archive Network), oltre a quelli disponibili su altre fonti come GitHub.\nPer installare un pacchetto in R, si utilizza la funzione install.packages(). Questa funzione scarica e installa il pacchetto desiderato dal repository CRAN. Una volta installato un pacchetto, è necessario caricarlo nella sessione di lavoro corrente usando la funzione library() per poter utilizzare le sue funzionalità.\nEcco un esempio di come installare e caricare il pacchetto ggplot2:\n\n# Installa il pacchetto ggplot2\ninstall.packages(\"ggplot2\")\n\n# Carica il pacchetto ggplot2\nlibrary(ggplot2)\n\nIn questo esempio, il primo comando installa ggplot2 e il secondo comando lo carica nella sessione di R attuale, rendendo disponibili tutte le sue funzioni e capacità.\nPer aggiornare un pacchetto, si può usare la funzione update.packages() e per rimuoverne uno, si usa remove.packages().\nI pacchetti possono anche essere installati da Rstudio, dal menu Strumenti|Installa pacchetti. Similarmente, i pacchetti possono essere aggiornati usando la voce Aggiorna pacchetti.\nAlcuni pacchetti di R includono dataset. Questi dataset sono particolarmente utili per apprendere tecniche di analisi dei dati, testare algoritmi, e per scopi didattici. Per esempio, wooldridge e Ecdat contengono vari dataset di carattere economico.\nPer accedere ai dataset inclusi nei pacchetti bisogna installarli e poi caricarli.\n\n# Installa il pacchetto Ecdat\ninstall.packages(\"Ecdat\")\n# Installa il pacchetto wooldridge\ninstall.packages(\"wooldridge\")\n\n# Carichiamo i pacchetti\nlibrary(Ecdat)\nlibrary(wooldridge)\n\n# Carica un dataset specifico, ad esempio 'Accident'\ndata(Accident)\n\nDopo aver installato e caricato Ecdat il comando data() consente di caricare uso specifico dataset in memoria per essere poi utilizzato nella nostra sessione.\nI dataset inclusi nei pacchetti offrono diversi vantaggi:\n\nFacilità di Accesso: Gli utenti possono accedere rapidamente a un’ampia gamma di dati senza doverli cercare o scaricare da fonti esterne.\nValidità e Affidabilità: I dati forniti nei pacchetti R sono generalmente ben documentati e validati, il che li rende affidabili per analisi e apprendimento.\nScopi Didattici: Sono ottimi per l’apprendimento e la pratica delle tecniche di analisi dei dati, offrendo casi di studio reali o simulati.\n\nIn conclusione, i pacchetti in R arricchiscono notevolmente l’esperienza dell’utente non solo con strumenti analitici avanzati ma anche con dati pronti per l’analisi, rendendo R un ambiente ancora più potente per l’analisi dei dati.\n\ninstall.packages(\"Ecdat\")\n\nAlternativamente, i pacchetti possono essere installati direttamente da RStudio usando il menu Tools (Strumenti).",
    "crumbs": [
      "Syllabus",
      "R",
      "Introduzione a `R`"
    ]
  },
  {
    "objectID": "IntroduzioneR.html#caricamento-dei-pacchetti",
    "href": "IntroduzioneR.html#caricamento-dei-pacchetti",
    "title": "R: Introduzione",
    "section": "Caricamento dei pacchetti",
    "text": "Caricamento dei pacchetti\nL’installazione rende disponibili i pacchetti sul proprio computer. Perché R possa utilizzare le funzionalità del pacchetto è necessario caricare i pacchetti utilizzando il comando library(). Ad esempio, per caricare il pacchetto Ecdat bisogna eseguire il seguente comando nella console R:\n\nlibrary(Ecdat)\n\n\nI dataset di Ecdat\nPer avere un’idea dei dataset messi a disposizione da Ecdat possiamo utilizzare la funzione di help\n\nhelp(package=\"Ecdat\")\n\nI dataset possono essere caricati nella sessione di R mediante il comando data(). Per esempio, il seguente comando\n\ndata(Caschool)\n\nrende disponibile il dataset Caschool. Il data set può essere richiamato semplicemente digitando il suo nome\n\nsummary(Caschool)\n\n    distcod              county                         district     grspan   \n Min.   :61382   Sonoma     : 29   Lakeside Union Elementary:  3   KK-06: 61  \n 1st Qu.:64308   Kern       : 27   Mountain View Elementary :  3   KK-08:359  \n Median :67760   Los Angeles: 27   Jefferson Elementary     :  2              \n Mean   :67473   Tulare     : 24   Liberty Elementary       :  2              \n 3rd Qu.:70419   San Diego  : 21   Ocean View Elementary    :  2              \n Max.   :75440   Santa Clara: 20   Pacific Union Elementary :  2              \n                 (Other)    :272   (Other)                  :406              \n    enrltot           teachers          calwpct          mealpct      \n Min.   :   81.0   Min.   :   4.85   Min.   : 0.000   Min.   :  0.00  \n 1st Qu.:  379.0   1st Qu.:  19.66   1st Qu.: 4.395   1st Qu.: 23.28  \n Median :  950.5   Median :  48.56   Median :10.520   Median : 41.75  \n Mean   : 2628.8   Mean   : 129.07   Mean   :13.246   Mean   : 44.71  \n 3rd Qu.: 3008.0   3rd Qu.: 146.35   3rd Qu.:18.981   3rd Qu.: 66.86  \n Max.   :27176.0   Max.   :1429.00   Max.   :78.994   Max.   :100.00  \n                                                                      \n    computer         testscr         compstu           expnstu    \n Min.   :   0.0   Min.   :605.5   Min.   :0.00000   Min.   :3926  \n 1st Qu.:  46.0   1st Qu.:640.0   1st Qu.:0.09377   1st Qu.:4906  \n Median : 117.5   Median :654.5   Median :0.12546   Median :5215  \n Mean   : 303.4   Mean   :654.2   Mean   :0.13593   Mean   :5312  \n 3rd Qu.: 375.2   3rd Qu.:666.7   3rd Qu.:0.16447   3rd Qu.:5601  \n Max.   :3324.0   Max.   :706.8   Max.   :0.42083   Max.   :7712  \n                                                                  \n      str            avginc           elpct           readscr     \n Min.   :14.00   Min.   : 5.335   Min.   : 0.000   Min.   :604.5  \n 1st Qu.:18.58   1st Qu.:10.639   1st Qu.: 1.941   1st Qu.:640.4  \n Median :19.72   Median :13.728   Median : 8.778   Median :655.8  \n Mean   :19.64   Mean   :15.317   Mean   :15.768   Mean   :655.0  \n 3rd Qu.:20.87   3rd Qu.:17.629   3rd Qu.:22.970   3rd Qu.:668.7  \n Max.   :25.80   Max.   :55.328   Max.   :85.540   Max.   :704.0  \n                                                                  \n    mathscr     \n Min.   :605.4  \n 1st Qu.:639.4  \n Median :652.5  \n Mean   :653.3  \n 3rd Qu.:665.9  \n Max.   :709.5",
    "crumbs": [
      "Syllabus",
      "R",
      "Introduzione a `R`"
    ]
  },
  {
    "objectID": "IntroduzioneR.html#il-sistema-di-help",
    "href": "IntroduzioneR.html#il-sistema-di-help",
    "title": "R: Introduzione",
    "section": "Il sistema di help",
    "text": "Il sistema di help\nIl sistema di help di R è un’importante risorsa per gli utenti che utilizzano questo software. Consente di accedere a informazioni dettagliate su tutte le funzioni e i pacchetti di R, nonché di comprendere meglio il funzionamento del linguaggio di programmazione R.\nOgni funzione in R ha la sua pagina di help alla quale si può accedere tramite la funzione help() o tramite il simbolo ? seguito dal nome della funzione della quale si vogliono ottenee inforrmazioni. Per esempio\n\nhelp(mean)\n\napre la pagina di help relativa alla funzione mean.\nLa pagina di help fornisce una descrizione della funzione, i suoi argomenti e tipologia dei valori che la funzione restituisce. La maggior parte delle funzioni in R hanno esempi di utilizzo nella loro pagina di help.\nPer ottenere aiuto sulle funzionalità di un pacchetto bisogna passare l’argomento packages seguito dal nome del pacchetto. Per esempio, il seguente comando mostra la pagina di help per il pacchetto ggplot2\n\nhelp(packages=\"ggplot2\")",
    "crumbs": [
      "Syllabus",
      "R",
      "Introduzione a `R`"
    ]
  },
  {
    "objectID": "IntroduzioneR.html#primi-grafici-con-ggplot2",
    "href": "IntroduzioneR.html#primi-grafici-con-ggplot2",
    "title": "R: Introduzione",
    "section": "Primi grafici con ggplot2",
    "text": "Primi grafici con ggplot2\nI passi per ottenere un grafico con ggplot2 sono:\n\nInstallare e caricare il pacchetto ggplot2 utilizzando il comando install.packages(\"ggplot2\") seguito da library(ggplot2).\nCaricare i dati che si desidera visualizzare in un data frame.\nCreare un oggetto ggplot utilizzando la funzione ggplot(). Gli argomenti di questa funzione sono il data.frame e la funzione aes mediante la quale possono essere specificate le variabili che si desidera utilizzare per l’asse x e l’asse y.\nAggiungere i livelli e gli stili al grafico utilizzando una serie di geometrie come geom_point(), geom_line(), geom_bar(). Queste funzioni definiscono le modalità di rappresentazione dei dati nel grafico (ad esempio, con punti, linee, barre, ecc.).\nAggiungere etichette, titoli e altre personalizzazioni utilizzando funzioni come labs(), xlab(), ylab(), ggtitle() e altre funzioni di personalizzazione.\n\nEcco un esempio di codice di base per creare un grafico a dispersione utilizzando ggplot2:\n\nlibrary(ggplot2)\n# Caricare i dati\ndata(Caschool)\n# Creare l'oggetto ggplot\nscatterplot &lt;- ggplot(Caschool, aes(x = str, y = testscr))\n# Aggiungere i punti al grafico\nscatterplot &lt;- scatterplot + geom_point(col = \"darkgreen\")\n# Aggiungere etichette e titoli\nscatterplot &lt;- scatterplot +\n  labs(title = \"Grafico a dispersione - testscr/str\",\n      x = \"Rapporto studenti insegnanti\", y = \"Punteggi nei test\")\n# Visualizzare il grafico\nscatterplot\n\n\n\n\n\n\n\n\nQuesto è solo un esempio molto semplice, ma ggplot2 offre molte altre funzionalità per la creazione di grafici avanzati e personalizzati. Per esempio, possiamo cambiare il tema grafico usando theme_bw() che elimina i colori\n\nscatterplot &lt;- scatterplot + theme_bw()\nscatterplot\n\n\n\n\n\n\n\n\nPossiamo anche costruire grafici raggruppati per variabile. Per ottenere un grafico a dispersione per str e testscr per le due tipologie di scuole grspan==\"KK-06\" egrspan=“KK-08”`:\n\nscatterplot &lt;- scatterplot + facet_wrap(~grspan)\nscatterplot\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nLa funzione facet_wrap() in ggplot2 è utilizzata per dividere i dati in sottoinsiemi basati su una variabile e creare una griglia di grafici separati, ognuno dei quali visualizza i dati per uno dei livelli della variabile.\nLa sintassi di base di facet_wrap() è la seguente:\n\nfacet_wrap(~variable, nrow = x, ncol = y)\n\nDove variable è la variabile che si vuole utilizzare per suddividere i dati in sottoinsiemi (nell precedente esempio abbiamo utilizzato grspan) e nrow e ncol specificano il numero di righe e colonne della griglia di grafici che si desidera creare.\n\n\nPossiamo anche aggiungere le rette di regression a ciascun grafico usando la geometria geom_smooth\n\nscatterplot + geom_smooth(method=\"lm\", col = \"darkred\")\n\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "Syllabus",
      "R",
      "Introduzione a `R`"
    ]
  },
  {
    "objectID": "IntroduzioneR.html#prime-manipolazione-di-dati-usando-dplyr",
    "href": "IntroduzioneR.html#prime-manipolazione-di-dati-usando-dplyr",
    "title": "R: Introduzione",
    "section": "Prime manipolazione di dati usando dplyr",
    "text": "Prime manipolazione di dati usando dplyr\n\nlibrary(dplyr)\n\nCalcoliamo la media e la standard deviation di testscr\n\nCaschool |&gt;\n  summarize(m = mean(testscr), s = sd(testscr))\n\n         m        s\n1 654.1565 19.05335\n\n\nPossiamo anche calcolare la media, la deviazione standard e il numero di osservazioni per il gruppo di scuole che hanno un rapporto studenti insegnanti minore di 20, \\(str&lt;20\\) e il gruppo di scuole che hanno un rapporto maggiore o uguale a venti (\\(str&gt;20\\)) usando la funzione group_by seguita dall’indicazione del gruppo (nel nostro caso str&lt;20):\n\ndf_1 &lt;- Caschool |&gt;\n  group_by(str&lt;20) |&gt;\n  summarize(m = mean(testscr),\n            s = sd(testscr),\n            n = n())\n\nIl risultato delle manipolazioni è un tibble — un sorta di data.frame più flessibile definito nel pacchetto dplyr.\ndf_1 può essere a sua volta utilizzato per altri calcoli e si comporta in tutto e per tutto come un normale data.frame.\n\ndf_1\n\n# A tibble: 2 × 4\n  `str &lt; 20`     m     s     n\n  &lt;lgl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 FALSE       650.  17.9   182\n2 TRUE        657.  19.4   238\n\n\n\n\n\n\n\n\nNote\n\n\n\nLe maggiori differenze fra i tibble e i data.frame sono:\n\nTipo di output: Il metodo di visualizzazione di un tibble è più compatto e leggibile rispetto a quello di un data.frame.\nComportamento dei nomi delle variabili: in un tibble, i nomi delle variabili sono sempre conservati e non vengono mai modificati (ad esempio, i nomi delle variabili non vengono convertiti in stringhe). In un data.frame, i nomi delle variabili possono essere modificati o convertiti in stringhe.\nComportamento di default dei dati mancanti: in un tibble, i dati mancanti vengono visualizzati in modo più chiaro rispetto a un data.frame.\nComportamento della subsetting: in un tibble, il subsetting (o l’estrazione di sottoinsiemi di dati) è più rigoroso rispetto a un data.frame, in quanto conserva sempre la classe del tibble, anche se viene restituito un singolo valore.\nFunzioni dplyr: un tibble è progettato per essere compatibile con le funzioni del pacchetto dplyr, che sono utilizzate per manipolare i dati.\n\nI tibble sono una versione leggermente migliorata dei tradizionali data.frame, progettata per semplificare l’analisi dei dati in R. Tuttavia, i data.frame sono ancora molto utilizzati e sono l’oggetto dati di base per molti pacchetti in R. Fortunatamente, molti dei comandi di R disegnati per i data.frame funzionano anche per i tibble.\n\n\nAbbiamo visto che una stima della differenza dei valori attesi fra i due gruppi \\[\n\\Delta = E(testscr|str&lt;20) - E(testscr|str\\geqslant20)\n\\] può essere ottenuta calcolando la differenza delle medie campionarie dei due gruppi e può essere ottenuta usando le informazioni in df_1:\n\n## Differenza delle medie campionarie\ndf_1$m[2]-df_1$m[1]\n\n[1] 7.37241\n\n\ne, quindi, \\[\n\\hat{\\Delta} = \\overline{testscr}_{str&lt;20} - \\overline{testscr}_{str\\geqslant20} = 7.3724101.\n\\]\nCon le stesse informazioni è possibile calcolare l’intervallo di confidenza al 95% per \\(\\Delta\\) che è dato da \\[\n\\hat{\\Delta}\\pm1.96\\times\\sqrt{\\frac{s_{str&lt;20}^{2}}{n_{str&lt;20}}+\\frac{s_{str\\geqslant20}^{2}}{n_{str\\geqslant20}}}.\n\\] Usando le informazioni contenute in df_1 otteniamo: \\[\n(3.7979806, 10.9468397)\n\\]",
    "crumbs": [
      "Syllabus",
      "R",
      "Introduzione a `R`"
    ]
  },
  {
    "objectID": "IntroduzioneR.html#qualcosa-di-più-complicato",
    "href": "IntroduzioneR.html#qualcosa-di-più-complicato",
    "title": "R: Introduzione",
    "section": "Qualcosa di più complicato",
    "text": "Qualcosa di più complicato\nInvece di stimare la variazione del valore atteso rispetto alle due macro-categorie (\\(str&lt;20\\) e \\(str\\geqslant20\\)) possiamo provare a stimare il valore atteso condizionatamente a piccoli intervalli. Per esempio, possiamo voler stimare la seguente differenza \\[\nE(testscr|20.1 &lt; str \\leqslant 20.6) - E(testscr|20.6 &lt; str \\leqslant 21.1)\n\\] oppure \\[\nE(testscr|21.6 &lt; str \\leqslant 22) - E(testscr|22 &lt; str \\leqslant 22.5).\n\\]\nPer stimare queste quantità utilizzando i dati nel campion, è necessario calcolare la media campionaria per le scuole che hanno un \\(str\\) che appartiene a ciascun intervallo. Per costruire questi intervalli, possiamo utilizzare la funzione cut(). La funzione cut() è utilizzata per suddividere un vettore numerico in più intervalli.\n\n\n\n\n\n\nNote\n\n\n\nLa sintassi della funzione cut() è la seguente:\n\ncut(x, breaks,\n       labels = NULL,\n       include.lowest = FALSE,\n       right = TRUE,\n       dig.lab = 3, ...)\n\ndove:\n\nx è il vettore numerico da suddividere in bin\nbreaks è un vettore contenente i valori di taglio, ovvero i punti di separazione tra i bin. Questo può essere specificato in diversi modi, ad esempio tramite un numero intero che specifica il numero di bin desiderati o un vettore numerico che specifica i limiti di ogni bin.\nlabels è un vettore di etichette per ogni bin. Se non specificato, gli intervalli saranno etichettati in base ai loro limiti.\ninclude.lowest indica se includere o meno il valore più basso del vettore x nel primo bin. Il valore predefinito è FALSE.\nright indica se i bin devono essere chiusi a destra o a sinistra. Il valore predefinito è TRUE, ovvero i bin sono chiusi a destra.\ndig.lab è il numero di cifre decimali da utilizzare per le etichette, se specificato.\n... sono altri argomenti opzionali.\n\n\n\nEcco un esempio di utilizzo della funzione cut() per suddividere str in tre bin di uguale ampiezza:\n\nstr_cat3 &lt;- cut(Caschool$str, 3)\nsummary(str_cat3)\n\n  (14,17.9] (17.9,21.9] (21.9,25.8] \n         73         305          42 \n\n\nIn questo caso il comando summary produce una tavola di frequenza con il numero delle scuole in ciascuna delle tre categorie (14,17.9], (17.9,21.9], (21.9,25.8].\nPossiamo anche specificare i breaks in modo esplicito\n\nstr_cat3 &lt;- cut(Caschool$str, c(13,20, 21, 26))\nsummary(str_cat3)\n\n(13,20] (20,21] (21,26] \n    243      86      91 \n\n\nIn questo ultimo caso, gli intervalli sono (13,20], (20,21], (21,26].\n\n\n\n\n\n\nNote\n\n\n\nstr_cat3 e, in generale, l’output di cut è un oggetto di classe factor. Questo tipo di variabili sono utilizzate per rappresentare variabili categoriche o qualitative, ovvero variabili che possono assumere un numero limitato di categorie o livelli (come il numero di intervalli nel nostro questo caso). La funzione summary() restituisce una tavola di frequenza per questo tipo di variabili perchè non avrebbe senso calcolare media, mediana e le altre quantità che sono solitamente restituita da summary quando l’argomento è una variabile di tipo numeric.\n\n\n\nlibrary(knitr)\n\ndf_2 &lt;- Caschool |&gt;\n1  mutate(str_cat = cut(str, 25)) |&gt;\n2  group_by(str_cat) |&gt;\n3  summarize(m = mean(testscr), s = sd(testscr), n = n())\n\n4df_2 |&gt; kable()\n\n\n1\n\nla funzione cut per dividere str in 25 intervalli;\n\n2\n\ngroup_by suddivide Caschool in gruppi specificati da str_cat\n\n3\n\nsummarize calcola la media, la standard deviation e il numero di osservazioni per ciascun gruppo\n\n4\n\nkabble restituisce la tavole dei valori\n\n\n\n\n\n\n\nstr_cat\nm\ns\nn\n\n\n\n\n(14,14.5]\n646.0500\n14.778549\n2\n\n\n(14.5,14.9]\n681.0750\n20.117197\n2\n\n\n(14.9,15.4]\n669.0583\n27.490814\n6\n\n\n(15.4,15.9]\n666.4300\n16.397313\n5\n\n\n(15.9,16.4]\n657.4625\n31.451677\n4\n\n\n(16.4,16.8]\n656.4000\n22.941905\n12\n\n\n(16.8,17.3]\n655.1200\n19.810342\n10\n\n\n(17.3,17.8]\n661.8417\n21.060798\n24\n\n\n(17.8,18.2]\n660.9820\n21.377905\n25\n\n\n(18.2,18.7]\n655.2611\n19.005516\n27\n\n\n(18.7,19.2]\n659.1279\n17.430926\n43\n\n\n(19.2,19.7]\n654.1674\n18.195814\n46\n\n\n(19.7,20.1]\n652.2074\n16.740564\n54\n\n\n(20.1,20.6]\n652.5538\n18.840601\n39\n\n\n(20.6,21.1]\n650.9581\n18.103751\n37\n\n\n(21.1,21.6]\n645.9219\n17.020841\n32\n\n\n(21.6,22]\n651.4000\n19.099852\n15\n\n\n(22,22.5]\n650.9208\n14.543992\n12\n\n\n(22.5,23]\n639.0750\n16.285659\n10\n\n\n(23,23.4]\n643.8833\n17.057669\n6\n\n\n(23.4,23.9]\n658.9750\n7.672091\n2\n\n\n(23.9,24.4]\n676.8500\nNA\n1\n\n\n(24.4,24.9]\n651.2000\nNA\n1\n\n\n(24.9,25.3]\n642.3833\n23.492216\n3\n\n\n(25.3,25.8]\n659.5750\n7.601398\n2\n\n\n\n\n\nAlcuni degli errori standard sono uguali a NA perché in almeno uno dei gruppi il numero di osservazioni è inferiore a 2, il numero minimo per poter calcolare questa misura dispersione.\nManipolando df_2, possiamo calcolare le differenze nelle media campionarie fra due intervalli adiacenti.\n\n1df_3 &lt;- df_2 |&gt; mutate(Delta_str = paste0(str_cat, \"-\", lag(str_cat)),\n2               Delta_testscr = m - lag(m),\n3               stderr = sqrt(s^2/n + lag(s^2/n))) |&gt;\n4               select(Delta_str, Delta_testscr, stderr)\n\n5kable(df_3)\n\n\n1\n\nla variabile Delta_str è uguale alla differenza dei due intervalli ottenuta incollando paste0 l’intervallo di ciascuna riga con quella precedente (la funzione lag(m) associa il valore di m della riga precedente). Questa variabile è utile per annotare l’asse delle ascisse del grafico che produrremo prodotto in seguito.\n\n2\n\nDelta_str contiene la differenze delle medie campionari di due intervalli successivi. Queste differenze sono calcolate usando m - lag(m) e quindi Delta_testscr è uguale a m, la media per l’intervallo, meno il valore della media per l’intervallo che preceda la riga in considerazione (lag(m))\n\n3\n\nstderr è l’errore standard della differenza delle medie in ciascun intervallo che è uguale a\n\n4\n\nselezioniamo le variabili che ci servono per il grafico mediante la funzione select()\n\n5\n\nkable(df_3) formatta il data.frame come una tavolo html. La funzione kable è contenuta nel pacchetto knitr.\n\n\n\n\n\n\n\nDelta_str\nDelta_testscr\nstderr\n\n\n\n\n(14,14.5]-NA\nNA\nNA\n\n\n(14.5,14.9]-(14,14.5]\n35.0249939\n17.650880\n\n\n(14.9,15.4]-(14.5,14.9]\n-12.0166524\n18.119279\n\n\n(15.4,15.9]-(14.9,15.4]\n-2.6283122\n13.406411\n\n\n(15.9,16.4]-(15.4,15.9]\n-8.9675232\n17.351552\n\n\n(16.4,16.8]-(15.9,16.4]\n-1.0624949\n17.063496\n\n\n(16.8,17.3]-(16.4,16.8]\n-1.2799978\n9.116243\n\n\n(17.3,17.8]-(16.8,17.3]\n6.7216634\n7.597797\n\n\n(17.8,18.2]-(17.3,17.8]\n-0.8596676\n6.063179\n\n\n(18.2,18.7]-(17.8,18.2]\n-5.7208842\n5.626609\n\n\n(18.7,19.2]-(18.2,18.7]\n3.8667941\n4.521517\n\n\n(19.2,19.7]-(18.7,19.2]\n-4.9605207\n3.776710\n\n\n(19.7,20.1]-(19.2,19.7]\n-1.9599775\n3.519561\n\n\n(20.1,20.6]-(19.7,20.1]\n0.3464399\n3.780410\n\n\n(20.6,21.1]-(20.1,20.6]\n-1.5957303\n4.237894\n\n\n(21.1,21.6]-(20.6,21.1]\n-5.0362433\n4.232187\n\n\n(21.6,22]-(21.1,21.6]\n5.4781291\n5.776997\n\n\n(22,22.5]-(21.6,22]\n-0.4791768\n6.476697\n\n\n(22.5,23]-(22,22.5]\n-11.8458333\n6.644515\n\n\n(23,23.4]-(22.5,23]\n4.8083476\n8.661194\n\n\n(23.4,23.9]-(23,23.4]\n15.0916951\n8.827486\n\n\n(23.9,24.4]-(23.4,23.9]\n17.8749390\nNA\n\n\n(24.4,24.9]-(23.9,24.4]\n-25.6499634\nNA\n\n\n(24.9,25.3]-(24.4,24.9]\n-8.8166707\nNA\n\n\n(25.3,25.8]-(24.9,25.3]\n17.1916097\n14.589449\n\n\n\n\n\nSi noti che per prima riga la differenza delle medie è NA. Il motivo è che non c’è un intervallo con valori più piccoli di per poter calcolare la differenza. La seconda riga ci dice che \\[\n\\overline{testscr}_{str \\in (14.5,14.9]} - \\overline{testscr}_{str \\in (14,14.5]}  = 35.0249939,\n\\] e che quindi scuole con classi con \\((14.5,14.9]\\) studenti per insegnante hanno punteggi più alti di circa 35.0249939 punti rispetto a quelle con \\(str\\in (14,14.5]\\). Questo valore positivo (classi più piccole hanno test score più bassi) e molto grande (quasi due volte la deviazione standard dei punteggi in tutto il campione) è dovuto al fatto che stiamo stimando la differenza dei valori attesi usando soltanto 4 scuole. Un numero troppo esigue per aspettarci che la stima sia in qualche modo “vicina” a quella che potremmo stimare se avessimo a disposizione i dati nel campione.\nLa terza riga ci dice che \\[\n\\overline{testscr}_{str \\in (14.9,15.4]} - \\overline{testscr}_{str \\in (14.5,14.9]}  = -12.0166524,\n\\] e che quindi scuole con \\(str\\in (14.9,15.4]\\) hanno punteggi più alti di circa -12.0166524 punti rispetto a quelle con \\(str\\in (14.5,14.9]\\). E così via per le altre righe.\nE’ molto probabile che tutte le stime e non soltanto quelle della prima riga siano particolarmente imprecise visto che sono tutte basate su un numero esiguo di osservazioni. Per quantificare la loro precisione, o la loro imprecisione, possiamo costruire l’intervallo di confidenza (al 95%) per ciascun valore dell’intervallo di \\(str\\). L’intervallo di confidenza al 95% è:\n\nc(df_3$Delta_testscr - 1.96 * df_3$stderr,\n  df_3$Delta_testscr + 1.96 * df_3$stderr)\n\ndove stderr è l’errore standard della differenza delle media che è stato calcolato nel precdedente blocco di codice.\nPer aggiungere l’intervallo di confidenza a df_3 possiamo usare dplyr e la funzione mutate:\n\ndf_3 &lt;- df_3 |&gt;\n1  mutate(ci_sx = Delta_testscr - 1.96 * stderr,\n2         ci_dx = Delta_testscr + 1.96 * stderr)\n\nkable(df_3)\n\n\n1\n\nl’estremo sinistro dell’intervallo di confidenza;\n\n2\n\nl’estremo destro dell’intervallo di confidenza;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDelta_str\nDelta_testscr\nstderr\nci_sx\nci_dx\n\n\n\n\n(14,14.5]-NA\nNA\nNA\nNA\nNA\n\n\n(14.5,14.9]-(14,14.5]\n35.0249939\n17.650880\n0.4292697\n69.620718\n\n\n(14.9,15.4]-(14.5,14.9]\n-12.0166524\n18.119279\n-47.5304392\n23.497134\n\n\n(15.4,15.9]-(14.9,15.4]\n-2.6283122\n13.406411\n-28.9048769\n23.648253\n\n\n(15.9,16.4]-(15.4,15.9]\n-8.9675232\n17.351552\n-42.9765654\n25.041519\n\n\n(16.4,16.8]-(15.9,16.4]\n-1.0624949\n17.063496\n-34.5069476\n32.381958\n\n\n(16.8,17.3]-(16.4,16.8]\n-1.2799978\n9.116243\n-19.1478335\n16.587838\n\n\n(17.3,17.8]-(16.8,17.3]\n6.7216634\n7.597797\n-8.1700183\n21.613345\n\n\n(17.8,18.2]-(17.3,17.8]\n-0.8596676\n6.063179\n-12.7434989\n11.024164\n\n\n(18.2,18.7]-(17.8,18.2]\n-5.7208842\n5.626609\n-16.7490376\n5.307269\n\n\n(18.7,19.2]-(18.2,18.7]\n3.8667941\n4.521517\n-4.9953794\n12.728967\n\n\n(19.2,19.7]-(18.7,19.2]\n-4.9605207\n3.776710\n-12.3628722\n2.441831\n\n\n(19.7,20.1]-(19.2,19.7]\n-1.9599775\n3.519561\n-8.8583162\n4.938361\n\n\n(20.1,20.6]-(19.7,20.1]\n0.3464399\n3.780410\n-7.0631635\n7.756043\n\n\n(20.6,21.1]-(20.1,20.6]\n-1.5957303\n4.237894\n-9.9020023\n6.710542\n\n\n(21.1,21.6]-(20.6,21.1]\n-5.0362433\n4.232187\n-13.3313288\n3.258842\n\n\n(21.6,22]-(21.1,21.6]\n5.4781291\n5.776997\n-5.8447856\n16.801044\n\n\n(22,22.5]-(21.6,22]\n-0.4791768\n6.476697\n-13.1735022\n12.215148\n\n\n(22.5,23]-(22,22.5]\n-11.8458333\n6.644515\n-24.8690823\n1.177416\n\n\n(23,23.4]-(22.5,23]\n4.8083476\n8.661194\n-12.1675926\n21.784288\n\n\n(23.4,23.9]-(23,23.4]\n15.0916951\n8.827486\n-2.2101770\n32.393567\n\n\n(23.9,24.4]-(23.4,23.9]\n17.8749390\nNA\nNA\nNA\n\n\n(24.4,24.9]-(23.9,24.4]\n-25.6499634\nNA\nNA\nNA\n\n\n(24.9,25.3]-(24.4,24.9]\n-8.8166707\nNA\nNA\nNA\n\n\n(25.3,25.8]-(24.9,25.3]\n17.1916097\n14.589449\n-11.4037108\n45.786930\n\n\n\n\n\nCome si vede chiaramente dall’analisi della tabella, tutti gli intervalli di confidenza sono molto ampi. Come preannunciato, i dati a nostra disposizione non sono abbastanza informativi per poter stimare tutte le differenze su intervalli così poco numerosi. Anche nel caso in cui considerassimo la differenza delle medie in scuole con \\(str\\in(18.7,19.2]\\) (27 scuole) e scuole con \\(str\\in (18.2,18.7]\\) (47 scuole), l’intervallo di confidenza è molto ampio: \\((-4.9953794, 12.7289675)\\). Un intervallo di confidenza così ampio implica che non possiamo neanche quantificare con l’appropriata confidenza il segno della differenza che potrebbe essere -12 o 2.\nLa rappresentazione grafica delle informazioni contenute in una tavole facilita spesso la comprensione dei risultati.\n\n1ggplot(df_3, aes(x=Delta_str,y=Delta_testscr)) +\n2  geom_pointrange(aes(ymin=ci_sx, ymax=ci_dx)) +\n3  geom_hline(yintercept = 0, col = \"darkred\") +\n  theme_bw() +\n  xlab(\"Intervalli str\") + ylab(\"Delta Media testscr\") +\n4  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n1\n\nsull’ascissa abbiamo la differenza degli intervalli, sull’ordinata la differenza delle medie;\n\n2\n\nla geometria utilizzata è geom_pointrange, che “plotta” la differenza delle medie (il punto) e l’intervallo di confidenza al 95% definito da ((ci_sx, ci_dx)) e rappresentato dalle linee che si estendono verticalmente.\n\n3\n\ngeom_hline(yintercept=0, col = \"darkred\") produce una riga orizzonate di colore rosso scuro\n\n4\n\nle etichette dell’asse della x sono ruotate di 90 gradi per favorire la loro leggibilità.\n\n\n\n\n\n\n\n\n\n\n\nIl grafico mostra che la stima di molte delle differenze è negativa e che gli intervalli di confidenza (eccettuati i tre casi in cui non è possibile costruire l’intervallo di confidenza) sono troppo ampi per poter concludere che il valore della differenza nella popolazione sia negativa",
    "crumbs": [
      "Syllabus",
      "R",
      "Introduzione a `R`"
    ]
  },
  {
    "objectID": "materiale.html",
    "href": "materiale.html",
    "title": "Materiale didattico",
    "section": "",
    "text": "Questa pagina contiene i collegamenti al materiale didattico del corso. (Nella sidebar qui a sinistra)\nIl materiale didattico è organizzato per lezione e a ciscuna lezione è associato\n\nle slide \ndispense R in formato html \nil codice R in formato Rmd in formato Rmd \nletture consigliate \n\nI collegamenti (a sinistra) si attiveranno in sincrono con la progressione del corso."
  },
  {
    "objectID": "probmodel_app.html",
    "href": "probmodel_app.html",
    "title": "Probit e Logit",
    "section": "",
    "text": "Questo documento descrive l’analisi del dataset Hmda, che contiene dati relativi alle domande di mutuo e le relative approvazioni o rifiuti.",
    "crumbs": [
      "Syllabus",
      "R",
      "Modelli per probabilità"
    ]
  },
  {
    "objectID": "probmodel_app.html#introduzione",
    "href": "probmodel_app.html#introduzione",
    "title": "Probit e Logit",
    "section": "",
    "text": "Questo documento descrive l’analisi del dataset Hmda, che contiene dati relativi alle domande di mutuo e le relative approvazioni o rifiuti.",
    "crumbs": [
      "Syllabus",
      "R",
      "Modelli per probabilità"
    ]
  },
  {
    "objectID": "probmodel_app.html#caricamento-del-dataset",
    "href": "probmodel_app.html#caricamento-del-dataset",
    "title": "Probit e Logit",
    "section": "Caricamento del Dataset",
    "text": "Caricamento del Dataset\nPer iniziare, carichiamo il dataset utilizzando il pacchetto Ecdat e esaminiamo le prime righe dei dati.\n\nlibrary(Ecdat)\nlibrary(dplyr)\nlibrary(fixest)\ndata(Hmda)\nhead(Hmda)\n\n    dir   hir       lvr ccs mcs pbcr dmi self single uria condominium black\n1 0.221 0.221 0.8000000   5   2   no  no   no     no  3.9           0    no\n2 0.265 0.265 0.9218750   2   2   no  no   no    yes  3.2           0    no\n3 0.372 0.248 0.9203980   1   2   no  no   no     no  3.2           0    no\n4 0.320 0.250 0.8604651   1   2   no  no   no     no  4.3           0    no\n5 0.360 0.350 0.6000000   1   1   no  no   no     no  3.2           0    no\n6 0.240 0.170 0.5105263   1   1   no  no   no     no  3.9           0    no\n  deny\n1   no\n2   no\n3   no\n4   no\n5   no\n6   no\n\n\nIl dataset Hmda contiene 2381 osservazioni e 13 variabili. Le variabili sono descritte nella ?@tbl-descr.\n\n\n\n\n\n\n\nVariabile\nDescrizione\n\n\n\n\ndir\nRapporto tra i pagamenti del debito e il reddito totale. Indica quanto del reddito totale viene destinato al pagamento dei debiti.\n\n\nhir\nRapporto tra le spese abitative e il reddito. Misura la percentuale del reddito spesa per le abitazioni.\n\n\nlvr\nRapporto tra l’importo del prestito e il valore stimato della proprietà. Indica quanta parte del valore della proprietà è finanziata tramite prestito.\n\n\nccs\nPunteggio di credito al consumo, da 1 a 6, dove un valore basso rappresenta un buon punteggio.\n\n\nmcs\nPunteggio di credito ipotecario, da 1 a 4, dove un valore basso indica un buon punteggio di credito.\n\n\npbcr\nPresenza di cattivi precedenti creditizi pubblici. Variabile binaria (si/no) che indica se esistono precedenti negativi.\n\n\ndmi\nRichiesta di assicurazione sul mutuo negata. Variabile binaria (si/no) che indica se è stata negata l’assicurazione sul mutuo.\n\n\nself\nSe l’individuo è un lavoratore autonomo. Variabile binaria (si/no).\n\n\nsingle\nSe l’applicante è single. Variabile binaria (si/no) che indica lo stato civile.\n\n\nuria\nTasso di disoccupazione del 1989 nel Massachusetts, nel settore di impiego dell’applicante. Fornisce contesto economico.\n\n\ncondominium\nSe l’unità abitativa è un condominio (=1). Variabile binaria (1/0) che descrive il tipo di proprietà abitativa.\n\n\nblack\nSe l’applicante è di etnia afroamericana. Variabile binaria (si/no), usata in analisi di discriminazione razziale.\n\n\ndeny\nSe la domanda di mutuo è stata negata. Variabile binaria (si/no) che indica l’esito della richiesta di mutuo.",
    "crumbs": [
      "Syllabus",
      "R",
      "Modelli per probabilità"
    ]
  },
  {
    "objectID": "probmodel_app.html#statistiche-descrittive",
    "href": "probmodel_app.html#statistiche-descrittive",
    "title": "Probit e Logit",
    "section": "Statistiche Descrittive",
    "text": "Statistiche Descrittive\nIl dataset contiene un’osservazione con alcuni dati mancanti (NA). Questa osservazione può essere eliminata mediante na.omit. Questa funzione restituisce un data.frame con le osservazioni complete, cioè tutte le osservazioni per cui tutte le varabile sono non NA.\n\nHmda &lt;- na.omit(Hmda)\n\nIl pacchetto gtsummary contiene delle funzioni molto utili per calcolare le statistiche descrittive delle variabili presenti in un data.frame.\n\nlibrary(gtsummary)\nlibrary(dplyr)\nHmda &lt;- Hmda |&gt; select(deny, everything())\nHmda |&gt;\n  tbl_summary(\n    by = black,\n    statistic = list(\n      all_continuous() ~ \"{mean} ({sd})\",\n      all_categorical() ~ \"{n} ({p}%)\"\n    ),\n    digits = all_continuous() ~ 2,\n    label = deny ~ \"Mutuo Concesso (deny)\",\n    include = names(Hmda)\n  ) |&gt; \n  add_overall() |&gt;\n   modify_spanning_header(c(\"stat_1\", \"stat_2\") ~ \"**Black**\") \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nOverall, N = 2,3801\nBlack\n\n\nno, N = 2,0411\nyes, N = 3391\n\n\n\n\nMutuo Concesso (deny)\n285 (12%)\n189 (9.3%)\n96 (28%)\n\n\ndir\n0.33 (0.11)\n0.33 (0.11)\n0.35 (0.09)\n\n\nhir\n0.26 (0.10)\n0.25 (0.10)\n0.27 (0.08)\n\n\nlvr\n0.74 (0.18)\n0.73 (0.18)\n0.81 (0.16)\n\n\nccs\n\n\n\n\n\n\n\n\n    1\n1,353 (57%)\n1,226 (60%)\n127 (37%)\n\n\n    2\n441 (19%)\n390 (19%)\n51 (15%)\n\n\n    3\n126 (5.3%)\n99 (4.9%)\n27 (8.0%)\n\n\n    4\n77 (3.2%)\n53 (2.6%)\n24 (7.1%)\n\n\n    5\n182 (7.6%)\n140 (6.9%)\n42 (12%)\n\n\n    6\n201 (8.4%)\n133 (6.5%)\n68 (20%)\n\n\nmcs\n\n\n\n\n\n\n\n\n    1\n747 (31%)\n697 (34%)\n50 (15%)\n\n\n    2\n1,571 (66%)\n1,288 (63%)\n283 (83%)\n\n\n    3\n41 (1.7%)\n38 (1.9%)\n3 (0.9%)\n\n\n    4\n21 (0.9%)\n18 (0.9%)\n3 (0.9%)\n\n\npbcr\n175 (7.4%)\n115 (5.6%)\n60 (18%)\n\n\ndmi\n48 (2.0%)\n31 (1.5%)\n17 (5.0%)\n\n\nself\n277 (12%)\n252 (12%)\n25 (7.4%)\n\n\nsingle\n936 (39%)\n761 (37%)\n175 (52%)\n\n\nuria\n3.77 (2.03)\n3.83 (2.10)\n3.45 (1.50)\n\n\ncondominium\n686 (29%)\n519 (25%)\n167 (49%)\n\n\n\n1 n (%); Mean (SD)",
    "crumbs": [
      "Syllabus",
      "R",
      "Modelli per probabilità"
    ]
  },
  {
    "objectID": "probmodel_app.html#categorizzazione-del-rapporto-loan-to-value",
    "href": "probmodel_app.html#categorizzazione-del-rapporto-loan-to-value",
    "title": "Probit e Logit",
    "section": "Categorizzazione del rapporto loan-to-value",
    "text": "Categorizzazione del rapporto loan-to-value\nClassifichiamo il rapporto loan-to-value (lvr) in categorie basse, medie e alte per analisi future.\n\nHmda &lt;- Hmda |&gt; \n  mutate(lvra = case_when(\n    lvr &lt; 0.8 ~ \"low\",\n    lvr &gt; 0.95 ~ \"high\",\n    TRUE ~ \"medium\"\n  ))\n\nCreiamo la variable dummy denied che prende il valore 1 quando deny==\"yes\" and il valore 0 quando deny==\"no\".\n\nHmda &lt;- Hmda |&gt;\n  mutate(denied = case_when(\n    deny == \"yes\" ~ 1,\n    deny == \"no\" ~ 0\n  ))",
    "crumbs": [
      "Syllabus",
      "R",
      "Modelli per probabilità"
    ]
  },
  {
    "objectID": "probmodel_app.html#modello-di-probabilità-lineare",
    "href": "probmodel_app.html#modello-di-probabilità-lineare",
    "title": "Probit e Logit",
    "section": "Modello di Probabilità Lineare",
    "text": "Modello di Probabilità Lineare\nUtilizziamo un modello di regressione lineare per stimare la probabilità di rifiuto del mutuo.\n\nlibrary(fixest)\nlpm_HMDA &lt;-\n  feols(denied ~ black + dir + hir + lvra + ccs + mcs + pbcr + dmi \n        + self + uria + condominium,\n    data = Hmda\n  )\nlpm_HMDA\n\nOLS estimation, Dep. Var.: denied\nObservations: 2,380 \nStandard-errors: IID \n             Estimate Std. Error   t value   Pr(&gt;|t|)    \n(Intercept) -0.010389   0.044382 -0.234072 8.1495e-01    \nblackyes     0.084833   0.017443  4.863364 1.2298e-06 ***\ndir          0.444625   0.086863  5.118693 3.3242e-07 ***\nhir         -0.046887   0.096121 -0.487795 6.2574e-01    \nlvralow     -0.188589   0.033249 -5.672020 1.5832e-08 ***\nlvramedium  -0.157255   0.033323 -4.719096 2.5070e-06 ***\nccs          0.030792   0.003684  8.357460  &lt; 2.2e-16 ***\nmcs          0.019743   0.011090  1.780232 7.5166e-02 .  \npbcryes      0.196684   0.023159  8.492874  &lt; 2.2e-16 ***\ndmiyes       0.701116   0.041172 17.028780  &lt; 2.2e-16 ***\nselfyes      0.055638   0.018169  3.062313 2.2210e-03 ** \nuria         0.004864   0.002872  1.693364 9.0518e-02 .  \ncondominium  0.003865   0.012980  0.297765 7.6591e-01    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.277932   Adj. R2: 0.263457\n\n\nIl coefficient sulla variable blackyes (la dummy automaticamente creata da R che prende il valore 1 se black==\"yes\") è 0.085. L’interpretazione di questo coefficiente è che una persona di coloro a parità di altre caratteristiche ha una probabilità di avere il mutuo concesso più bassa di 0.085.\nPer avere un’idea di quanto sia grande questa differenza, possiamo calcolare la variazione relative della probabilità: \\[\n\\frac{\\Pr(black=1|X) - \\Pr(black=0|X)}{\\Pr(black=0)} = \\frac{0.085}{0.093} \\approx 0.91 (91\\%)\n\\] In altre parole, se rapportata alla probabilità (non condizionata) che hanno le persone non di colore di ottenere il mutuo (9.3%), le persone di colore hanno una probabilita’ piu bassa di ottenere il mutuo di circa il 90%.",
    "crumbs": [
      "Syllabus",
      "R",
      "Modelli per probabilità"
    ]
  },
  {
    "objectID": "probmodel_app.html#modello-logit-e-probit",
    "href": "probmodel_app.html#modello-logit-e-probit",
    "title": "Probit e Logit",
    "section": "Modello Logit e Probit",
    "text": "Modello Logit e Probit\n\nlogit_HMDA &lt;-\n  feglm(\n    denied ~ black + dir + hir + lvra + ccs + mcs + pbcr +\n      dmi + self + uria + condominium,\n    data = Hmda,\n    family = binomial(\"logit\")\n  )\n\n\nprobit_HMDA &lt;-\n  feglm(\n    denied ~ black + dir + hir + lvra + ccs + mcs + pbcr +\n      dmi + self + uria + condominium,\n    data = Hmda,\n    family = binomial(\"probit\")\n  )\n\nConfrontiamo i tre diversi modelli:\n\n\n\nMentre il coefficiente del modello lineare per la probabilità si presta immediatamente ad una interpretazione, i coefficienti del modello logit e probit ci danno esclusiavamente delle informazioni riguardo al segno della relazione fra la probabilità e le rispettive variabili. Per ottenere un’interpretazione bisogna procedere calcolando le predizioni.",
    "crumbs": [
      "Syllabus",
      "R",
      "Modelli per probabilità"
    ]
  },
  {
    "objectID": "probmodel_app.html#predizioni",
    "href": "probmodel_app.html#predizioni",
    "title": "Probit e Logit",
    "section": "Predizioni",
    "text": "Predizioni\nIl modo più semplice per ottenere una stima della differenza nella probabilita’ che il mutuo venga accettto per le persone di colore e quelle non di colore e’ procedere a calcolare le predizioni a dei valori prespecificati delle \\(X\\):\nPer il modello probit: \\[\n\\begin{aligned}\n\\underset{\\text{probabilità diniego mutuo per black}}{\\underbrace{\\Phi\\left(\\hat{\\beta}_{0}+\\hat{\\beta}_{1}+\\hat{\\beta}_{2}\\bar{dir}+\\hat{\\beta}_{3}\\bar{hir}+\\hat{\\beta}_{6}\\bar{ccs}+\\hat{\\beta}_{7}\\bar{mcs}+\\hat{\\beta}_{11}\\bar{uria}\\right)}}\\\\-\\underset{\\text{probabilità diniego mutuo per non-black}}{\\underbrace{\\Phi\\left(\\hat{\\beta}_{0}+\\hat{\\beta}_{2}\\bar{dir}+\\hat{\\beta}_{3}\\bar{hir}+\\hat{\\beta}_{6}\\bar{ccs}+\\hat{\\beta}_{7}\\bar{mcs}+\\hat{\\beta}_{11}\\bar{uria}\\right)}}\n\\end{aligned}\n\\] e per il modello logit \\[\n\\begin{aligned}\n\\underset{\\text{probabilità diniego mutuo per black}}{\\underbrace{F\\left(\\hat{\\beta}_{0}+\\hat{\\beta}_{1}+\\hat{\\beta}_{2}\\bar{dir}+\\hat{\\beta}_{3}\\bar{hir}+\\hat{\\beta}_{6}\\bar{ccs}+\\hat{\\beta}_{7}\\bar{mcs}+\\hat{\\beta}_{11}\\bar{uria}\\right)}}\\\\-\\underset{\\text{probabilità diniego mutuo per non-black}}{\\underbrace{F\\left(\\hat{\\beta}_{0}+\\hat{\\beta}_{2}\\bar{dir}+\\hat{\\beta}_{3}\\bar{hir}+\\hat{\\beta}_{6}\\bar{ccs}+\\hat{\\beta}_{7}\\bar{mcs}+\\hat{\\beta}_{11}\\bar{uria}\\right)}},\n\\end{aligned}\n\\] dove \\(F(\\cdot)\\) è la funzione di ripartizaione della distribuzione logistica.\nPer ottenere le predizioni è necessario creare un data.frame contenente i valori per le \\(X\\):\n\nnew &lt;- data.frame(\n  \"dir\" = mean(Hmda$dir),\n  \"hir\" = mean(Hmda$hir),\n  \"lvra\" = \"low\",\n  \"ccs\" = mean(Hmda$ccs),\n  \"mcs\" = mean(Hmda$mcs),\n  \"pbcr\" = \"no\",\n  \"dmi\" = \"no\",\n  \"self\" = \"no\",\n  \"black\" = c(\"no\", \"yes\"),\n  \"uria\" = mean(Hmda$uria),\n  \"condominium\" = 0\n)\n\nPossiamo ottenere le predizioni per i due modelli usando la funzione predict:\n\nlogit_pred &lt;- predict(logit_HMDA, newdata = new)\nprobit_pred &lt;- predict(probit_HMDA, newdata = new)\n\nlogit_pred e probit_pred sono due vettori che hanno come prime elemento la stima della probabilità per black and come secondo la stima della probabilità per non-black (condizionatamente ai valori specificati in new per le altre variabili). La differenza di questi due valori è la stima della differenza della probabilita’.\n\ndelta_logit = diff(logit_pred)\ndelta_logit\n\n[1] 0.04204562\n\n\n\ndelta_probit = diff(probit_pred)\ndelta_probit\n\n[1] 0.05186245\n\n\nLo stesso risultato puo’ essere ottenuto usando marginaleffects\n\nlibrary(marginaleffects)\n\navg_slopes(logit_HMDA, newdata = \"mean\", variables = \"black\")\n\n\n  Term Contrast Estimate Std. Error   z Pr(&gt;|z|)   S  2.5 % 97.5 %\n black yes - no    0.042     0.0145 2.9  0.00375 8.1 0.0136 0.0705\n\nColumns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\n\navg_slopes(probit_HMDA, newdata = \"mean\", variables = \"black\")\n\n\n  Term Contrast Estimate Std. Error    z Pr(&gt;|z|)   S  2.5 % 97.5 %\n black yes - no   0.0519      0.017 3.06  0.00222 8.8 0.0186 0.0851\n\nColumns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\nAlternativamente, possiamo calcolare la media delle probabilità\n\nHmda_tmp &lt;- Hmda\nHmda_tmp$black &lt;- \"yes\"\nproba_black &lt;- predict(logit_HMDA, newdata = Hmda_tmp)\nHmda_tmp$black &lt;- \"no\"\nproba_nonblack &lt;- predict(logit_HMDA, newdata = Hmda_tmp)\n\nmean(proba_black - proba_nonblack)\n\n[1] 0.06281968\n\n\nQuesta stima e’ equivalente a quella ottenuta con marginaleffects\n\navg_slopes(logit_HMDA, variables = \"black\")\n\n\n  Term Contrast Estimate Std. Error    z Pr(&gt;|z|)    S  2.5 % 97.5 %\n black yes - no   0.0628     0.0184 3.41   &lt;0.001 10.6 0.0267 0.0989\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\nI vantaggi di utilizzare marginaleffects rispetto a procedere ai calcoli manuali sono che 1) otteniamo anche gli errori standard per l’effetto e 2) marinaleffects calcola gli effetti per tutte le variabili del modello:\n\navg_slopes(logit_HMDA)\n\n\n        Term      Contrast Estimate Std. Error       z Pr(&gt;|z|)    S     2.5 %\n black       yes - no       0.06282    0.01841  3.4131  &lt; 0.001 10.6  0.026745\n ccs         dY/dX          0.02195    0.00299  7.3335  &lt; 0.001 42.0  0.016084\n condominium 1 - 0          0.00251    0.01262  0.1989  0.84235  0.2 -0.022227\n dir         dY/dX          0.35585    0.07822  4.5495  &lt; 0.001 17.5  0.202548\n dmi         yes - no       0.73198    0.06885 10.6314  &lt; 0.001 85.3  0.597038\n hir         dY/dX         -0.00628    0.09347 -0.0672  0.94640  0.1 -0.189488\n lvra        low - high    -0.15213    0.04388 -3.4667  &lt; 0.001 10.9 -0.238139\n lvra        medium - high -0.11724    0.04381 -2.6763  0.00744  7.1 -0.203099\n mcs         dY/dX          0.01947    0.01057  1.8415  0.06555  3.9 -0.001252\n pbcr        yes - no       0.12664    0.02810  4.5064  &lt; 0.001 17.2  0.071563\n self        yes - no       0.05348    0.02085  2.5651  0.01031  6.6  0.012618\n uria        dY/dX          0.00474    0.00257  1.8457  0.06493  3.9 -0.000293\n   97.5 %\n  0.09889\n  0.02782\n  0.02725\n  0.50915\n  0.86693\n  0.17692\n -0.06612\n -0.03138\n  0.04019\n  0.18172\n  0.09435\n  0.00977\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\nQueste stime sono stime medie. Possiamo anche visualizzare le stime usilizzando le \\(X\\) sdi ciascun individuo nel nostro campione e poi visualizzare le differenze.\n\na &lt;- slopes(logit_HMDA)\nb &lt;- slopes(logit_HMDA, newdata = \"mean\")\nlibrary(ggplot2)\nggplot(a, aes(x=estimate)) + \n  geom_histogram(bins = 60) + \n  geom_vline(data=b, aes(xintercept = estimate), color = \"darkred\") + \n  facet_wrap(contrast~term, scales= \"free\") + \n  theme_minimal()",
    "crumbs": [
      "Syllabus",
      "R",
      "Modelli per probabilità"
    ]
  }
]