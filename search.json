[
  {
    "objectID": "IntroduzioneR.html",
    "href": "IntroduzioneR.html",
    "title": "R: Introduzione",
    "section": "",
    "text": "R è un linguaggio di programmazione open source utilizzato per l’analisi e visualizzazione dei dati.\nR è la versione open source di S, software sviluppato da John Chambers e colleghi presso i Bell Laboratories di AT&T alla fine degli anni ’70. Nell’idea del suo creatore S doveva essere un linguaggio di programmazione per l’analisi dei dati che fosse più semplice e più interattivo rispetto ai linguaggi esistenti dell’epoca, come FORTRAN e SAS.\nR fu sviluppato inizialmente da Ross Ihaka e Robert Gentleman presso l’Università di Auckland, in Nuova Zelanda. La prima versione di R venne condivisa dai sui creatori nel 1993. Nel 1995 il software fu rilasciato sotto la licenza open source GNU GPL.\nLa versione 1.0 è stata rilasciata il 29 febbraio 2000 e da quel momento la crescita in popolarità non si è mai arrestata.\nNegli ultimi dieci anni, due aziende hanno contribuito alla crescita di R: R Studio (oggi diventata Posit) e Revolution Analytics.\nRevolution Analytics fondata nel 2007, è stata una delle prime società ad offrire una versione commerciale di R. Revolution Analytics ha introdotto nuove funzionalità, come l’elaborazione parallela e distribuita, che hanno permesso di elaborare grandi quantità di dati in modo più efficiente.\nL’acquisizione di Revolution Analytics da parte di Microsoft nel 2015 ha ulteriormente rafforzato l’adozione di R, poiché Microsoft ha iniziato ad integrare R in molti dei suoi prodotti, come SQL Server e Power BI.\nRStudio è stata fondata nel 2011 da JJ Allaire ed ha cambiato nome in Posit nel 2022. RStudio ha creato un ambiente di sviluppo integrato (IDE) per R, chiamato appunto RSudio, che semplifica lo sviluppo di codice R, la gestione dei pacchetti e la creazione di grafici. RSudio è diventato uno strumento fondamentale per molti utenti R, poiché semplifica notevolmente il processo di sviluppo e di debugging.\nRStudio ha inoltre creato e mantiene pacchetti importanti come ggplot2() e dplyr(), che hanno migliorato notevolmente la capacità di R per la visualizzazione dei dati e la manipolazione dei dati.\nR è oggi uno dei linguaggi di programmazione più popolari per l’analisi dei dati e la statistica negli ultimi anni. Ecco alcuni dati sull’adozione di R:\n\nNumero di utenti: Secondo un sondaggio del 2022 condotto da Stack Overflow R è uno dei linguaggi di programmazione più popolare al mondo, utilizzato dal 4.7% degli sviluppatori. Nella lista è il primo software ad essere specificatamente pensato per applicazioni statistiche.\nNumero di pacchetti: Il Comprehensive R Archive Network (CRAN), il principale repository di pacchetti per R, contiene oltre 19.000 pacchetti. Questi pacchetti coprono una vasta gamma di applicazioni che vanno dalla statistica al machine learning, dalla visualizzazione e manipolazione dei dati alla stesura automatica di report, e altri task generici e non necessariamente legati alle applicazioni di carattere statistico.\nPopolarità dei pacchetti: ggplot2 (per la visualizzazione dei dati) e dplyr (per la manipolazione dei dati) sono fra i pacchetti più popolari.\nUso aziendale: L’adozione di R nell’ambiente aziendale è aumentata negli ultimi anni, con molte aziende che lo utilizzano per l’analisi dei dati e la statistica.\n\nIn generale, R è diventato un linguaggio di programmazione popolare tra i data scientist, gli statistici e gli analisti dei dati grazie alla sua vasta gamma di pacchetti, alla sua flessibilità e alla sua potenza nell’analisi dei dati."
  },
  {
    "objectID": "IntroduzioneR.html#storia",
    "href": "IntroduzioneR.html#storia",
    "title": "R: Introduzione",
    "section": "",
    "text": "R è un linguaggio di programmazione open source utilizzato per l’analisi e visualizzazione dei dati.\nR è la versione open source di S, software sviluppato da John Chambers e colleghi presso i Bell Laboratories di AT&T alla fine degli anni ’70. Nell’idea del suo creatore S doveva essere un linguaggio di programmazione per l’analisi dei dati che fosse più semplice e più interattivo rispetto ai linguaggi esistenti dell’epoca, come FORTRAN e SAS.\nR fu sviluppato inizialmente da Ross Ihaka e Robert Gentleman presso l’Università di Auckland, in Nuova Zelanda. La prima versione di R venne condivisa dai sui creatori nel 1993. Nel 1995 il software fu rilasciato sotto la licenza open source GNU GPL.\nLa versione 1.0 è stata rilasciata il 29 febbraio 2000 e da quel momento la crescita in popolarità non si è mai arrestata.\nNegli ultimi dieci anni, due aziende hanno contribuito alla crescita di R: R Studio (oggi diventata Posit) e Revolution Analytics.\nRevolution Analytics fondata nel 2007, è stata una delle prime società ad offrire una versione commerciale di R. Revolution Analytics ha introdotto nuove funzionalità, come l’elaborazione parallela e distribuita, che hanno permesso di elaborare grandi quantità di dati in modo più efficiente.\nL’acquisizione di Revolution Analytics da parte di Microsoft nel 2015 ha ulteriormente rafforzato l’adozione di R, poiché Microsoft ha iniziato ad integrare R in molti dei suoi prodotti, come SQL Server e Power BI.\nRStudio è stata fondata nel 2011 da JJ Allaire ed ha cambiato nome in Posit nel 2022. RStudio ha creato un ambiente di sviluppo integrato (IDE) per R, chiamato appunto RSudio, che semplifica lo sviluppo di codice R, la gestione dei pacchetti e la creazione di grafici. RSudio è diventato uno strumento fondamentale per molti utenti R, poiché semplifica notevolmente il processo di sviluppo e di debugging.\nRStudio ha inoltre creato e mantiene pacchetti importanti come ggplot2() e dplyr(), che hanno migliorato notevolmente la capacità di R per la visualizzazione dei dati e la manipolazione dei dati.\nR è oggi uno dei linguaggi di programmazione più popolari per l’analisi dei dati e la statistica negli ultimi anni. Ecco alcuni dati sull’adozione di R:\n\nNumero di utenti: Secondo un sondaggio del 2022 condotto da Stack Overflow R è uno dei linguaggi di programmazione più popolare al mondo, utilizzato dal 4.7% degli sviluppatori. Nella lista è il primo software ad essere specificatamente pensato per applicazioni statistiche.\nNumero di pacchetti: Il Comprehensive R Archive Network (CRAN), il principale repository di pacchetti per R, contiene oltre 19.000 pacchetti. Questi pacchetti coprono una vasta gamma di applicazioni che vanno dalla statistica al machine learning, dalla visualizzazione e manipolazione dei dati alla stesura automatica di report, e altri task generici e non necessariamente legati alle applicazioni di carattere statistico.\nPopolarità dei pacchetti: ggplot2 (per la visualizzazione dei dati) e dplyr (per la manipolazione dei dati) sono fra i pacchetti più popolari.\nUso aziendale: L’adozione di R nell’ambiente aziendale è aumentata negli ultimi anni, con molte aziende che lo utilizzano per l’analisi dei dati e la statistica.\n\nIn generale, R è diventato un linguaggio di programmazione popolare tra i data scientist, gli statistici e gli analisti dei dati grazie alla sua vasta gamma di pacchetti, alla sua flessibilità e alla sua potenza nell’analisi dei dati."
  },
  {
    "objectID": "IntroduzioneR.html#installazione-di-r-e-rstudio",
    "href": "IntroduzioneR.html#installazione-di-r-e-rstudio",
    "title": "R: Introduzione",
    "section": "Installazione di R e Rstudio",
    "text": "Installazione di R e Rstudio\nPer iniziare ad utilizzare R, è necessario installare il software. R può essere scaricato gratuitamente dal sito ufficiale (www.r-project.org/) scegliendo la versione adatta al sistema operativo utilizzato.\nPer installare RStudio sul tuo computer basta visitare https://posit.co/download/rstudio-desktop/, scaricare la versione di RStudio Desktop compatibile con il sistema operativo e seguire le istruzioni per completare l’installazione."
  },
  {
    "objectID": "IntroduzioneR.html#installazione-di-pacchetti",
    "href": "IntroduzioneR.html#installazione-di-pacchetti",
    "title": "R: Introduzione",
    "section": "Installazione di pacchetti",
    "text": "Installazione di pacchetti\nPer utilizzare pacchetti aggiuntivi come ggplot2 e dplyr, è necessario installarli utilizzando il comando install.packages() seguito dal nome del pacchetto da installare.\nAd esempio, per installare il pacchetto ggplot2, bisogna digitare il seguente comando nella console R:\n\ninstall.packages(\"ggplot2\")\n\nPer installare dplyr bisogna usare il seguente comando:\n\ninstall.packages(\"ggplot2\")\n\nUn pacchetto particolarmente utile poiché contiene parecchi dataset di carattere economico, è Ecdat. Può essere installato mediante il seguente comando:\n\ninstall.packages(\"Ecdat\")\n\nAlternativamente, i pacchetti possono essere installati direttamente da RStudio usando il menu Tools (Strumenti)."
  },
  {
    "objectID": "IntroduzioneR.html#caricamento-pacchetti",
    "href": "IntroduzioneR.html#caricamento-pacchetti",
    "title": "R: Introduzione",
    "section": "Caricamento pacchetti",
    "text": "Caricamento pacchetti\nL’installazione rende disponibili i pacchetti sul proprio computer. Perché R possa utilizzare le funzionalità del pacchetto è necessario caricare i pacchetti utilizzando il comando library(). Ad esempio, per caricare il pacchetto Ecdat bisogna eseguire il seguente comando nella console R:\n\nlibrary(Ecdat)"
  },
  {
    "objectID": "IntroduzioneR.html#i-dataset-di-ecdat",
    "href": "IntroduzioneR.html#i-dataset-di-ecdat",
    "title": "R: Introduzione",
    "section": "I dataset di Ecdat",
    "text": "I dataset di Ecdat\nPer avere un’idea dei dataset messi a disposizione da Ecdat possiamo utilizzare la funzione di help\n\nhelp(package=\"Ecdat\")\n\n\n\n\n\n\n\nNote\n\n\n\nIl sistema di help di R è un’importante risorsa per gli utenti che utilizzano questo software. Consente di accedere a informazioni dettagliate su tutte le funzioni e i pacchetti di R, nonché di comprendere meglio il funzionamento del linguaggio di programmazione R.\nOgni funzione in R ha la sua pagina di help, alla quale si può accedere tramite la funzione help() o tramite il simbolo ? seguito dal nome della funzione. Per esempio\n\nhelp(mean)\n\napre la pagina di help relativa alla funzione mean.\nLa pagina di help fornisce una descrizione della funzione, i suoi argomenti e tipologia dei valori che la funzione restituisce. Inoltre, la maggior parte delle funzioni in R hanno esempi di utilizzo nella loro pagina di help.\nPer ottenere aiuto su un pacchetto e sulle sue funzionalità bisgna passare l’argomento packages seguito dal nome del pacchetto. Per esempio, il seguente comando mostra la pagina di help per il pacchetto ggplot2\n\nhelp(packages=\"ggplot2\")\n\n\n\nI dataset possono essere caricati nella sessione di R mediante il comando data(). Per esempio, il seguente comando\n\ndata(Caschool)\n\nrende disponibile il dataset Caschool. Il data set può essere richiamato semplicemente digitando il suo nome\n\nsummary(Caschool)\n\n    distcod              county                         district     grspan   \n Min.   :61382   Sonoma     : 29   Lakeside Union Elementary:  3   KK-06: 61  \n 1st Qu.:64308   Kern       : 27   Mountain View Elementary :  3   KK-08:359  \n Median :67760   Los Angeles: 27   Jefferson Elementary     :  2              \n Mean   :67473   Tulare     : 24   Liberty Elementary       :  2              \n 3rd Qu.:70419   San Diego  : 21   Ocean View Elementary    :  2              \n Max.   :75440   Santa Clara: 20   Pacific Union Elementary :  2              \n                 (Other)    :272   (Other)                  :406              \n    enrltot           teachers          calwpct          mealpct      \n Min.   :   81.0   Min.   :   4.85   Min.   : 0.000   Min.   :  0.00  \n 1st Qu.:  379.0   1st Qu.:  19.66   1st Qu.: 4.395   1st Qu.: 23.28  \n Median :  950.5   Median :  48.56   Median :10.520   Median : 41.75  \n Mean   : 2628.8   Mean   : 129.07   Mean   :13.246   Mean   : 44.71  \n 3rd Qu.: 3008.0   3rd Qu.: 146.35   3rd Qu.:18.981   3rd Qu.: 66.86  \n Max.   :27176.0   Max.   :1429.00   Max.   :78.994   Max.   :100.00  \n                                                                      \n    computer         testscr         compstu           expnstu    \n Min.   :   0.0   Min.   :605.5   Min.   :0.00000   Min.   :3926  \n 1st Qu.:  46.0   1st Qu.:640.0   1st Qu.:0.09377   1st Qu.:4906  \n Median : 117.5   Median :654.5   Median :0.12546   Median :5215  \n Mean   : 303.4   Mean   :654.2   Mean   :0.13593   Mean   :5312  \n 3rd Qu.: 375.2   3rd Qu.:666.7   3rd Qu.:0.16447   3rd Qu.:5601  \n Max.   :3324.0   Max.   :706.8   Max.   :0.42083   Max.   :7712  \n                                                                  \n      str            avginc           elpct           readscr     \n Min.   :14.00   Min.   : 5.335   Min.   : 0.000   Min.   :604.5  \n 1st Qu.:18.58   1st Qu.:10.639   1st Qu.: 1.941   1st Qu.:640.4  \n Median :19.72   Median :13.728   Median : 8.778   Median :655.8  \n Mean   :19.64   Mean   :15.317   Mean   :15.768   Mean   :655.0  \n 3rd Qu.:20.87   3rd Qu.:17.629   3rd Qu.:22.970   3rd Qu.:668.7  \n Max.   :25.80   Max.   :55.328   Max.   :85.540   Max.   :704.0  \n                                                                  \n    mathscr     \n Min.   :605.4  \n 1st Qu.:639.4  \n Median :652.5  \n Mean   :653.3  \n 3rd Qu.:665.9  \n Max.   :709.5"
  },
  {
    "objectID": "IntroduzioneR.html#primi-grafici-con-ggplot2",
    "href": "IntroduzioneR.html#primi-grafici-con-ggplot2",
    "title": "R: Introduzione",
    "section": "Primi grafici con ggplot2",
    "text": "Primi grafici con ggplot2\nI passi per ottenere un grafico con ggplot2 sono:\n\nInstallare e caricare il pacchetto ggplot2 utilizzando il comando install.packages(\"ggplot2\") seguito da library(ggplot2).\nCaricare i dati che si desidera visualizzare in un data frame.\nCreare un oggetto ggplot utilizzando la funzione ggplot(). Gli argomenti di questa funzione sono il data.frame e la funzione aes mediante la quale possono essere specificate le variabili che si desidera utilizzare per l’asse x e l’asse y.\nAggiungere i livelli e gli stili al grafico utilizzando una serie di geometrie come geom_point(), geom_line(), geom_bar(). Queste funzioni definiscono le modalità di rappresentazione dei dati nel grafico (ad esempio, con punti, linee, barre, ecc.).\nAggiungere etichette, titoli e altre personalizzazioni utilizzando funzioni come labs(), xlab(), ylab(), ggtitle() e altre funzioni di personalizzazione.\n\nEcco un esempio di codice di base per creare un grafico a dispersione utilizzando ggplot2:\n\nlibrary(ggplot2)\n# Caricare i dati\ndata(Caschool)\n# Creare l'oggetto ggplot\nscatterplot &lt;- ggplot(Caschool, aes(x = str, y = testscr))\n# Aggiungere i punti al grafico\nscatterplot &lt;- scatterplot + geom_point(col = \"darkgreen\")\n# Aggiungere etichette e titoli\nscatterplot &lt;- scatterplot +\n  labs(title = \"Grafico a dispersione - testscr/str\",\n      x = \"Rapporto studenti insegnanti\", y = \"Punteggi nei test\")\n# Visualizzare il grafico\nscatterplot\n\n\n\n\nQuesto è solo un esempio molto semplice, ma ggplot2 offre molte altre funzionalità per la creazione di grafici avanzati e personalizzati. Per esempio, possiamo cambiare il tema grafico usando theme_bw() che elimina i colori\n\nscatterplot &lt;- scatterplot + theme_bw()\nscatterplot\n\n\n\n\nPossiamo anche costruire grafici raggruppati per variabile. Per ottenere un grafico a dispersione per str e testscr per le due tipologie di scuole grspan==\"KK-06\" egrspan=“KK-08”`:\n\nscatterplot &lt;- scatterplot + facet_wrap(~grspan)\nscatterplot\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nLa funzione facet_wrap() in ggplot2 è utilizzata per dividere i dati in sottoinsiemi basati su una variabile e creare una griglia di grafici separati, ognuno dei quali visualizza i dati per uno dei livelli della variabile.\nLa sintassi di base di facet_wrap() è la seguente:\n\nfacet_wrap(~variable, nrow = x, ncol = y)\n\nDove variable è la variabile che si vuole utilizzare per suddividere i dati in sottoinsiemi (nell precedente esempio abbiamo utilizzato `),nrowencol` specificano il numero di righe e colonne della griglia di grafici che si desidera creare.\n\n\nPossiamo anche aggiungere le rette di regression a ciascun grafico usando la geometria geom_smooth\n\nscatterplot + geom_smooth(method=\"lm\", col = \"darkred\")\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "IntroduzioneR.html#prime-manipolazione-di-dati-usando-dplyr",
    "href": "IntroduzioneR.html#prime-manipolazione-di-dati-usando-dplyr",
    "title": "R: Introduzione",
    "section": "Prime manipolazione di dati usando dplyr",
    "text": "Prime manipolazione di dati usando dplyr\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCalcoliamo la media e la standard deviation di testscr\n\nCaschool |&gt;\n  summarize(m = mean(testscr), s = sd(testscr))\n\n         m        s\n1 654.1565 19.05335\n\n\nPossiamo anche calcolare la media, la standard deviation e il numero di osservazioni per il gruppo di scuole che hanno un rapporto studenti insegnanti minore di 20, \\(str&lt;20\\) e il gruppo di scuole che hanno un rapporto maggiore o uguale a venti (\\(str&gt;20\\)) usando la funzione group_by seguita dall’indicazione del gruppo (nel nostro caso str&lt;20):\n\ndf_1 &lt;- Caschool |&gt;\n  group_by(str&lt;20) |&gt;\n  summarize(m = mean(testscr),\n            s = sd(testscr),\n            n = n())\n\nIl risultato delle manipolazioni è un tibble — un sorta di data.frame più flessibile definito nel pacchetto dplyr.\ndf_1 può essere a sua volta utilizzato per altri calcoli e si comporta in tutto e per tutto come un normale data.frame.\n\ndf_1\n\n# A tibble: 2 × 4\n  `str &lt; 20`     m     s     n\n  &lt;lgl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 FALSE       650.  17.9   182\n2 TRUE        657.  19.4   238\n\n\n\n\n\n\n\n\nNote\n\n\n\nLe maggiori differenze fra i tibble e i data.frame sono:\n\nTipo di output: Il metodo di visualizzazione di un tibble è più compatto e leggibile rispetto a quello di un data.frame.\nComportamento dei nomi delle variabili: in un tibble, i nomi delle variabili sono sempre conservati e non vengono mai modificati (ad esempio, i nomi delle variabili non vengono convertiti in stringhe). In un data.frame, i nomi delle variabili possono essere modificati o convertiti in stringhe.\nComportamento di default dei dati mancanti: in un tibble, i dati mancanti vengono visualizzati in modo più chiaro rispetto a un data.frame.\nComportamento della subsetting: in un tibble, il subsetting (o l’estrazione di sottoinsiemi di dati) è più rigoroso rispetto a un data.frame, in quanto conserva sempre la classe del tibble, anche se viene restituito un singolo valore.\nFunzioni dplyr: un tibble è progettato per essere compatibile con le funzioni del pacchetto dplyr, che sono utilizzate per manipolare i dati.\n\nI tibble sono una versione leggermente migliorata dei tradizionali data.frame, progettata per semplificare l’analisi dei dati in R. Tuttavia, i data.frame sono ancora molto utilizzati e sono l’oggetto dati di base per molti pacchetti in R. Fortunatamente, molti dei comandi di R disegnati per i data.frame funzionano anche per i tibble.\n\n\nAbbiamo visto che una stima della differenza dei valori attesi fra i due gruppi \\[\n\\Delta = E(testscr|str&lt;20) - E(testscr|str\\geqslant20)\n\\] può essere ottenuta calcolando la differenza delle medie campionarie dei due gruppi e può essere ottenuta usando le informazioni in df_1:\n\n## Differenza delle medie campionarie\ndf_1$m[2]-df_1$m[1]\n\n[1] 7.37241\n\n\ne, quindi, \\[\n\\hat{\\Delta} = \\overline{testscr}_{str&lt;20} - \\overline{testscr}_{str\\geqslant20} = 7.3724101.\n\\]\nCon le stesse informazioni è possibile calcolare l’intervallo di confidenza al 95% per \\(\\Delta\\) che è dato da \\[\n\\hat{\\Delta}\\pm1.96\\times\\sqrt{\\frac{s_{str&lt;20}^{2}}{n_{str&lt;20}}+\\frac{s_{str\\geqslant20}^{2}}{n_{str\\geqslant20}}}.\n\\] Usando le informazioni contenute in df_1 otteniamo: \\[\n(3.7979806, 10.9468397)\n\\]"
  },
  {
    "objectID": "IntroduzioneR.html#qualcosa-di-più-complicato",
    "href": "IntroduzioneR.html#qualcosa-di-più-complicato",
    "title": "R: Introduzione",
    "section": "Qualcosa di più complicato",
    "text": "Qualcosa di più complicato\nInvece di stimare la variazione del valore atteso rispetto alle due macro-categorie (\\(str&lt;20\\) e \\(str\\geqslant20\\)) possiamo provare a stimare il valore atteso condizionatamente a piccoli intervalli. Per esempio, possiamo voler stimare la seguente differenza \\[\nE(testscr|20.1 &lt; str \\leqslant 20.6) - E(testscr|20.6 &lt; str \\leqslant 21.1)\n\\] oppure \\[\nE(testscr|21.6 &lt; str \\leqslant 22) - E(testscr|22 &lt; str \\leqslant 22.5).\n\\]\nPer stimare queste quantità utilizzando i dati nel campion, è necessario calcolare la media campionaria per le scuole che hanno un \\(str\\) che appartiene a ciascun intervallo. Per costruire questi intervalli, possiamo utilizzare la funzione cut(). La funzione cut() è utilizzata per suddividere un vettore numerico in più intervalli.\n\n\n\n\n\n\nNote\n\n\n\nLa sintassi della funzione cut() è la seguente:\n\ncut(x, breaks,\n       labels = NULL,\n       include.lowest = FALSE,\n       right = TRUE,\n       dig.lab = 3, ...)\n\ndove:\n\nx è il vettore numerico da suddividere in bin\nbreaks è un vettore contenente i valori di taglio, ovvero i punti di separazione tra i bin. Questo può essere specificato in diversi modi, ad esempio tramite un numero intero che specifica il numero di bin desiderati o un vettore numerico che specifica i limiti di ogni bin.\nlabels è un vettore di etichette per ogni bin. Se non specificato, gli intervalli saranno etichettati in base ai loro limiti.\ninclude.lowest indica se includere o meno il valore più basso del vettore x nel primo bin. Il valore predefinito è FALSE.\nright indica se i bin devono essere chiusi a destra o a sinistra. Il valore predefinito è TRUE, ovvero i bin sono chiusi a destra.\ndig.lab è il numero di cifre decimali da utilizzare per le etichette, se specificato.\n... sono altri argomenti opzionali.\n\n\n\nEcco un esempio di utilizzo della funzione cut() per suddividere str in tre bin di uguale ampiezza:\n\nstr_cat3 &lt;- cut(Caschool$str, 3)\nsummary(str_cat3)\n\n  (14,17.9] (17.9,21.9] (21.9,25.8] \n         73         305          42 \n\n\nIn questo caso il comando summary produce una tavola di frequenza con il numero delle scuole in ciascuna delle tre categorie (14,17.9], (17.9,21.9], (21.9,25.8].\nPossiamo anche specificare i breaks in modo esplicito\n\nstr_cat3 &lt;- cut(Caschool$str, c(13,20, 21, 26))\nsummary(str_cat3)\n\n(13,20] (20,21] (21,26] \n    243      86      91 \n\n\nIn questo ultimo caso, gli intervalli sono (13,20], (20,21], (21,26].\n\n\n\n\n\n\nNote\n\n\n\nstr_cat3 e, in generale, l’output di cut è un oggetto di classe factor. Questo tipo di variabili sono utilizzate per rappresentare variabili categoriche o qualitative, ovvero variabili che possono assumere un numero limitato di categorie o livelli (come il numero di intervalli nel nostro questo caso). La funzione summary() restituisce una tavola di frequenza per questo tipo di variabili perchè non avrebbe senso calcolare media, mediana e le altre quantità che sono solitamente restituita da summary quando l’argomento è una variabile di tipo numeric.\n\n\n\nlibrary(knitr)\n\ndf_2 &lt;- Caschool |&gt;\n1  mutate(str_cat = cut(str, 25)) |&gt;\n2  group_by(str_cat) |&gt;\n3  summarize(m = mean(testscr), s = sd(testscr), n = n())\n\n4df_2 |&gt; kable()\n\n\n1\n\nla funzione cut per dividere str in 25 intervalli;\n\n2\n\ngroup_by suddivide Caschool in gruppi specificati da str_cat\n\n3\n\nsummarize calcola la media, la standard deviation e il numero di osservazioni per ciascun gruppo\n\n4\n\nkabble restituisce la tavole dei valori\n\n\n\n\n\n\n\nstr_cat\nm\ns\nn\n\n\n\n\n(14,14.5]\n646.0500\n14.778549\n2\n\n\n(14.5,14.9]\n681.0750\n20.117197\n2\n\n\n(14.9,15.4]\n669.0583\n27.490814\n6\n\n\n(15.4,15.9]\n666.4300\n16.397313\n5\n\n\n(15.9,16.4]\n657.4625\n31.451677\n4\n\n\n(16.4,16.8]\n656.4000\n22.941905\n12\n\n\n(16.8,17.3]\n655.1200\n19.810342\n10\n\n\n(17.3,17.8]\n661.8417\n21.060798\n24\n\n\n(17.8,18.2]\n660.9820\n21.377905\n25\n\n\n(18.2,18.7]\n655.2611\n19.005516\n27\n\n\n(18.7,19.2]\n659.1279\n17.430926\n43\n\n\n(19.2,19.7]\n654.1674\n18.195814\n46\n\n\n(19.7,20.1]\n652.2074\n16.740564\n54\n\n\n(20.1,20.6]\n652.5538\n18.840601\n39\n\n\n(20.6,21.1]\n650.9581\n18.103751\n37\n\n\n(21.1,21.6]\n645.9219\n17.020841\n32\n\n\n(21.6,22]\n651.4000\n19.099852\n15\n\n\n(22,22.5]\n650.9208\n14.543992\n12\n\n\n(22.5,23]\n639.0750\n16.285659\n10\n\n\n(23,23.4]\n643.8833\n17.057669\n6\n\n\n(23.4,23.9]\n658.9750\n7.672091\n2\n\n\n(23.9,24.4]\n676.8500\nNA\n1\n\n\n(24.4,24.9]\n651.2000\nNA\n1\n\n\n(24.9,25.3]\n642.3833\n23.492216\n3\n\n\n(25.3,25.8]\n659.5750\n7.601398\n2\n\n\n\n\n\nAlcuni degli errori standard sono uguali a NA perché in almeno uno dei gruppi il numero di osservazioni è inferiore a 2, il numero minimo per poter calcolare una misura dispersione.\nManipolando df_2, possiamo calcolare le differenze nelle media campionarie fra due intervalli adiacenti.\n\n1df_3 &lt;- df_2 |&gt; mutate(Delta_str = paste0(str_cat, \"-\", lag(str_cat)),\n2               Delta_testscr = m - lag(m),\n3               stderr = sqrt(s^2/n + lag(s^2/n))) |&gt;\n4               select(Delta_str, Delta_testscr, stderr)\n\n5kable(df_3)\n\n\n1\n\nla variabile Delta_str è uguale alla differenza dei due intervalli ottenuta incollando paste0 l’intervallo di ciascuna riga con quella precedente (la funzione lag(m) associa il valore di m della riga precedente). Questa variabile è utile per annotare l’asse delle ascisse del grafico che produrremo prodotto in seguito.\n\n2\n\nDelta_str contiene la differenze delle medie campionari di due intervalli successivi. Queste differenze sono calcolate usando m - lag(m) e quindi Delta_testscr è uguale a m, la media per l’intervallo, meno il valore della media per l’intervallo che preceda la riga in considerazione (lag(m))\n\n3\n\nstderr è l’errore standard della differenza delle medie in ciascun intervallo che è uguale a\n\n4\n\nselezioniamo le variabili che ci servono per il grafico mediante la funzione select()\n\n5\n\nkable(df_3) formatta il data.frame come una tavolo html. La funzione kable è contenuta nel pacchetto knitr.\n\n\n\n\n\n\n\nDelta_str\nDelta_testscr\nstderr\n\n\n\n\n(14,14.5]-NA\nNA\nNA\n\n\n(14.5,14.9]-(14,14.5]\n35.0249939\n17.650880\n\n\n(14.9,15.4]-(14.5,14.9]\n-12.0166524\n18.119279\n\n\n(15.4,15.9]-(14.9,15.4]\n-2.6283122\n13.406411\n\n\n(15.9,16.4]-(15.4,15.9]\n-8.9675232\n17.351552\n\n\n(16.4,16.8]-(15.9,16.4]\n-1.0624949\n17.063496\n\n\n(16.8,17.3]-(16.4,16.8]\n-1.2799978\n9.116243\n\n\n(17.3,17.8]-(16.8,17.3]\n6.7216634\n7.597797\n\n\n(17.8,18.2]-(17.3,17.8]\n-0.8596676\n6.063179\n\n\n(18.2,18.7]-(17.8,18.2]\n-5.7208842\n5.626609\n\n\n(18.7,19.2]-(18.2,18.7]\n3.8667941\n4.521517\n\n\n(19.2,19.7]-(18.7,19.2]\n-4.9605207\n3.776710\n\n\n(19.7,20.1]-(19.2,19.7]\n-1.9599775\n3.519561\n\n\n(20.1,20.6]-(19.7,20.1]\n0.3464399\n3.780410\n\n\n(20.6,21.1]-(20.1,20.6]\n-1.5957303\n4.237894\n\n\n(21.1,21.6]-(20.6,21.1]\n-5.0362433\n4.232187\n\n\n(21.6,22]-(21.1,21.6]\n5.4781291\n5.776997\n\n\n(22,22.5]-(21.6,22]\n-0.4791768\n6.476697\n\n\n(22.5,23]-(22,22.5]\n-11.8458333\n6.644515\n\n\n(23,23.4]-(22.5,23]\n4.8083476\n8.661194\n\n\n(23.4,23.9]-(23,23.4]\n15.0916951\n8.827486\n\n\n(23.9,24.4]-(23.4,23.9]\n17.8749390\nNA\n\n\n(24.4,24.9]-(23.9,24.4]\n-25.6499634\nNA\n\n\n(24.9,25.3]-(24.4,24.9]\n-8.8166707\nNA\n\n\n(25.3,25.8]-(24.9,25.3]\n17.1916097\n14.589449\n\n\n\n\n\nSi noti che per prima riga la differenza delle medie è NA. Il motivo è che non c’è un intervallo con valori più piccoli di per poter calcolare la differenza. La seconda riga ci dice che \\[\n\\overline{testscr}_{str \\in (14.5,14.9]} - \\overline{testscr}_{str \\in (14,14.5]}  = 35.0249939,\n\\] e che quindi scuole con classi con \\((14.5,14.9]\\) studenti per insegnante hanno punteggi più alti di circa 35.0249939 punti rispetto a quelle con \\(str\\in (14,14.5]\\). Questo valore positivo (classi più piccole hanno test score più bassi) e molto grande (quasi due volte la deviazione standard dei punteggi in tutto il campione) è dovuto al fatto che stiamo stimando la differenza dei valori attesi usando soltanto 4 scuole. Un numero troppo esigue per aspettarci che la stima sia in qualche modo “vicina” a quella che potremmo stimare se avessimo a disposizione i dati nel campione.\nLa terza riga ci dice che \\[\n\\overline{testscr}_{str \\in (14.9,15.4]} - \\overline{testscr}_{str \\in (14.5,14.9]}  = -12.0166524,\n\\] e che quindi scuole con \\(str\\in (14.9,15.4]\\) hanno punteggi più alti di circa -12.0166524 punti rispetto a quelle con \\(str\\in (14.5,14.9]\\). E così via per le altre righe.\nE’ molto probabile che tutte le stime e non soltanto quelle della prima riga siano particolarmente imprecise visto che sono tutte basate su un numero esiguo di osservazioni. Per quantificare la loro precisione, o la loro imprecisione, possiamo costruire l’intervallo di confidenza (al 95%) per ciascun valore dell’intervallo di \\(str\\). L’intervallo di confidenza al 95% è:\n\nc(df_3$Delta_testscr - 1.96 * df_3$stderr,\n  df_3$Delta_testscr + 1.96 * df_3$stderr)\n\ndove stderr è l’errore standard della differenza delle media che è stato calcolato nel precdedente blocco di codice.\nPer aggiungere l’intervallo di confidenza a df_3 possiamo usare dplyr e la funzione mutate:\n\ndf_3 &lt;- df_3 |&gt;\n1  mutate(ci_sx = Delta_testscr - 1.96 * stderr,\n2         ci_dx = Delta_testscr + 1.96 * stderr)\n\nkable(df_3)\n\n\n1\n\nl’estremo sinistro dell’intervallo di confidenza;\n\n2\n\nl’estremo destro dell’intervallo di confidenza;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDelta_str\nDelta_testscr\nstderr\nci_sx\nci_dx\n\n\n\n\n(14,14.5]-NA\nNA\nNA\nNA\nNA\n\n\n(14.5,14.9]-(14,14.5]\n35.0249939\n17.650880\n0.4292697\n69.620718\n\n\n(14.9,15.4]-(14.5,14.9]\n-12.0166524\n18.119279\n-47.5304392\n23.497134\n\n\n(15.4,15.9]-(14.9,15.4]\n-2.6283122\n13.406411\n-28.9048769\n23.648253\n\n\n(15.9,16.4]-(15.4,15.9]\n-8.9675232\n17.351552\n-42.9765654\n25.041519\n\n\n(16.4,16.8]-(15.9,16.4]\n-1.0624949\n17.063496\n-34.5069476\n32.381958\n\n\n(16.8,17.3]-(16.4,16.8]\n-1.2799978\n9.116243\n-19.1478335\n16.587838\n\n\n(17.3,17.8]-(16.8,17.3]\n6.7216634\n7.597797\n-8.1700183\n21.613345\n\n\n(17.8,18.2]-(17.3,17.8]\n-0.8596676\n6.063179\n-12.7434989\n11.024164\n\n\n(18.2,18.7]-(17.8,18.2]\n-5.7208842\n5.626609\n-16.7490376\n5.307269\n\n\n(18.7,19.2]-(18.2,18.7]\n3.8667941\n4.521517\n-4.9953794\n12.728967\n\n\n(19.2,19.7]-(18.7,19.2]\n-4.9605207\n3.776710\n-12.3628722\n2.441831\n\n\n(19.7,20.1]-(19.2,19.7]\n-1.9599775\n3.519561\n-8.8583162\n4.938361\n\n\n(20.1,20.6]-(19.7,20.1]\n0.3464399\n3.780410\n-7.0631635\n7.756043\n\n\n(20.6,21.1]-(20.1,20.6]\n-1.5957303\n4.237894\n-9.9020023\n6.710542\n\n\n(21.1,21.6]-(20.6,21.1]\n-5.0362433\n4.232187\n-13.3313288\n3.258842\n\n\n(21.6,22]-(21.1,21.6]\n5.4781291\n5.776997\n-5.8447856\n16.801044\n\n\n(22,22.5]-(21.6,22]\n-0.4791768\n6.476697\n-13.1735022\n12.215148\n\n\n(22.5,23]-(22,22.5]\n-11.8458333\n6.644515\n-24.8690823\n1.177416\n\n\n(23,23.4]-(22.5,23]\n4.8083476\n8.661194\n-12.1675926\n21.784288\n\n\n(23.4,23.9]-(23,23.4]\n15.0916951\n8.827486\n-2.2101770\n32.393567\n\n\n(23.9,24.4]-(23.4,23.9]\n17.8749390\nNA\nNA\nNA\n\n\n(24.4,24.9]-(23.9,24.4]\n-25.6499634\nNA\nNA\nNA\n\n\n(24.9,25.3]-(24.4,24.9]\n-8.8166707\nNA\nNA\nNA\n\n\n(25.3,25.8]-(24.9,25.3]\n17.1916097\n14.589449\n-11.4037108\n45.786930\n\n\n\n\n\nCome si vede chiaramente dall’analisi della tabella, tutti gli intervalli di confidenza sono molto ampi. Come preannunciato, i dati a nostra disposizione non sono abbastanza informativi per poter stimare tutte le differenze su intervalli così poco numerosi. Anche nel caso in cui considerassimo la differenza delle medie in scuole con \\(str\\in(18.7,19.2]\\) (27 scuole) e scuole con \\(str\\in (18.2,18.7]\\) (47 scuole), l’intervallo di confidenza è molto ampio: \\((-4.9953794, 12.7289675)\\). Un intervallo di confidenza così ampio implica che non possiamo neanche quantificare con l’appropriata confidenza il segno della differenza che potrebbe essere -12 o 2.\nLa rappresentazione grafica delle informazioni contenute in una tavole facilita spesso la comprensione dei risultati.\n\n1ggplot(df_3, aes(x=Delta_str,y=Delta_testscr)) +\n2  geom_pointrange(aes(ymin=ci_sx, ymax=ci_dx)) +\n3  geom_hline(yintercept = 0, col = \"darkred\") +\n  theme_bw() +\n  xlab(\"Intervalli str\") + ylab(\"Delta Media testscr\") +\n4  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n1\n\nsull’ascissa abbiamo la differenza degli intervalli, sull’ordinata la differenza delle medie;\n\n2\n\nla geometria utilizzata è geom_pointrange, che “plotta” la differenza delle medie (il punto) e l’intervallo di confidenza al 95% definito da ((ci_sx, ci_dx)) e rappresentato dalle linee che si estendono verticalmente.\n\n3\n\ngeom_hline(yintercept=0, col = \"darkred\") produce una riga orizzonate di colore rosso scuro\n\n4\n\nle etichette dell’asse della x sono ruotate di 90 gradi per favorire la loro leggibilità.\n\n\n\n\n\n\n\nIl grafico mostra che:\n\nLa stima di molte delle differenze è negativa\nTutti gli intervalli di confidenza sono troppo ampi per poter concludere con l’appropriata confidenza che il valore della differenza nella popolazione è di uno specifico segno\nIn tre casi non è possibile costruire l’intervallo di confidenza."
  },
  {
    "objectID": "Modelli.html",
    "href": "Modelli.html",
    "title": "Il modello lineare univariato",
    "section": "",
    "text": "“Ceteris paribus” è una locuzione latina che significa “a parità d’altre condizioni”, “date le medesime circostanze”. Viene spesso utilizzata in economia e in altri campi scientifici per descrivere la situazione in cui alcuni fattori di un sistema siano mantenuti costanti o invariati durante l’analisi dell’impatto di altri fattori su una variabile di interesse. L’effetto “ceteris paribus” di un aumento del prezzo di un bene porterà a una diminuzione della sua domanda” – questo effetto è calcolato assumendo che gli altri fattori che influenzano la domanda, come il reddito e le preferenze dei consumatori, rimangano invariate. L’obiettivo dell’econometria che studieremo è quello di utilizzare i dati per stimare effetti ceteris paribus di una variabile (o di più variabili) su unàaltra variabile.\nPer comprendere le tecniche econometriche che introdurremo è essenziale definire con precisione il concetto di modello econometrico e la sua derivazione.\n\n\nPer poter provare a stimare l’effetto ceteris paribus di una variabile su un’altra occorre definire precisamente qual è in nostro obiettivo in termini matematici. Inizieremo postulando l’esistenza di un modello, il modello vero, che lega la variabile \\(Y\\) ad altre variabili. \\[\nY = f^*(X_1, \\ldots, X_k, W_1, \\dots, W_r).\n\\tag{1}\\] Equazione 1 definisce il vero meccanismo di determinazione della variabile \\(Y\\) sulla base delle \\(k\\) variabili \\(X_1,\\dots,X_k\\) e delle \\(r\\) variabili \\(W_1,\\dots,W_k\\); \\(f^*\\) è una funzione multivariata che descrive il meccanismo di determinazione. La ragione per cui stiamo usando una diversa notazione per le \\(k\\) e le \\(r\\) variabile è per sottolineare la loro diversa natura. Le variabili \\(X_1,\\dots,X_k\\) sono osservabili, cioè è possibile ottenere dati per queste variabili. Le variabili \\(W_1,\\dots,W_r\\) sono invece non-osservabili, cioè non è possibile raccogliere delle osservazioni.\nEquazione 1 potrebbe rappresentare il meccanismo con cui il salario di un individuo \\(Y\\) viene determinato dal livello di istruzione (\\(X_1\\)), dall’età \\(X_2\\), dal genere (\\(X_3\\)), dall’esperienza (\\(X_4\\)) e da altre variabili osservabili. A determinare il salario contribuisce anche l’abilità dell’individuo (\\(W_1\\)). Abilità è una variabile che non osserviamo, cioè non esiste nessuna dataset che contiene questa informazioni ecco perché è relegata fra le \\(W\\).\nE’ conveniente assumere una particolare struttura del modello. Assumeremo in particolare che il vero modello può essere scritto in questo modo: \\[\nY = g^*(X_1, \\ldots, X_k) + h^*(W_1, \\dots, W_r).\n\\tag{2}\\] In Equazione 2 il modello ha due componenti additive: \\(g^*\\) è una funzione che ha come argomenti le sole variabili osservabili, mentre \\(h^*\\) è una funzione delle sole variabili osservabili. L’effetto di un variazione di \\(X_1\\) da \\(x_1\\) a \\(x_1'\\) tenendo costanti le altre variabili a \\(X_2=x_2,\\dots, X_k=x_k\\) e \\(W_1=w_1,\\dots, W_k=w_k\\) secondo il modello in Equazione 2 è \\[\ng^*(x', \\ldots, x_k) - g^*(x, \\ldots, x_k).\n\\] Questo effetto in genere dipenderà da \\(x\\) e \\(x'\\), ma anche da i valori a cui sono tenute tutte le variabili osservabili, mentre non dipende dai valori ai quali abbiamo tenuto costanti le variabili osservabili \\(w_1, w_2, \\dots, w_k\\).\nSupponiamo adesso che usando la teoria economica, il buon senso, l’intuizione ed un po’ di fortuna il modello che abbiamo in mente coincida per le variabili osservabili con quello dell’?@eq-eq-truth2. Il modello econometrico diventa \\[\nY = g^*(X_1, \\ldots, X_k) + u\n\\] dove \\(u=h^*(W_1, \\dots, W_r)\\) è la componente non osservata del modello.\nConsideriamo un individuo con \\((Y_i, X_{i1}, \\dots, x_{ik})\\). Secondo il modello econometrico \\[\nY_i = g^*(X_{i1}, \\ldots, X_{ik}) + u_i\n\\] dove \\(u_i\\) è una variabile casuale perche il suo valore dipende dai valori non osservati per l’individuo \\(i\\).\nNon ha senso chiederci qual è il valore di \\(Y\\) associato con x’ e compagnia: non esiste un unico valore perché \\(Y_i\\) prenderà gli stessi valore a seconda dei valori di \\(W_1,\\dots,W_r\\), Questi valori sono casuali non non observabili e quindi non possiamo fissarli ad un valore. Quello che possiamo fare è chiederci e se \\(E(Y_i\\)\nSe calcoliamo il valore di \\(Y\\) corrispondente a \\(X_1=x_1'\\), e \\(X_2=x_2\\), \\(X_k=x_k\\).\nMa in questo modello non riusciremo a fissare i valori delle variabili non osservabili. Per esempio, il valore di \\(Y\\) è\nessendo osservabile è \\(W_1\\)Potrebbe essere chiaramente determinato da Il livello di istruzione di un individuo è considerato un fattore chiave nella determinazione del suo reddito/salario. Tuttavia, ci sono anche altri fattori che possono influenzare il salario. Se indichiamo con \\(Y\\) il salario, con \\(X_1\\) il livello di istruzione (parleremo poi di cosa intendiamo per livello di istruzione) e con \\(X_2\\), \\(X_3\\), \\(\\ldots\\), \\(X_k\\) gli altri fattori, possiamo pensare alla relazione come\nIn altre parole, avremo soltanto a disposizione dati su \\(Y\\) e \\(X\\).\ndi cui vogliamo variabile \\(Y\\) ad altre variabili\nprrecisi definire adeguatamente i\nIl livello di istruzione di un individuo è considerato un fattore chiave nella determinazione del suo reddito/salario. Tuttavia, ci sono anche altri fattori che possono influenzare il salario. Se indichiamo con \\(Y\\) il salario, con \\(X_1\\) il livello di istruzione (parleremo poi di cosa intendiamo per livello di istruzione) e con \\(X_2\\), \\(X_3\\), \\(\\ldots\\), \\(X_k\\) gli altri fattori, possiamo pensare alla relazione come \\[\nY = f(X_1, X_2, X_3, X_4, X_5, X_6, X_7,\\ldots,X_k).\n\\tag{3}\\] Per esempio, \\(X_3\\) potrebbe rappresentare l’esperienza lavorativa dell’individuo, \\(X_4\\) il genere (maschio/femmina) e \\(X_5\\) l’età, \\(X_6\\) la il settore dell’impiego, \\(X_7\\) l’abilità dell’individuo e così via discorrendo. Equazione 3 definisce un modello, cioè una descrizione matematica di un meccanismo di determinazione della variabile \\(Y\\). La quasi totalità dei modelli economici può essere espressa in una maniera analoga all’Equazione 3.\nCome si fa a giungere al modello dell’Equazione 3? Tipicamente ci si appella alla teoria economica. Per esempio, la teoria per la scelta del livello di istruzione, basata sulla massimizzazione dell’utilità nel corso della vita, postula che gli individui sceglieranno un livello di istruzione tale per cui il costo marginale di un’unità addizionale di istruzione è uguale al suo beneficio marginale. Costi e benefici marginali dipendono direttamente e indirettamente da una serie di fattori specifici all’individuo (le \\(X\\) in Equazione 3). La teoria non suggerisce direttamente la forma della funzione \\(f\\) a meno che non si facciano delle assunzioni sulle funzioni di utilità e altre assunzioni sulle forme funzionali di altri elementi che compongono la teoria. Spesso i modelli vengono postulati senza fare riferimento alla teoria e sembrano originare dal buon senso e dall’intuizione economica. In realtà, anche quando non esplicito il ruolo della teoria è importante.\nPer quanto sofisticata la teoria, le variabili \\(X_1, \\ldots, X_k\\) potrebbero non essere le sole a contribuire alla determinazione di \\(Y\\). In fin dei conti, Il ruolo di un modello è quello di stilizzare una realtà molto complessa, troppo complessa, rimuovendo i dettagli che sono poco importanti per la comprensione del meccanismo che ci interessa studiare. Il problema è che un’eccessiva o inopportuna semplificazione potrebbe rendere il modello poco utile per lo scopo per il quale è stato creato. Ci serve quindi un quadro di riferimento per comprendere se le semplificazioni adottate dal modello ci consentono comunque di ottenere relazioni ceteris paribus corrette. Chiaramente la definizione di modello corretto prevede la conoscenza dei veri effetti, ma se sapessimo i veri effetti modelli ed econometria non sarebbe necessari. Invece, partiamo da postulare il modello corretto: \\[\n  Y = h(X_1, \\dots, X_k, W_1, \\dots, W_r),\n   \\tag{4}\\] La differenza fra il vero modello e quello dell’Equazione 3 è la presenza della variabili \\(W_1, W_2, \\dots, W_r\\) e del fatto che la funzione che descrive le relazioni è \\(h\\). E’ importante sottolineare che il modello in Equazione 5 non può essere effettivamente utilizzato; è semplicemente una pietra di paragone per capire quando il nostro modello in Equazione 3 può catturare le stesse relazioni ceteris paribus del modello in Equazione 5. Chiameremo le variabili \\(W_1, W_2, \\dots, W_r\\) non osservabili sia perchè non possono essere misurate (in questo caso )\nIl modello economico potrebbe essere troppo generico e le variabili individuate sono un solo sottoinsieme di quelle che effettivamente contribuiscono alla determinazione di \\(Y\\). La nostra intuizione e il nostro buon senso essendo limitati ci portano a trascurate importanti variabili. Il vero modello per \\(Y\\) è dunque \\[\n  Y = h(X_1, \\dots, X_k, W_1, \\dots, W_r),\n   \\tag{5}\\] dove \\(W_1, W_2, \\dots, W_r\\) sono le variabili che non abbiamo considerato in Equazione 3 e \\(h\\) è una funzione che esplicita la loro relazione. E’ importante sottolineare che quest’ultimo modello non sarà quello utilizzato proprio perché non conosciamo cosa siano \\(W_1, W_2, \\dots, W_r\\). Questo modello ci servirà esclusivamente come pietra di paragone per capire se il modello basato sulle variabili in Equazione 3 può catturare le stesse relazioni ceteris paribus del modello in Equazione 5. descrive il vero modello, allora \\[\n  CPE(x,x')=\\Delta_{f}(x,x')+\\Delta_{\\varepsilon}(x,x'),\n  \\] dove \\[\n  \\begin{align*}\n  \\Delta_{f}(x,x') & =E\\left[f(X_{1},\\dots,X_{k})|X_{1}=x'_{1},X_{2}=x_{2},\\ldots,W_{1}=w_{1},\\ldots,W_{r}=w_{r}\\right]\\\\\n& \\qquad-E\\left[f(X_{1},\\dots,X_{k},W_{1},W_{2},\\dots,W_{r})|X_{1}=x_{1},X_{2}=x_{2},\\ldots,W_{1}=w_{1},\\ldots,W_{r}=w_{r}\\right]\n  \\end{align*}\n  \\] e \\[\n  \\Delta_{\\varepsilon}(x,x')=E\\left[\\varepsilon|X_{1}=x'_{1},X_{2}=x_{2},\\ldots,W_{1}=w_{1},\\ldots,W_{r}=w_{r}\\right]-E\\left[\\varepsilon|X_{1}=x{}_{1},X_{2}=x_{2},\\ldots,W_{1}=w_{1},\\ldots,W_{r}=w_{r}\\right]\n  \\] Andiamo a definire adesso l’effetto ceteris paribus di un variazione, da \\(x_1\\) a \\(x_1'\\) usando il modello in Equazione 3. Questo è dato dalle seguente differenza nelle aspettative condizionali:\n\\[\n  E\\left[f(X_1,\\dots,X_k)|X_1 = x'_1, X_2=x_2, \\ldots, W_1=w_1,\\ldots, W_r=w_r\\right] - E\\left[f(X_1, \\dots, X_k, W_1, W_2, \\dots, W_r)|X_1 = x_1, X_2=x_2, \\ldots, W_1=w_1,\\ldots, W_r=w_r\\right].\n  \\]\nè dato dalla della funzione \\(h\\) quando una variabile, diciamo \\(X_1\\), mentre le altre rimangono costanti. Formalmente, \\[\n  h(X_1+\\Delta X_1, \\dots, X_k, W_1, W_2, \\dots, W_r) - h(X_1+\\Delta X_1, \\dots, X_k, W_1, W_2, \\dots, W_r).\n  \\] Come detto, quello che potremmo fare\n### Ceteris Paribus effect L’effetto ceteris paribus di un aumento\nSe il modello in Equazione 3 è postulato a partire dall’intuizione economica, in \\(u\\) confluiscono altre variabili che non abbiamo erroneamente preso in considerazione. L’idea è che il vero meccanismo è \\[\n  Y = h(X_1, \\dots, X_k, W_1, W_2, \\dots, W_r),\n  \\] per una qualche funzione \\(h\\). Possiamo esprimere questo modello in termini del modello\nLa teoria economica può essere utilizzata come punto di partenza per specificare sia la forma funzionale di \\(f\\) sia i fattori rilevanti per la determinazione del salario. Il modello teorico spesso utilizzato per studiare la relazione fra salari e livelli di educazione è quello in cui la scelta del livello di istruzione è dettata dalla massimizzazione dell’utilità nel corso della vita. Secondo questo modello gli individui sceglieranno un livello di istruzione tale per cui i costi marginali di una addizionale di istruzione sono uguali ai benefici marginali. Oltre a dipendere dal livello di istruzione questi costi e benefici dipendono dipendono direttamente e indirettamente da una serie di fattori specifici all’individuo (le \\(X\\) in Equazione 3). Alternativamente le variabili che influenzano il salario potrebbero essere dettate dal buon senso e non da una rigorosa analisi economica.\nQuale che sia l’approccio per definire queste variabili, ricordiamoci che l’obiettivo non è fornirne un elenco. L’obiettivo è quello di quantificare mediante l’utilizzo di dati la relazione fra queste variabili e, in questo esempio, la relazione fra istruzione e salario. Chiaramente questo richiede di specificare una forma funzionale per \\(f\\), cioè fare delle assunzione affinché sia possibile poter determinare queste relazioni.\nLa specificazione della forma funzionale è una assunzione sia che derivi dalla teoria sia che provenga dalla nostra fantastica intuizione. Ma andiamo per ordine. Potremmo iniziare postulando che \\[\nY = \\beta_0 + \\beta_1 X_{1} + \\beta_2 X_{2} + \\ldots + \\beta_k X_{k} + u\n\\tag{6}\\] dove \\(\\beta_0, \\beta_1, \\ldots, \\beta_k\\) sono i parametri del modello e \\(u\\) e il termine di errore. Qual è la relazione fra Equazione 3 e quaste nuova specificazione? Sono due le differenze. La prima è che abbiamo imposto una forma funzionale particolare scegliendo per \\(f\\) una forma lineare nelle variabili che comparivano in Equazione 3. La seconda è che contiene il termine di errore \\(u\\). Comprendere la natura di \\(u\\) è importantissimo e centrale per una corretta comprensione e interpretazione dei modelli econometrici.\nSchematicamente, l’errore comprende le seguenti componenti:\n\naltre variabili che potrebbero contribuire a determinare \\(Y\\) Le variabili \\(X_1, \\ldots, X_k\\) potrebbero non esaurire la lista di variabili che contribuiscono a determinare \\(Y\\). Questo perchè il modello economico è così generico che le variabili individuate sono sono un sottoinsieme di quelle che effettivamente contribuiscono alla determinazione di \\(Y\\). Se il modello in Equazione 3 è postulato a partire dall’intuizione economica, in \\(u\\) confluiscono altre variabili che non abbiamo erroneamente preso in considerazione. L’idea è che il vero meccanismo è \\[\n  Y = h(X_1, \\dots, X_k, W_1, W_2, \\dots, W_r),\n  \\] per una qualche funzione \\(h\\). Possiamo esprimere questo modello in termini del modello\nIn questo caso, abbiamo che\nerrore di approssimazione, cioè la differenza fra il modello lineare e il vero modello non lineare\n\nQueste assunzioni devono essere funzionali ai dati che abbiamo a disposizione. Supponiamo per il momento di avere a disposizioni un campione di individui (assumeremo sempre che il campione sia estratto casualmente dalla popolazione di riferimento) per i quali conosciamo soltanto il salario e il livello di istruzione. Cioè il nostro campione, di dimension \\(n\\) è \\({(Y_i, X_{1i}), (Y_1, X_{11}), \\ldots, ((Y_n, X_{n1}))}\\).\n. Questo ha il vantaggio di rendere l’analisi più agile (spesso introdurre fattori coerentemente in un modello teorico è tecnicamente difficile), ma le derivazioni formali possono fornire una intuizione a cui il nostro buon senso non sarebbe mai giunto. Entrambi gli approcci sono seguiti in econometria. Quando i meccanismi e relazioni sono modellati sulla base della teoria economica parliamo di econometria strutturale. Quando invece le relazioni sono modellate sulla base dell’intuizione senza un preciso riferimento alla teoria economica parliamo di modelli a forma ridotta (reduced form). Quest’ultimo tipo di modelli è esplicitamente disegnato per l’analisi empirica e si basano su una descrizione più semplice e sintetica delle relazioni tra le variabili. Sebbene molti degli strumenti presentati di seguito sono tendenzialmente ispirati dai modelli a forma ridotta, molte delle tecniche possono essere impiegati nel campo dei modelli strutturali. Semplificando\nQualunque sia l’approccio che ha generato la specificazione in Equazione 3,\n\n\n\nIl modello di regressione lineare assume una relazione lineare tra la variabile indipendente \\(X\\) e la variabile dipendente \\(Y\\), che può essere espressa come segue: \\[Y = \\beta_0 + \\beta_1 X + u, \\tag{7}\\] dove \\(\\beta_0\\) e \\(\\beta_1\\) rappresentano parametri sconosciuti e \\(u\\) è l’errore di regressione. L’errore \\(u\\) incorpora tutti i fattori (o variabili) che influenzano \\(Y\\) ma non sono inclusi nel modello lineare.\nPrendiamo, ad esempio, il modello lineare che descrive la relazione tra i punteggi dei test (\\(Y\\)) e la dimensione delle classi (\\(X\\)). Ci sono numerosi fattori che influenzano i risultati dei test, tra cui la qualità degli insegnanti, la motivazione degli studenti, le competenze linguistiche degli alunni e le risorse della scuola. Questi fattori confluiscono nell’errore poiché non sono direttamente inclusi nel modello.\nUn altro esempio di regressione lineare è la relazione tra il reddito di un individuo (\\(Y\\)) e il livello di istruzione (\\(X\\)). Anche in questo caso, ci sono molteplici fattori che influenzano il reddito di un individuo, come l’esperienza lavorativa, le abilità personali e il settore in cui si lavora. Questi fattori non inclusi nel modello lineare confluiscono nel termine di errore \\(u\\).\nQuando riferite al modello in Equazione 7, le variabili \\(Y\\) e \\(X\\) prendono diversi nomi spesso utilizzati in modo intercambiabile. \\(Y\\) viene chiamata variabile dipendente, variabile da spiegare o variabile. La variabile \\(X\\) viene chiamata variabile indipendente, variabile esplicativa, variabile di controllo, variabile predittiva o regressore. Più infrequentemente ci si riferisce a \\(X\\) con il termine covariata. I termini “variabile dipendente” e “variabile indipendente” sono frequentemente utilizzati in econometria. Tuttavia, si noti che “indipendente” non si riferisce in questo caso alla nozione statistica di indipendenza tra variabili casuali.\nLa scelta di utilizzare un modello lineare è ovviamente una semplificazione. Linearità implica che una variazione di una unità di \\(X\\) abbia lo stesso effetto su \\(Y\\), indipendentemente dal valore iniziale di \\(X\\). Questo è irrealistico per molte applicazioni economiche. Ad esempio, nell’esempio del salario-educazione, potremmo voler consentire dei rendimenti crescenti: un anno addizionale di istruzione potrebbe infatti avere un effetto maggiore sul salario se quell’anno è speso in un master piuttosto che uno scuola media.\nSono diverse le ragione per questa semplificazione. Prima di tutto, i modelli lineari sono matematicamente semplici e facili da interpretare, il che rende l’analisi più accessibile anche per chi non ha un background matematico avanzato. Il modello lineare consente di valutare la relazione tra le variabili sotto assunzioni trasparenti e permette anche di predire \\(Y\\) sulla base del valore di \\(X\\) molto semplicemente. Vedremo più avanti che sebbene la linearità sia un limite, il modello può essere modificato al fine di tenere in considerazione la presenza di relazioni non-lineari.\n\n\n\nLa assunzione chiave del modello lineare è la seguente:\n\n\n\n\\(E(u|X) = 0\\)\n\n\nSi ricordi che se \\(E(u|X) = 0\\), allora \\(corr(u,X)=0\\). Quindi, questa assunzione stipula che la variabile inclusa del modello, \\(X\\), e altre variabili che hanno una qualche relazione con \\(Y\\) e contenute in \\(u\\) non sono correlate.\nQuesta è un’assunzione molto forte e, come vedremo, in molte applicazioni non potrà essere considerata valida. In ogni caso, inizieremo a studiare il modello lineare sotto questa assunzione per comprendere la sua logica. In seguito, ci chiederemo come sia possibile interpretare il modello quando l’assunzione non è soddisfatta.\nLa fondamentale implicazione di (ass-key?) è che l’aspettativa condizionale di \\(Y\\) dato \\(X\\) è lineare in \\(X\\), cioè \\[\nE(Y|X) = \\beta_0 + \\beta_1 X.\n\\] Usando questa linearità possiamo ottenere l’interpretazione del parametro \\(\\beta_1\\): \\[\nE(Y|X=x+1) - E(Y|X=x) = \\left[\\beta_0 + \\beta_1 (x+1)\\right]  - \\left[\\beta_0 + \\beta_1 x\\right] = \\beta_1,\n\\] \\(\\beta_1\\) ci dà la risposta di \\(E(Y|X)\\) ad una variazione unitaria (da \\(x\\) a \\(x+1\\)) di \\(X\\).\n::: {.boxmore} Anche \\(\\beta_0\\) ha una interpretazione in termini del valore atteso condizionato di \\(Y\\): \\[\\beta_0 = E(Y|X=0). \\tag{8}\\] Sebbene formalmente corretta, l’interpretazione pratica dell’intercetta è resa problematica da due fatti: (i) in molte applicazione, la variabile \\(X\\) non assume il valore \\(0\\). Se il modello lineare della dimensione delle aule e potrebbe non assumere il valore \\(\\beta_0\\) assorbe la media delle variabile omesse. Cosa succede se invece che uguale a zero, l’aspettativa di \\(u\\) dato \\(X\\) è uguale ad una costante, per esempio \\(E(u|X)=5\\), o \\(E(u|X)=15\\). In questo caso è normale pensare che (ass-key?) non sia valida e l’interpretazione di \\(\\beta_1\\) non sarà quella di quantificare l’effetto di una variazione unitaria sul valore atteso condizionato di \\(Y\\). In realtà le cose sono un tantino più complicate. Proviamo a capire perché. Se \\(E(u|X)=\\kappa_u\\) per qualche valore \\(\\kappa_u\\), abbiamo che \\[\nE(Y|X) = E(\\beta_0 + \\beta_1 X + \\kappa_u|X) = \\beta_0 + \\beta_1 X + \\kappa_u.\n\\] L’aspettativa condizionata è ancora lineare, ma con un intercetta uguale a \\(\\beta_0 + \\kappa_u\\). In ogni caso, l’interpretazione di \\(\\beta_1\\) è invariata rispetta al caso in cui \\(\\kappa_u=0\\) (cioè nel caso specificato dall’{#ass-key}), come si vede chiaramente da \\[\nE(Y|X=x+1) - E(Y|X=x) = \\left[\\beta_0 + \\beta_1 (x+1) + \\kappa_u\\right]  - \\left[\\beta_0 + \\beta_1 x + \\kappa_u\\right] = \\beta_1.\n\\] A questo punto è lecito essere confusi. Abbiamo parlato più volte della centralità dell’assunzione \\(E(u|X)=0\\), ma adesso sembrerebbe che l’interpretazione di \\(\\beta_1\\) è sempre \\(E(Y|X=x+1) - E(Y|X=x)\\) anche quando \\(E(u|X)=\\kappa_u \\neq 0\\). Ora consideriamo il modello lineare data da \\[\nY = \\beta_0 + \\beta_1 X_i + \\varepsilon_i,\n\\] dove \\(\\varepsilon_i=u_i-\\kappa_u\\). In questo modello l’errore è uguale all’errore originale, \\(u_i\\), a cui abbiamo sottratto \\(\\kappa_u\\). Questo è un nuovo modello lineare che soddisfa (ass-key?) — \\(E(\\varepsilon_i|X)=E(u_i|X)-\\kappa_u=\\kappa_u - \\kappa_u = 0\\) — e dove \\(\\beta_1=E(Y|X=x+1) - E(Y|X=x)\\)$ è\nIn realtà, l’assunzione necessaria per interpretare \\(\\beta_1\\) come la variazione di \\(E(Y|X)\\) dovuta ad una variazione di \\(X\\) è \\[\nE(u|X) = \\text{constant}.\n\\] Sembrerebbe che L’assunzione è falsa non quando \\(E(u|X)\\neq 0\\), ma quando il valore atteso di \\(u\\) dato \\(X\\) varia con \\(X\\). In altre parole, l’assunzione #ass-key non è soddisfatta se \\[\nE(u|X=x) = f(x),\n\\] dove \\(f(\\cdot)\\) è una funzione non constante, cioè una funzione tale per cui \\(f(x_1)\\neq f(x_2)\\) per almeno una coppia di valori \\(x_1\\), \\(x_2\\)."
  },
  {
    "objectID": "Modelli.html#il-modello-vero",
    "href": "Modelli.html#il-modello-vero",
    "title": "Il modello lineare univariato",
    "section": "",
    "text": "Per poter provare a stimare l’effetto ceteris paribus di una variabile su un’altra occorre definire precisamente qual è in nostro obiettivo in termini matematici. Inizieremo postulando l’esistenza di un modello, il modello vero, che lega la variabile \\(Y\\) ad altre variabili. \\[\nY = f^*(X_1, \\ldots, X_k, W_1, \\dots, W_r).\n\\tag{1}\\] Equazione 1 definisce il vero meccanismo di determinazione della variabile \\(Y\\) sulla base delle \\(k\\) variabili \\(X_1,\\dots,X_k\\) e delle \\(r\\) variabili \\(W_1,\\dots,W_k\\); \\(f^*\\) è una funzione multivariata che descrive il meccanismo di determinazione. La ragione per cui stiamo usando una diversa notazione per le \\(k\\) e le \\(r\\) variabile è per sottolineare la loro diversa natura. Le variabili \\(X_1,\\dots,X_k\\) sono osservabili, cioè è possibile ottenere dati per queste variabili. Le variabili \\(W_1,\\dots,W_r\\) sono invece non-osservabili, cioè non è possibile raccogliere delle osservazioni.\nEquazione 1 potrebbe rappresentare il meccanismo con cui il salario di un individuo \\(Y\\) viene determinato dal livello di istruzione (\\(X_1\\)), dall’età \\(X_2\\), dal genere (\\(X_3\\)), dall’esperienza (\\(X_4\\)) e da altre variabili osservabili. A determinare il salario contribuisce anche l’abilità dell’individuo (\\(W_1\\)). Abilità è una variabile che non osserviamo, cioè non esiste nessuna dataset che contiene questa informazioni ecco perché è relegata fra le \\(W\\).\nE’ conveniente assumere una particolare struttura del modello. Assumeremo in particolare che il vero modello può essere scritto in questo modo: \\[\nY = g^*(X_1, \\ldots, X_k) + h^*(W_1, \\dots, W_r).\n\\tag{2}\\] In Equazione 2 il modello ha due componenti additive: \\(g^*\\) è una funzione che ha come argomenti le sole variabili osservabili, mentre \\(h^*\\) è una funzione delle sole variabili osservabili. L’effetto di un variazione di \\(X_1\\) da \\(x_1\\) a \\(x_1'\\) tenendo costanti le altre variabili a \\(X_2=x_2,\\dots, X_k=x_k\\) e \\(W_1=w_1,\\dots, W_k=w_k\\) secondo il modello in Equazione 2 è \\[\ng^*(x', \\ldots, x_k) - g^*(x, \\ldots, x_k).\n\\] Questo effetto in genere dipenderà da \\(x\\) e \\(x'\\), ma anche da i valori a cui sono tenute tutte le variabili osservabili, mentre non dipende dai valori ai quali abbiamo tenuto costanti le variabili osservabili \\(w_1, w_2, \\dots, w_k\\).\nSupponiamo adesso che usando la teoria economica, il buon senso, l’intuizione ed un po’ di fortuna il modello che abbiamo in mente coincida per le variabili osservabili con quello dell’?@eq-eq-truth2. Il modello econometrico diventa \\[\nY = g^*(X_1, \\ldots, X_k) + u\n\\] dove \\(u=h^*(W_1, \\dots, W_r)\\) è la componente non osservata del modello.\nConsideriamo un individuo con \\((Y_i, X_{i1}, \\dots, x_{ik})\\). Secondo il modello econometrico \\[\nY_i = g^*(X_{i1}, \\ldots, X_{ik}) + u_i\n\\] dove \\(u_i\\) è una variabile casuale perche il suo valore dipende dai valori non osservati per l’individuo \\(i\\).\nNon ha senso chiederci qual è il valore di \\(Y\\) associato con x’ e compagnia: non esiste un unico valore perché \\(Y_i\\) prenderà gli stessi valore a seconda dei valori di \\(W_1,\\dots,W_r\\), Questi valori sono casuali non non observabili e quindi non possiamo fissarli ad un valore. Quello che possiamo fare è chiederci e se \\(E(Y_i\\)\nSe calcoliamo il valore di \\(Y\\) corrispondente a \\(X_1=x_1'\\), e \\(X_2=x_2\\), \\(X_k=x_k\\).\nMa in questo modello non riusciremo a fissare i valori delle variabili non osservabili. Per esempio, il valore di \\(Y\\) è\nessendo osservabile è \\(W_1\\)Potrebbe essere chiaramente determinato da Il livello di istruzione di un individuo è considerato un fattore chiave nella determinazione del suo reddito/salario. Tuttavia, ci sono anche altri fattori che possono influenzare il salario. Se indichiamo con \\(Y\\) il salario, con \\(X_1\\) il livello di istruzione (parleremo poi di cosa intendiamo per livello di istruzione) e con \\(X_2\\), \\(X_3\\), \\(\\ldots\\), \\(X_k\\) gli altri fattori, possiamo pensare alla relazione come\nIn altre parole, avremo soltanto a disposizione dati su \\(Y\\) e \\(X\\).\ndi cui vogliamo variabile \\(Y\\) ad altre variabili\nprrecisi definire adeguatamente i\nIl livello di istruzione di un individuo è considerato un fattore chiave nella determinazione del suo reddito/salario. Tuttavia, ci sono anche altri fattori che possono influenzare il salario. Se indichiamo con \\(Y\\) il salario, con \\(X_1\\) il livello di istruzione (parleremo poi di cosa intendiamo per livello di istruzione) e con \\(X_2\\), \\(X_3\\), \\(\\ldots\\), \\(X_k\\) gli altri fattori, possiamo pensare alla relazione come \\[\nY = f(X_1, X_2, X_3, X_4, X_5, X_6, X_7,\\ldots,X_k).\n\\tag{3}\\] Per esempio, \\(X_3\\) potrebbe rappresentare l’esperienza lavorativa dell’individuo, \\(X_4\\) il genere (maschio/femmina) e \\(X_5\\) l’età, \\(X_6\\) la il settore dell’impiego, \\(X_7\\) l’abilità dell’individuo e così via discorrendo. Equazione 3 definisce un modello, cioè una descrizione matematica di un meccanismo di determinazione della variabile \\(Y\\). La quasi totalità dei modelli economici può essere espressa in una maniera analoga all’Equazione 3.\nCome si fa a giungere al modello dell’Equazione 3? Tipicamente ci si appella alla teoria economica. Per esempio, la teoria per la scelta del livello di istruzione, basata sulla massimizzazione dell’utilità nel corso della vita, postula che gli individui sceglieranno un livello di istruzione tale per cui il costo marginale di un’unità addizionale di istruzione è uguale al suo beneficio marginale. Costi e benefici marginali dipendono direttamente e indirettamente da una serie di fattori specifici all’individuo (le \\(X\\) in Equazione 3). La teoria non suggerisce direttamente la forma della funzione \\(f\\) a meno che non si facciano delle assunzioni sulle funzioni di utilità e altre assunzioni sulle forme funzionali di altri elementi che compongono la teoria. Spesso i modelli vengono postulati senza fare riferimento alla teoria e sembrano originare dal buon senso e dall’intuizione economica. In realtà, anche quando non esplicito il ruolo della teoria è importante.\nPer quanto sofisticata la teoria, le variabili \\(X_1, \\ldots, X_k\\) potrebbero non essere le sole a contribuire alla determinazione di \\(Y\\). In fin dei conti, Il ruolo di un modello è quello di stilizzare una realtà molto complessa, troppo complessa, rimuovendo i dettagli che sono poco importanti per la comprensione del meccanismo che ci interessa studiare. Il problema è che un’eccessiva o inopportuna semplificazione potrebbe rendere il modello poco utile per lo scopo per il quale è stato creato. Ci serve quindi un quadro di riferimento per comprendere se le semplificazioni adottate dal modello ci consentono comunque di ottenere relazioni ceteris paribus corrette. Chiaramente la definizione di modello corretto prevede la conoscenza dei veri effetti, ma se sapessimo i veri effetti modelli ed econometria non sarebbe necessari. Invece, partiamo da postulare il modello corretto: \\[\n  Y = h(X_1, \\dots, X_k, W_1, \\dots, W_r),\n   \\tag{4}\\] La differenza fra il vero modello e quello dell’Equazione 3 è la presenza della variabili \\(W_1, W_2, \\dots, W_r\\) e del fatto che la funzione che descrive le relazioni è \\(h\\). E’ importante sottolineare che il modello in Equazione 5 non può essere effettivamente utilizzato; è semplicemente una pietra di paragone per capire quando il nostro modello in Equazione 3 può catturare le stesse relazioni ceteris paribus del modello in Equazione 5. Chiameremo le variabili \\(W_1, W_2, \\dots, W_r\\) non osservabili sia perchè non possono essere misurate (in questo caso )\nIl modello economico potrebbe essere troppo generico e le variabili individuate sono un solo sottoinsieme di quelle che effettivamente contribuiscono alla determinazione di \\(Y\\). La nostra intuizione e il nostro buon senso essendo limitati ci portano a trascurate importanti variabili. Il vero modello per \\(Y\\) è dunque \\[\n  Y = h(X_1, \\dots, X_k, W_1, \\dots, W_r),\n   \\tag{5}\\] dove \\(W_1, W_2, \\dots, W_r\\) sono le variabili che non abbiamo considerato in Equazione 3 e \\(h\\) è una funzione che esplicita la loro relazione. E’ importante sottolineare che quest’ultimo modello non sarà quello utilizzato proprio perché non conosciamo cosa siano \\(W_1, W_2, \\dots, W_r\\). Questo modello ci servirà esclusivamente come pietra di paragone per capire se il modello basato sulle variabili in Equazione 3 può catturare le stesse relazioni ceteris paribus del modello in Equazione 5. descrive il vero modello, allora \\[\n  CPE(x,x')=\\Delta_{f}(x,x')+\\Delta_{\\varepsilon}(x,x'),\n  \\] dove \\[\n  \\begin{align*}\n  \\Delta_{f}(x,x') & =E\\left[f(X_{1},\\dots,X_{k})|X_{1}=x'_{1},X_{2}=x_{2},\\ldots,W_{1}=w_{1},\\ldots,W_{r}=w_{r}\\right]\\\\\n& \\qquad-E\\left[f(X_{1},\\dots,X_{k},W_{1},W_{2},\\dots,W_{r})|X_{1}=x_{1},X_{2}=x_{2},\\ldots,W_{1}=w_{1},\\ldots,W_{r}=w_{r}\\right]\n  \\end{align*}\n  \\] e \\[\n  \\Delta_{\\varepsilon}(x,x')=E\\left[\\varepsilon|X_{1}=x'_{1},X_{2}=x_{2},\\ldots,W_{1}=w_{1},\\ldots,W_{r}=w_{r}\\right]-E\\left[\\varepsilon|X_{1}=x{}_{1},X_{2}=x_{2},\\ldots,W_{1}=w_{1},\\ldots,W_{r}=w_{r}\\right]\n  \\] Andiamo a definire adesso l’effetto ceteris paribus di un variazione, da \\(x_1\\) a \\(x_1'\\) usando il modello in Equazione 3. Questo è dato dalle seguente differenza nelle aspettative condizionali:\n\\[\n  E\\left[f(X_1,\\dots,X_k)|X_1 = x'_1, X_2=x_2, \\ldots, W_1=w_1,\\ldots, W_r=w_r\\right] - E\\left[f(X_1, \\dots, X_k, W_1, W_2, \\dots, W_r)|X_1 = x_1, X_2=x_2, \\ldots, W_1=w_1,\\ldots, W_r=w_r\\right].\n  \\]\nè dato dalla della funzione \\(h\\) quando una variabile, diciamo \\(X_1\\), mentre le altre rimangono costanti. Formalmente, \\[\n  h(X_1+\\Delta X_1, \\dots, X_k, W_1, W_2, \\dots, W_r) - h(X_1+\\Delta X_1, \\dots, X_k, W_1, W_2, \\dots, W_r).\n  \\] Come detto, quello che potremmo fare\n### Ceteris Paribus effect L’effetto ceteris paribus di un aumento\nSe il modello in Equazione 3 è postulato a partire dall’intuizione economica, in \\(u\\) confluiscono altre variabili che non abbiamo erroneamente preso in considerazione. L’idea è che il vero meccanismo è \\[\n  Y = h(X_1, \\dots, X_k, W_1, W_2, \\dots, W_r),\n  \\] per una qualche funzione \\(h\\). Possiamo esprimere questo modello in termini del modello\nLa teoria economica può essere utilizzata come punto di partenza per specificare sia la forma funzionale di \\(f\\) sia i fattori rilevanti per la determinazione del salario. Il modello teorico spesso utilizzato per studiare la relazione fra salari e livelli di educazione è quello in cui la scelta del livello di istruzione è dettata dalla massimizzazione dell’utilità nel corso della vita. Secondo questo modello gli individui sceglieranno un livello di istruzione tale per cui i costi marginali di una addizionale di istruzione sono uguali ai benefici marginali. Oltre a dipendere dal livello di istruzione questi costi e benefici dipendono dipendono direttamente e indirettamente da una serie di fattori specifici all’individuo (le \\(X\\) in Equazione 3). Alternativamente le variabili che influenzano il salario potrebbero essere dettate dal buon senso e non da una rigorosa analisi economica.\nQuale che sia l’approccio per definire queste variabili, ricordiamoci che l’obiettivo non è fornirne un elenco. L’obiettivo è quello di quantificare mediante l’utilizzo di dati la relazione fra queste variabili e, in questo esempio, la relazione fra istruzione e salario. Chiaramente questo richiede di specificare una forma funzionale per \\(f\\), cioè fare delle assunzione affinché sia possibile poter determinare queste relazioni.\nLa specificazione della forma funzionale è una assunzione sia che derivi dalla teoria sia che provenga dalla nostra fantastica intuizione. Ma andiamo per ordine. Potremmo iniziare postulando che \\[\nY = \\beta_0 + \\beta_1 X_{1} + \\beta_2 X_{2} + \\ldots + \\beta_k X_{k} + u\n\\tag{6}\\] dove \\(\\beta_0, \\beta_1, \\ldots, \\beta_k\\) sono i parametri del modello e \\(u\\) e il termine di errore. Qual è la relazione fra Equazione 3 e quaste nuova specificazione? Sono due le differenze. La prima è che abbiamo imposto una forma funzionale particolare scegliendo per \\(f\\) una forma lineare nelle variabili che comparivano in Equazione 3. La seconda è che contiene il termine di errore \\(u\\). Comprendere la natura di \\(u\\) è importantissimo e centrale per una corretta comprensione e interpretazione dei modelli econometrici.\nSchematicamente, l’errore comprende le seguenti componenti:\n\naltre variabili che potrebbero contribuire a determinare \\(Y\\) Le variabili \\(X_1, \\ldots, X_k\\) potrebbero non esaurire la lista di variabili che contribuiscono a determinare \\(Y\\). Questo perchè il modello economico è così generico che le variabili individuate sono sono un sottoinsieme di quelle che effettivamente contribuiscono alla determinazione di \\(Y\\). Se il modello in Equazione 3 è postulato a partire dall’intuizione economica, in \\(u\\) confluiscono altre variabili che non abbiamo erroneamente preso in considerazione. L’idea è che il vero meccanismo è \\[\n  Y = h(X_1, \\dots, X_k, W_1, W_2, \\dots, W_r),\n  \\] per una qualche funzione \\(h\\). Possiamo esprimere questo modello in termini del modello\nIn questo caso, abbiamo che\nerrore di approssimazione, cioè la differenza fra il modello lineare e il vero modello non lineare\n\nQueste assunzioni devono essere funzionali ai dati che abbiamo a disposizione. Supponiamo per il momento di avere a disposizioni un campione di individui (assumeremo sempre che il campione sia estratto casualmente dalla popolazione di riferimento) per i quali conosciamo soltanto il salario e il livello di istruzione. Cioè il nostro campione, di dimension \\(n\\) è \\({(Y_i, X_{1i}), (Y_1, X_{11}), \\ldots, ((Y_n, X_{n1}))}\\).\n. Questo ha il vantaggio di rendere l’analisi più agile (spesso introdurre fattori coerentemente in un modello teorico è tecnicamente difficile), ma le derivazioni formali possono fornire una intuizione a cui il nostro buon senso non sarebbe mai giunto. Entrambi gli approcci sono seguiti in econometria. Quando i meccanismi e relazioni sono modellati sulla base della teoria economica parliamo di econometria strutturale. Quando invece le relazioni sono modellate sulla base dell’intuizione senza un preciso riferimento alla teoria economica parliamo di modelli a forma ridotta (reduced form). Quest’ultimo tipo di modelli è esplicitamente disegnato per l’analisi empirica e si basano su una descrizione più semplice e sintetica delle relazioni tra le variabili. Sebbene molti degli strumenti presentati di seguito sono tendenzialmente ispirati dai modelli a forma ridotta, molte delle tecniche possono essere impiegati nel campo dei modelli strutturali. Semplificando\nQualunque sia l’approccio che ha generato la specificazione in Equazione 3,"
  },
  {
    "objectID": "Modelli.html#il-modello-lineare",
    "href": "Modelli.html#il-modello-lineare",
    "title": "Il modello lineare univariato",
    "section": "",
    "text": "Il modello di regressione lineare assume una relazione lineare tra la variabile indipendente \\(X\\) e la variabile dipendente \\(Y\\), che può essere espressa come segue: \\[Y = \\beta_0 + \\beta_1 X + u, \\tag{7}\\] dove \\(\\beta_0\\) e \\(\\beta_1\\) rappresentano parametri sconosciuti e \\(u\\) è l’errore di regressione. L’errore \\(u\\) incorpora tutti i fattori (o variabili) che influenzano \\(Y\\) ma non sono inclusi nel modello lineare.\nPrendiamo, ad esempio, il modello lineare che descrive la relazione tra i punteggi dei test (\\(Y\\)) e la dimensione delle classi (\\(X\\)). Ci sono numerosi fattori che influenzano i risultati dei test, tra cui la qualità degli insegnanti, la motivazione degli studenti, le competenze linguistiche degli alunni e le risorse della scuola. Questi fattori confluiscono nell’errore poiché non sono direttamente inclusi nel modello.\nUn altro esempio di regressione lineare è la relazione tra il reddito di un individuo (\\(Y\\)) e il livello di istruzione (\\(X\\)). Anche in questo caso, ci sono molteplici fattori che influenzano il reddito di un individuo, come l’esperienza lavorativa, le abilità personali e il settore in cui si lavora. Questi fattori non inclusi nel modello lineare confluiscono nel termine di errore \\(u\\).\nQuando riferite al modello in Equazione 7, le variabili \\(Y\\) e \\(X\\) prendono diversi nomi spesso utilizzati in modo intercambiabile. \\(Y\\) viene chiamata variabile dipendente, variabile da spiegare o variabile. La variabile \\(X\\) viene chiamata variabile indipendente, variabile esplicativa, variabile di controllo, variabile predittiva o regressore. Più infrequentemente ci si riferisce a \\(X\\) con il termine covariata. I termini “variabile dipendente” e “variabile indipendente” sono frequentemente utilizzati in econometria. Tuttavia, si noti che “indipendente” non si riferisce in questo caso alla nozione statistica di indipendenza tra variabili casuali.\nLa scelta di utilizzare un modello lineare è ovviamente una semplificazione. Linearità implica che una variazione di una unità di \\(X\\) abbia lo stesso effetto su \\(Y\\), indipendentemente dal valore iniziale di \\(X\\). Questo è irrealistico per molte applicazioni economiche. Ad esempio, nell’esempio del salario-educazione, potremmo voler consentire dei rendimenti crescenti: un anno addizionale di istruzione potrebbe infatti avere un effetto maggiore sul salario se quell’anno è speso in un master piuttosto che uno scuola media.\nSono diverse le ragione per questa semplificazione. Prima di tutto, i modelli lineari sono matematicamente semplici e facili da interpretare, il che rende l’analisi più accessibile anche per chi non ha un background matematico avanzato. Il modello lineare consente di valutare la relazione tra le variabili sotto assunzioni trasparenti e permette anche di predire \\(Y\\) sulla base del valore di \\(X\\) molto semplicemente. Vedremo più avanti che sebbene la linearità sia un limite, il modello può essere modificato al fine di tenere in considerazione la presenza di relazioni non-lineari."
  },
  {
    "objectID": "Modelli.html#lassunzione-chiave",
    "href": "Modelli.html#lassunzione-chiave",
    "title": "Il modello lineare univariato",
    "section": "",
    "text": "La assunzione chiave del modello lineare è la seguente:\n\n\n\n\\(E(u|X) = 0\\)\n\n\nSi ricordi che se \\(E(u|X) = 0\\), allora \\(corr(u,X)=0\\). Quindi, questa assunzione stipula che la variabile inclusa del modello, \\(X\\), e altre variabili che hanno una qualche relazione con \\(Y\\) e contenute in \\(u\\) non sono correlate.\nQuesta è un’assunzione molto forte e, come vedremo, in molte applicazioni non potrà essere considerata valida. In ogni caso, inizieremo a studiare il modello lineare sotto questa assunzione per comprendere la sua logica. In seguito, ci chiederemo come sia possibile interpretare il modello quando l’assunzione non è soddisfatta.\nLa fondamentale implicazione di (ass-key?) è che l’aspettativa condizionale di \\(Y\\) dato \\(X\\) è lineare in \\(X\\), cioè \\[\nE(Y|X) = \\beta_0 + \\beta_1 X.\n\\] Usando questa linearità possiamo ottenere l’interpretazione del parametro \\(\\beta_1\\): \\[\nE(Y|X=x+1) - E(Y|X=x) = \\left[\\beta_0 + \\beta_1 (x+1)\\right]  - \\left[\\beta_0 + \\beta_1 x\\right] = \\beta_1,\n\\] \\(\\beta_1\\) ci dà la risposta di \\(E(Y|X)\\) ad una variazione unitaria (da \\(x\\) a \\(x+1\\)) di \\(X\\).\n::: {.boxmore} Anche \\(\\beta_0\\) ha una interpretazione in termini del valore atteso condizionato di \\(Y\\): \\[\\beta_0 = E(Y|X=0). \\tag{8}\\] Sebbene formalmente corretta, l’interpretazione pratica dell’intercetta è resa problematica da due fatti: (i) in molte applicazione, la variabile \\(X\\) non assume il valore \\(0\\). Se il modello lineare della dimensione delle aule e potrebbe non assumere il valore \\(\\beta_0\\) assorbe la media delle variabile omesse. Cosa succede se invece che uguale a zero, l’aspettativa di \\(u\\) dato \\(X\\) è uguale ad una costante, per esempio \\(E(u|X)=5\\), o \\(E(u|X)=15\\). In questo caso è normale pensare che (ass-key?) non sia valida e l’interpretazione di \\(\\beta_1\\) non sarà quella di quantificare l’effetto di una variazione unitaria sul valore atteso condizionato di \\(Y\\). In realtà le cose sono un tantino più complicate. Proviamo a capire perché. Se \\(E(u|X)=\\kappa_u\\) per qualche valore \\(\\kappa_u\\), abbiamo che \\[\nE(Y|X) = E(\\beta_0 + \\beta_1 X + \\kappa_u|X) = \\beta_0 + \\beta_1 X + \\kappa_u.\n\\] L’aspettativa condizionata è ancora lineare, ma con un intercetta uguale a \\(\\beta_0 + \\kappa_u\\). In ogni caso, l’interpretazione di \\(\\beta_1\\) è invariata rispetta al caso in cui \\(\\kappa_u=0\\) (cioè nel caso specificato dall’{#ass-key}), come si vede chiaramente da \\[\nE(Y|X=x+1) - E(Y|X=x) = \\left[\\beta_0 + \\beta_1 (x+1) + \\kappa_u\\right]  - \\left[\\beta_0 + \\beta_1 x + \\kappa_u\\right] = \\beta_1.\n\\] A questo punto è lecito essere confusi. Abbiamo parlato più volte della centralità dell’assunzione \\(E(u|X)=0\\), ma adesso sembrerebbe che l’interpretazione di \\(\\beta_1\\) è sempre \\(E(Y|X=x+1) - E(Y|X=x)\\) anche quando \\(E(u|X)=\\kappa_u \\neq 0\\). Ora consideriamo il modello lineare data da \\[\nY = \\beta_0 + \\beta_1 X_i + \\varepsilon_i,\n\\] dove \\(\\varepsilon_i=u_i-\\kappa_u\\). In questo modello l’errore è uguale all’errore originale, \\(u_i\\), a cui abbiamo sottratto \\(\\kappa_u\\). Questo è un nuovo modello lineare che soddisfa (ass-key?) — \\(E(\\varepsilon_i|X)=E(u_i|X)-\\kappa_u=\\kappa_u - \\kappa_u = 0\\) — e dove \\(\\beta_1=E(Y|X=x+1) - E(Y|X=x)\\)$ è\nIn realtà, l’assunzione necessaria per interpretare \\(\\beta_1\\) come la variazione di \\(E(Y|X)\\) dovuta ad una variazione di \\(X\\) è \\[\nE(u|X) = \\text{constant}.\n\\] Sembrerebbe che L’assunzione è falsa non quando \\(E(u|X)\\neq 0\\), ma quando il valore atteso di \\(u\\) dato \\(X\\) varia con \\(X\\). In altre parole, l’assunzione #ass-key non è soddisfatta se \\[\nE(u|X=x) = f(x),\n\\] dove \\(f(\\cdot)\\) è una funzione non constante, cioè una funzione tale per cui \\(f(x_1)\\neq f(x_2)\\) per almeno una coppia di valori \\(x_1\\), \\(x_2\\)."
  },
  {
    "objectID": "materiale.html",
    "href": "materiale.html",
    "title": "Materiale didattico",
    "section": "",
    "text": "Questa pagina contiene i collegamenti al materiale didattico del corso. (Nella sidebar qui a sinistra)\nIl materiale didattico è organizzato per lezione e a ciscuna lezione è associato\n\nle slide ()\ndispense R in formato html ()\nil codice R in formato Rmd in formato Rmd ()\nletture consigliate ()\n\nI collegamenti (a sinistra) si attiveranno in sincrono con la progressione del corso."
  },
  {
    "objectID": "montecarlo.html",
    "href": "montecarlo.html",
    "title": "Simulazioni Monte Carlo",
    "section": "",
    "text": "Le simulazioni Monte Carlo sono un metodo numerico spesso utilizzato per verificare le proprietà statistiche di stimatori in modelli econometrici. L’idea di fondo è quella di generare diversi campioni tratti da una ipotizzata popolazione statistica e di calcolare le stime su questi campioni. Utilizzando queste stime è possibile poi verificare le proprietà frequentiste degli stimatori."
  },
  {
    "objectID": "montecarlo.html#esempio-media-campionaria",
    "href": "montecarlo.html#esempio-media-campionaria",
    "title": "Simulazioni Monte Carlo",
    "section": "Esempio: media campionaria",
    "text": "Esempio: media campionaria\nIniziamo con un esempio molto semplice: la media campionaria. Sappiamo dalla teoria che se \\(X_1, \\dots, X_n\\) sono delle variabili casuali indipendentemente e identicamente distribuite con \\(E(X_i)=\\mu_X&lt;\\infty\\) e \\(var(X)=\\sigma_X^2&lt;\\infty\\), allora\n\n\\(E(\\bar{X})=\\mu_X\\)\n\\(\\sqrt{n}(\\bar{X}-\\mu)/\\sigma_X\\xrightarrow{d} N(0,1).\\) Inoltre, per \\(s=\\sqrt{\\frac{1}{n-1}\\sum_{i=1}^n (X_i-\\mu_X)^2}\\), avremo\n\\(\\sqrt{n}(\\bar{X}-\\mu)/s \\xrightarrow{d} N(0,1).\\)\n\nNel caso in cui \\(X_i\\sim N(\\mu_X, \\sigma^2_X)\\), \\(i=1,\\ldots,n\\),\n\n\\(\\sqrt{n}(\\bar{X}-\\mu)/\\sigma_X \\sim N(0,1),\\) e\n\\(\\sqrt{n}(\\bar{X}-\\mu)/s \\sim t(n-1),\\)\n\ndove \\(t(\\nu)\\) denota la distribuzione di student con \\(\\nu\\) gradi di libertà. La differenza fra il caso in cui le osservazioni non hanno una distribuzione normale è che \\(\\bar{X}\\) avrà esattamente una distribuzione normale (non approssimativamente normale come nel case 2.) e \\(\\sqrt{n}(\\bar{X}-\\mu)/s\\) esattamente una distribuzione student-t.\nCome possiamo verificare che queste proprietà siano effettivamente soddisfatte? Possiamo generare ripetutamente campioni di \\(n\\) osservazioni da altrettante variabili casuali e per ciascuno campione calcolare la media campionaria e la standard deviation. Ci aspettiamo che la media delle media, cioè la media degli \\(\\bar{X}\\) calcolati sui campioni, sia approssimativamente uguale a \\(\\mu_X\\) e che gli intervalli di confidenza “coprano” \\(\\mu_X\\) il \\(1-\\alpha\\)% delle volta. Nel caso in cui \\(X_i\\sim N(\\mu_X, \\sigma^2_X)\\), \\(i=1,\\ldots,n\\), la qualità della “copertura” non dipende dalla grandezza dei campioni, mentre quando dobbiamo fare use dell’approssimazione asintotica la “copertura” tenderà ad avvicinarsi a quella nominale al crescere del campione.\nIl seguente codice conduce l’esperimento di montecarlo, simulando le \\(X_i\\) da una distribuzione \\(\\chi^2_{3}\\) centrata per avere una media e una varianza specifica.\n\nset.seed(5647382)\n# Impostazione del numero di simulazioni\nn_simulations &lt;- 1500\n\n# Impostazione della dimensione del campione (cioè `n`)\nsample_size &lt;- 30\n\n# Inizializzazione dei vettori per memorizzare i risultati\n# cioè gli X_bar e le standard deviation per ciascun campione\nx_bars &lt;- numeric(n_simulations)\ns &lt;- numeric(n_simulations)\n\n# Parametri veri del modello\nmu_X    &lt;- 1\nsigma_X &lt;- 1\n# Esecuzione delle simulazioni\nfor (j in 1:n_simulations) {\n  # Generazione del campione\n  X &lt;- mu_X + sigma_X*(rchisq(sample_size, df=3) - 3)/sqrt(6)\n  x_bars[j] &lt;- mean(X)\n  s[j] &lt;- sd(X)\n}\n\nVerifichiamo la proprietà 1.\n\nmean(x_bars) - mu_X\n\n[1] -0.001650921\n\n\nLa differenza non è esattamente uguale a zero perché stiamo calcolando la media di 1500 medie. Se provassimo ad aumentare il numero di simulazioni, la differenza fra il vero valore \\(\\mu_X=1\\) e la media delle medie si ridurrebbe, e sarebbe eventualmente uguale a zero quando n_simulations\\(\\to\\infty\\).\nAndiamo a verificare la distribuzione di \\(\\bar{X}\\).\n\n## Utilità per annotare il grafico\nlibrary(latex2exp)\n## Standardizzazione di X_bar\nx_bars_std &lt;- sqrt(sample_size)*(x_bars-mu_X)/s\n## Histogramma di x_bars_std dovrebbe essere simile a quello di una t(n-1)\nhist(x_bars_std,\n     border = \"lightgray\", col=\"slategray\",\n     breaks = 100,\n     prob=TRUE,\n     xlab = TeX(\"\\\\sqrt{n}(\\\\bar{X}-\\\\mu_X)/s\"))\n## Aggiungiamo la densità di t(n-1)\nrr &lt;- range(x_bars_std)*1.15\nxx &lt;- seq(rr[1], rr[2], length.out=1000)\nyy &lt;- dt(xx, df=sample_size)\nlines(x=xx, y=yy, col = \"darkred\", lwd = 2)\n\n\n\n\nCome si vede la distribuzione di density di una \\(t(n-1)\\) (in rosso nel grafico) non approssima molto bene l’istogramma delle medie campionarie normalizzate. Per comprendere quanto sia problematico questo scostamento, possiamo calcolare gli intervalli di confidenza al 95% e vedere quanto spesso contengono \\(\\mu_X\\).\n\nci_conf &lt;- cbind(\n  x_bars - 1.96*s/sqrt(sample_size),\n  x_bars + 1.96*s/sqrt(sample_size))\n\n\n# Calcolo delle proprietà degli intervalli di confidenza\n\ncoverage &lt;- mean(ci_conf[, 1] &lt;= mu_X & mu_X&lt;=ci_conf[, 2])\ncat(\"La copertura del'intervallo di confidenza al 95% per mu_X:\", coverage, \"\\n\")\n\nLa copertura del'intervallo di confidenza al 95% per mu_X: 0.9213333 \n\n\nSoltanto il 92.1333333% dei campioni restituisce degli intervalli di confidenza che contengono \\(\\mu_X\\). La regione della discrepanza è dovuta al fatto che abbiamo considerato campioni di dimensioni “piccole”, \\(n=30\\), mentre la teoria è basata sull’assunto che i campioni siano grandi, cioè \\(n\\to\\infty\\).\n\nExercise 1 Come cambiano i risultati in termini di copertura dell’intervallo di confidenza quando la dimensione dei campioni è \\(n=200\\)?\n\n\nExercise 2 Modificare il codice affinché i dati siano simulati \\(X_i\\sim N(\\mu_X, \\sigma^2)\\), \\(i=1,\\ldots, n\\). Come cambia la copertura degli intervalli di confidenza? Come è possibile spiegare questa differenza rispetto al caso in cui le variabili casuali hanno una distribuzione \\(\\chi^2\\)?"
  },
  {
    "objectID": "montecarlo.html#simulazioni-monte-carlo-per-regressione.",
    "href": "montecarlo.html#simulazioni-monte-carlo-per-regressione.",
    "title": "Simulazioni Monte Carlo",
    "section": "Simulazioni Monte Carlo per regressione.",
    "text": "Simulazioni Monte Carlo per regressione.\n\n# Pacchetto per calcolare errori standard\nlibrary(sandwich)\n# Impostazione del numero di simulazioni\nn_simulations &lt;- 5000\n\n# Impostazione della dimensione del campione\nsample_size &lt;- 150\n\n# Inizializzazione dei vettori per memorizzare i risultati\nbetahat_0 &lt;- numeric(n_simulations)\nbetahat_1 &lt;- numeric(n_simulations)\n# Matrici contengono gli errori standard.\n# La prima colonna contiene errore standard sotto\n# l'assunzione di omoschedasticità; la seconda colonna\n# contiene l'errore standard robusto\nse_0 &lt;- matrix(, nrow = n_simulations, ncol = 2)\nse_1 &lt;- matrix(, nrow = n_simulations, ncol = 2)\n\n# \"Veri\" coefficienti del modello\nbeta_0 &lt;- 2\nbeta_1 &lt;- 1\n\n# Esecuzione delle simulazioni\nfor (i in 1:n_simulations) {\n  # Generazione dei dati\n  x &lt;- rnorm(sample_size)\n  u &lt;- (rchisq(sample_size, df = 3)-3)/sqrt(2*3)\n  y &lt;- beta_0 + beta_1 * x + u\n\n  # Stima del modello\n  model &lt;- lm(y ~ x)\n\n  # Salvataggio delle stime dei parametri\n  betahat_0[i] &lt;- coef(model)[1]\n  betahat_1[i] &lt;- coef(model)[2]\n\n  # Salvataggio degli errori standard\n  se_homo = sqrt(diag(vcov(model)))\n  se_hete = sqrt(diag(vcovHC(model, type=\"HC1\")))\n  se_0[i, 1] &lt;- se_homo[1]\n  se_1[i, 1] &lt;- se_homo[2]\n  se_0[i, 2] &lt;- se_hete[1]\n  se_1[i, 2] &lt;- se_hete[2]\n}\n\n# Costruzione data.frame\n\nmc1 &lt;- data.frame(t_homo_0 = (betahat_0-beta_0)/se_0[,1],\n                  t_homo_1 = (betahat_1-beta_1)/se_1[,1],\n                  t_hete_0 = (betahat_0-beta_0)/se_0[,2],\n                  t_hete_1 = (betahat_1-beta_1)/se_1[,2]\n                  )\n\n\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(dplyr)\nmcg &lt;- gather(mc1, key = \"coefficient\", value = \"t\")\nggplot(mcg, aes(x=t)) +\n  geom_histogram(aes(y=..density..),\n    col = \"pink\", fill = \"slategray\") +\n  stat_function(fun = dnorm,\n                geom = \"polygon\",\n                col = \"darkblue\",\n                fill = \"lightblue\",\n                alpha=0.65) +\n  facet_wrap(~coefficient)\n\n\n\n\nFigure 1: ?(caption)\n\n\n\n\nTutte le distribuzioni delle statistiche sembrano abbastanza simili a quelle di una normale standard, cioè una normale cone media zero e varianza unitaria (nel Figure 1 in blue). Un modo più preciso per esaminare la qualità dell’approssimazione normale consiste nel contare il numero di intervalli di confidenza che contengono i veri valori dei coefficienti. Usando le statistiche \\(t\\), ciò equivale a contare il numero di statistiche che sono minori in valore assoluto di \\(1.64\\) e \\(1.96\\). Se l’approssimazione è soddisfacente, dovrebbero essere rispettivamente il 10% e il 5% del totale.\n\nmc1 |&gt; summarise_all(.funs = function(x) mean(abs(x)&lt;1.64))\n\n  t_homo_0 t_homo_1 t_hete_0 t_hete_1\n1   0.8888   0.9012   0.8902   0.8954\n\nmc1 |&gt; summarise_all(.funs = function(x) mean(abs(x)&lt;1.96))\n\n  t_homo_0 t_homo_1 t_hete_0 t_hete_1\n1   0.9462    0.951   0.9464   0.9474\n\n\nLe “coperture” degli intervalli di confidenza sono prossimi ai loro valori teorici.\n\n\n\n\n\n\nNote\n\n\n\nLa percentuale dei campioni per il quale la statistica \\(t\\) è maggiore in valore assoluto di \\(1.96\\) (e \\(1.64\\)) coincide con le dimensioni effettiva del test di significatività (quelle teoriche sono del \\(5%\\) e del \\(10\\))\n\nmc1 |&gt; summarise_all(.funs = function(x) mean(abs(x)&gt;1.64))\n\n  t_homo_0 t_homo_1 t_hete_0 t_hete_1\n1   0.1112   0.0988   0.1098   0.1046\n\nmc1 |&gt; summarise_all(.funs = function(x) mean(abs(x)&gt;1.96))\n\n  t_homo_0 t_homo_1 t_hete_0 t_hete_1\n1   0.0538    0.049   0.0536   0.0526\n\n\n\n\nModifichiamo adesso il codice e generiamo il modello con errori eteroschedastici.\n\nset.seed(373982)\n# Impostazione del numero di simulazioni\nn_simulations &lt;- 5000\n\n# Impostazione della dimensione del campione\nsample_size &lt;- 150\n\n# Inizializzazione dei vettori per memorizzare i risultati\nbetahat_0 &lt;- numeric(n_simulations)\nbetahat_1 &lt;- numeric(n_simulations)\n# Matrici contengono gli errori standard.\n# La prima colonna contiene errore standard sotto\n# l'assunzione di omoschedasticità; la seconda colonna\n# contiene l'errore standard robusto\nse_0 &lt;- matrix(, nrow = n_simulations, ncol = 2)\nse_1 &lt;- matrix(, nrow = n_simulations, ncol = 2)\n\n# \"Veri\" coefficienti del modello\nbeta_0 &lt;- 2\nbeta_1 &lt;- 1\n\n# Esecuzione delle simulazioni\nfor (i in 1:n_simulations) {\n  # Generazione dei dati\n  x &lt;- rnorm(sample_size)\n  u &lt;- sqrt(x^2)*(rchisq(sample_size, df = 3)-3)/sqrt(2*3)\n  # Nota: Var(u|x) = E(u^2|x) = x^2\n  #       Var(u) = E(E(u^2|x)) = E(x^2) = 1\n  y &lt;- beta_0 + beta_1 * x + u\n\n  # Stima del modello\n  model &lt;- lm(y ~ x)\n\n  # Salvataggio delle stime dei parametri\n  betahat_0[i] &lt;- coef(model)[1]\n  betahat_1[i] &lt;- coef(model)[2]\n\n  # Salvataggio degli errori standard\n  se_homo = sqrt(diag(vcov(model)))\n  se_hete = sqrt(diag(vcovHC(model, type=\"HC1\")))\n  se_0[i, 1] &lt;- se_homo[1]\n  se_1[i, 1] &lt;- se_homo[2]\n  se_0[i, 2] &lt;- se_hete[1]\n  se_1[i, 2] &lt;- se_hete[2]\n}\n\n# Costruzione data.frame\n\nmc1 &lt;- data.frame(t_homo_0 = (betahat_0-beta_0)/se_0[,1],\n                  t_homo_1 = (betahat_1-beta_1)/se_1[,1],\n                  t_hete_0 = (betahat_0-beta_0)/se_0[,2],\n                  t_hete_1 = (betahat_1-beta_1)/se_1[,2]\n                  )\n\n\nmcg &lt;- gather(mc1, key = \"coefficient\", value = \"t\")\nggplot(mcg, aes(x=t)) +\n  geom_histogram(aes(y=..density..),\n    col = \"pink\", fill = \"slategray\") +\n  stat_function(fun = dnorm,\n                geom = \"polygon\",\n                col = \"darkblue\",\n                fill = \"lightblue\",\n                alpha=0.65) +\n  facet_wrap(~coefficient)\n\n\n\n\nFigure 2: ?(caption)\n\n\n\n\nDall’analisi del grafico in Figure 2 ci accorgiamo che l’approssimazione normale “funziona” con gli errori standard validi per eteroschedasticità mentre è pessima sotto omoschedasticità.\nLa verifica della copertura degli intervalli mostra chiaramente quanto sia problematico non utilizzare gli errori standard robusti.\n\nmc1 |&gt; summarise_all(.funs = function(x) mean(abs(x)&lt;1.64))\n\n  t_homo_0 t_homo_1 t_hete_0 t_hete_1\n1    0.901   0.6436    0.896   0.8742\n\nmc1 |&gt; summarise_all(.funs = function(x) mean(abs(x)&lt;1.96))\n\n  t_homo_0 t_homo_1 t_hete_0 t_hete_1\n1   0.9492   0.7254    0.946   0.9366"
  },
  {
    "objectID": "programma.html",
    "href": "programma.html",
    "title": "Programma del corso",
    "section": "",
    "text": "Programma del corso Questa pagina contiene il programma dettagliato del corso.\n\n\n\n\n\nLezione\nData\nArgomento\nLetture\nMateriale\n\n\n\n\n1\n20/02/23\nIntroduzione all'econometria\nCap. 1\nSlides\n\n\n2\n27/02/23\nRichiami di probabilità e statistica\nCap. 2-3\n\n\n\nModello Lineare Univariato\n\n\n3\n01/03/23\nFormalizzazione e stima dei coefficienti\nCap. 4\n\n\n\n4\n03/03/23\nPredizioni ed effetti causali\n\n\n\n\n5\n06/03/23\nInferenza sui coefficienti\n\n\n\n\n6\n08/03/23\nR e il modello lineare\n\n\n\n\nModello Lineare Multivariato\n\n\n7\n13/03/23\nDistorsioni da variabili omesse\nCap. 5\n\n\n\n8\n15/03/23\nStima dei parametri\n\n\n\n\n9\n17/03/23\nInferenza su singoli parametri\n\n\n\n\n10\n20/03/23\nInferenza su più parametri\n\n\n\n\n11\n22/03/23\nTutti i modelli sono sbagliati, alcuni sono utili\n\n\n\n\n12\n24/03/23\nVariabili misurate con errore\n\n\n\n\nEconometria in azione (I)\n\n\n13\n27/03/23\nIl caso dei salari italiani\nSlides\n\n\n\nFunzioni di regressioni non lineari\n\n\n14\n29/03/23\nPolinomi e trasformazioni logaritmiche\nCap. 6\n\n\n\n15\n31/03/23\nInterazioni fra variabili\n\n\n\n\nRegressione con variabile dipendente binaria\n\n\n16\n03/04/23\nModelli Logit e Probit: motivazioni\nCap. 9\n\n\n\n17\n05/04/23\nStima dei coefficienti e inferenza\n\n\n\n\n18\n12/04/23\nClasificazione e predire di probabilità\n\n\n\n\nValutazione di studi basati sulla regressione multipla\n\n\n19\n14/04/23\nValidità interna e validità esterna\nCap. 7\n\n\n\nDati Panel\n\n\n20\n17/04/23\nCaratteristiche dei dati panel\nCap. 8\n\n\n\n21\n19/04/23\nRegressioni in differenza\n\n\n\n\n22\n21/04/23\nRegressioni con effetti fissi\n\n\n\n\n23\n26/04/23\nInferenze in dati panel\n\n\n\n\nEconometria in azione (II)\n\n\n24\n28/04/23\nArmi e crimine\nSlides\n\n\n\nVariabili Strumentali\n\n\n25\n03/05/23\nIntroduzione variabili strumentali\nCap. 10\n\n\n\n26\n05/05/23\nIl modello di regressione IV\n\n\n\n\n27\n08/05/23\nInferenza con strumenti forti\n\n\n\n\n28\n10/05/23\nInferenza con strumenti deboli\n\n\n\n\nEconometria in azione (III)\n\n\n29\n12/05/23\nIl valore dell'istruzione\n\n\n\n\nEsperimenti e quasi-esperimenti\n\n\n30\n15/05/23\nEsperimenti ideali ed effetti causali\nCap. 11\n\n\n\n31\n17/05/23\nStima degli effetti causali con esperimenti\n\n\n\n\n32\n19/05/23\nQuasi-esperimenti\n\n\n\n\nRegressioni per serie temporali di tipo economico\n\n\n33\n22/05/23\nPrevisioni economiche\nCap. 12-13\n\n\n\n34\n24/05/23\nCorrelazione seriale e stazionarietà\n\n\n\n\n35\n26/05/23\nQualità delle previsioni multiperiodali\n\n\n\n\n36\n29/05/23\nStima degli effetti causali dinamici"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Prof. Giuseppe Ragusa\n   Viale del Castro Laurenziano, 9\n   giuseppe.ragusa@uniroma1.it\n   Schedule an appointment\n\n\n\n\n\n   Lunedì, Martedì e Venerdì\n   20 february, 2023 - 1 giugno 2023\n   (L&V) 10:00–12:00 (M) 14:00-15:00\n   (L&M) Aula 10 (V) Aula 3"
  },
  {
    "objectID": "syllabus.html#descrizione-del-corso",
    "href": "syllabus.html#descrizione-del-corso",
    "title": "Syllabus",
    "section": "Descrizione del corso",
    "text": "Descrizione del corso\nL’obiettivo del corso è quello di introdurre gli studenti allo studio dell’econometria mediante un approccio prevalentemente applicato. Sebbene il corso si concentra sia sugli aspetti teorici sia su quelli pratici della disciplina, l’enfasi è sulla comprensione intuitiva dei concetti fondamentali della materia e sulla loro applicazione empirica su temi microeconomici, macroeconomici e finanziari."
  },
  {
    "objectID": "syllabus.html#obiettivi-del-corso",
    "href": "syllabus.html#obiettivi-del-corso",
    "title": "Syllabus",
    "section": "Obiettivi del corso",
    "text": "Obiettivi del corso\nAl termine del corso lo studente dovrà essere in grado di svolgere autonomamente un’analisi empirica ed interpretarne i risultati, valutando l’adeguatezza delle assunzioni necessarie per la correttezza delle interpretazioni.\nIn particolare, lo studente sarà in grado di\n\nSpiegare la filosofia dei modelli introdotti e la loro capacità di catturare relazioni causali o di fornire predizioni di buona qualità;\nValutare l’adeguatezza delle assunzioni sottostanti i modelli econometrici;\nValutare la qualità delle predizioni mediante rigorose misure statistiche;\nUsare R per stimare e valutare i modelli econometrici su dati reali."
  },
  {
    "objectID": "syllabus.html#libro-di-testo",
    "href": "syllabus.html#libro-di-testo",
    "title": "Syllabus",
    "section": "Libro di testo",
    "text": "Libro di testo\n\n\n\n\n\nIl libro di testo utilizzato in questo corso è:\nStock, J. H. e Watson, M.W: Introduzione all’econometria, Pearson Italia, 2005."
  },
  {
    "objectID": "syllabus.html#software",
    "href": "syllabus.html#software",
    "title": "Syllabus",
    "section": "Software",
    "text": "Software\n\n\n\n\n\nIl corso prevede l’utilizzo di R, uno dei linguaggi di programmazione statistico/econometrico più diffusi e potenti.\nR ha una licenza open-source (GNU GPL), è compatibile con i maggiori sistemi operativi (GNU/Linux, macOS, Microsoft Windows)."
  },
  {
    "objectID": "syllabus.html#orari-di-ricevimento",
    "href": "syllabus.html#orari-di-ricevimento",
    "title": "Syllabus",
    "section": "Orari di ricevimento",
    "text": "Orari di ricevimento\nGli orari di ricevimento sono:\n\n\n\nGiorno\nOrario\n\n\n\n\nLunedì\n15:00-16:00\n\n\nMercoledì\n12:00-13:00\n\n\n\nE’ obbligatorio prenotare un appuntamento utilizzando questo link:"
  },
  {
    "objectID": "syllabus.html#modalità-di-valutazione",
    "href": "syllabus.html#modalità-di-valutazione",
    "title": "Syllabus",
    "section": "Modalità di valutazione",
    "text": "Modalità di valutazione\nLa modalità di esame consiste in una prova scritta e una verifica orale."
  }
]